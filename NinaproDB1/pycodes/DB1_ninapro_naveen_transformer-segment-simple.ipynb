{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "# get_ipython().magic(u'matplotlib auto')\n",
    "import tensorflow as tf\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()\n",
    "# import torch\n",
    "from tensorflow import keras\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential,Model\n",
    "# from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D,Activation\n",
    "# from tensorflow import reshape\n",
    "# from keras.utils import np_utils\n",
    "# from tensorflow.keras.layers import Conv1D,Conv2D, MaxPooling1D,AveragePooling1D\n",
    "# from tensorflow.keras.layers import Input, LocallyConnected1D\n",
    "# from tensorflow.keras.layers import SeparableConv1D, Bidirectional\n",
    "# from tensorflow.keras.layers import LocallyConnected2D\n",
    "# from tensorflow.keras.layers import ZeroPadding2D,ZeroPadding1D, MaxPooling2D, Bidirectional\n",
    "# from tensorflow.keras.regularizers import l2,l1\n",
    "# from tensorflow.keras.layers import BatchNormalization\n",
    "# from tensorflow.keras.callbacks import CSVLogger,LearningRateScheduler\n",
    "# from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "# import coremltools\n",
    "# from torch import nn, optim\n",
    "# import torch.nn.functional as F\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "#from IPython.display import display, HTML\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import GRU,SimpleRNN\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "# get_ipython().magic(u'matplotlib auto')\n",
    "import tensorflow as tf\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()\n",
    "# import torch\n",
    "from tensorflow import keras\n",
    "# config = tf.ConfigProto( device_count = {'GPU': 0 } )\n",
    "# sess = tf.Session(config=config)\n",
    "# keras.backend.set_session(sess)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Activation\n",
    "from tensorflow import reshape\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.layers import Conv1D,Conv2D, MaxPooling1D,AveragePooling1D\n",
    "from tensorflow.keras.layers import SeparableConv1D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import ZeroPadding2D,ZeroPadding1D, MaxPooling2D, Bidirectional\n",
    "from tensorflow.keras.regularizers import l2,l1\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "# import coremltools\n",
    "# from torch import nn, optim\n",
    "# import torch.nn.functional as F\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import GRU, SimpleRNN\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if tf.test.gpu_device_name(): \n",
    "\n",
    "#     print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "# else:\n",
    "\n",
    "#    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import psutil\n",
    "# import humanize\n",
    "# # import os\n",
    "# # import GPUtil as GPU\n",
    "# GPUs = GPU.getGPUs()\n",
    "# # XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
    "# gpu = GPUs[0]\n",
    "# def printm():\n",
    "#  process = psutil.Process(os.getpid())\n",
    "#  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "#  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "# printm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if tf.test.gpu_device_name():\n",
    "#    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "#else:\n",
    "#    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf \n",
    "\n",
    "#if tf.test.gpu_device_name(): \n",
    "#\n",
    "#   print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "#else:\n",
    "\n",
    "#  print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpu_available = tf.config.list_physical_devices('GPU')\n",
    "#is_cuda_gpu_available = tf.test.is_gpu_available(cuda_only=True)\n",
    "#is_cuda_gpu_min_3 = tf.test.is_gpu_available(True, (3,0))\n",
    "#print(is_cuda_gpu_min_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(validations, predictions):\n",
    "\n",
    "    matrix = metrics.confusion_matrix(validations, predictions)\n",
    "    plt.figure(figsize=(20, 14))\n",
    "    sns.heatmap(matrix,\n",
    "                cmap='coolwarm',\n",
    "                linecolor='white',\n",
    "                linewidths=1,\n",
    "                xticklabels=LABELS,\n",
    "                yticklabels=LABELS,\n",
    "                annot=True,\n",
    "                fmt='d')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'Class_label']\n"
     ]
    }
   ],
   "source": [
    "column_names = ['C'+str(j) for j in range(1, N_FEATURES+1)]\n",
    "lst = ['Class_label']\n",
    "column_names = column_names+lst\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_Train(file_path_Train):\n",
    "    df_Train = pd.read_csv(file_path_Train,header=None,names=column_names)\n",
    "    # Last column has a \";\" character which must be removed ...\n",
    "    df_Train['Class_label'].replace(regex=True,inplace=True,to_replace=r';',value=r'')\n",
    "    # ... and then this column must be transformed to float explicitly\n",
    "    df_Train['Class_label'] = df_Train['Class_label'].apply(convert_to_float)\n",
    "    # This is very important otherwise the model will not fit and loss\n",
    "    # will show up as NAN\n",
    "    df_Train.dropna(axis=0, how='any', inplace=True)\n",
    "    return df_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_float(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_basic_dataframe_info(dataframe):\n",
    "    # Shape and how many rows and columns\n",
    "    print('Number of columns in the dataframe: %i' % (dataframe.shape[1]))\n",
    "    print('Number of rows in the dataframe: %i\\n' % (dataframe.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_Test(file_path_Test):\n",
    "    df_Test = pd.read_csv(file_path_Test,header=None,names=column_names)\n",
    "    # Last column has a \";\" character which must be removed ...\n",
    "    df_Test['Class_label'].replace(regex=True,inplace=True,to_replace=r';',value=r'')\n",
    "    # ... and then this column must be transformed to float explicitly\n",
    "    df_Test['Class_label'] = df_Test['Class_label'].apply(convert_to_float)\n",
    "    # This is very important otherwise the model will not fit and loss\n",
    "    # will show up as NAN\n",
    "    df_Test.dropna(axis=0, how='any', inplace=True)\n",
    "    return df_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    " pd.options.display.float_format = \"{:,.5f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 function to segment data into trial lengths (trial length =513 samples in this dataset)\n",
    "def create_segments_and_labels(df, time_steps,step,n_features, label_name):\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - time_steps, step):\n",
    "      for j in range(1, n_features+1):\n",
    "        L = ('C'+str(j)) \n",
    "        segments.append(df[str(L)].values[i: i + time_steps])\n",
    "      label = stats.mode(df[label_name][i: i + time_steps])[0][0]\n",
    "      labels.append(label)\n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, time_steps, n_features)\n",
    "    labels = np.asarray(labels)\n",
    "    return reshaped_segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "path='/media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_naveen/Total_process_TT/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_naveen/Total_process_TT/nina_pro_naveen_DB1_Train.csv\n"
     ]
    }
   ],
   "source": [
    "# file_path_train=path+'Train_data'+'.'+'csv'\n",
    "file_path_train=path+'nina_pro_naveen_DB1_Train'+'.'+'csv'\n",
    "print(file_path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_naveen/Total_process_TT/nina_pro_naveen_DB1_Test.csv\n"
     ]
    }
   ],
   "source": [
    "file_path_test=path+'nina_pro_naveen_DB1_Test'+'.'+'csv'\n",
    "# file_path_test=path+'Test_data'+'.'+'csv'\n",
    "print(file_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in the dataframe: 11\n",
      "Number of rows in the dataframe: 4914000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>Class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00720</td>\n",
       "      <td>0.00242</td>\n",
       "      <td>0.00493</td>\n",
       "      <td>0.00242</td>\n",
       "      <td>0.00245</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.01634</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>0.00247</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00836</td>\n",
       "      <td>0.00243</td>\n",
       "      <td>0.00478</td>\n",
       "      <td>0.00242</td>\n",
       "      <td>0.00245</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>0.00312</td>\n",
       "      <td>0.01699</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>0.00247</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00949</td>\n",
       "      <td>0.00243</td>\n",
       "      <td>0.00464</td>\n",
       "      <td>0.00242</td>\n",
       "      <td>0.00246</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>0.00317</td>\n",
       "      <td>0.01762</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>0.00248</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01052</td>\n",
       "      <td>0.00243</td>\n",
       "      <td>0.00451</td>\n",
       "      <td>0.00242</td>\n",
       "      <td>0.00246</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>0.00322</td>\n",
       "      <td>0.01822</td>\n",
       "      <td>0.00242</td>\n",
       "      <td>0.00248</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01142</td>\n",
       "      <td>0.00243</td>\n",
       "      <td>0.00439</td>\n",
       "      <td>0.00242</td>\n",
       "      <td>0.00246</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>0.00327</td>\n",
       "      <td>0.01877</td>\n",
       "      <td>0.00242</td>\n",
       "      <td>0.00248</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C1      C2      C3      C4      C5      C6      C7      C8      C9  \\\n",
       "0 0.00720 0.00242 0.00493 0.00242 0.00245 0.00241 0.00308 0.01634 0.00241   \n",
       "1 0.00836 0.00243 0.00478 0.00242 0.00245 0.00241 0.00312 0.01699 0.00241   \n",
       "2 0.00949 0.00243 0.00464 0.00242 0.00246 0.00241 0.00317 0.01762 0.00241   \n",
       "3 0.01052 0.00243 0.00451 0.00242 0.00246 0.00241 0.00322 0.01822 0.00242   \n",
       "4 0.01142 0.00243 0.00439 0.00242 0.00246 0.00241 0.00327 0.01877 0.00242   \n",
       "\n",
       "      C10  Class_label  \n",
       "0 0.00247      1.00000  \n",
       "1 0.00247      1.00000  \n",
       "2 0.00248      1.00000  \n",
       "3 0.00248      1.00000  \n",
       "4 0.00248      1.00000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train=read_data_Train(file_path_train)\n",
    "show_basic_dataframe_info(df_Train)\n",
    "df_Train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_Train['Class_label'].value_counts().plot(kind='bar',\n",
    "                                   title='Training Samples count for each class')\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 20\n",
    "fig_size[1] = 10\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.ylabel('Total Samples')\n",
    "plt.xlabel('classes')\n",
    "plt.grid(True)\n",
    "plt.autoscale(axis='x',tight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in the dataframe: 11\n",
      "Number of rows in the dataframe: 2106000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>Class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.03176</td>\n",
       "      <td>0.00247</td>\n",
       "      <td>0.00243</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00244</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00257</td>\n",
       "      <td>0.03562</td>\n",
       "      <td>0.00244</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.03205</td>\n",
       "      <td>0.00248</td>\n",
       "      <td>0.00244</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00245</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00258</td>\n",
       "      <td>0.03567</td>\n",
       "      <td>0.00244</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03234</td>\n",
       "      <td>0.00248</td>\n",
       "      <td>0.00245</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00246</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00259</td>\n",
       "      <td>0.03569</td>\n",
       "      <td>0.00244</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03261</td>\n",
       "      <td>0.00249</td>\n",
       "      <td>0.00246</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00246</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00260</td>\n",
       "      <td>0.03570</td>\n",
       "      <td>0.00244</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.03285</td>\n",
       "      <td>0.00249</td>\n",
       "      <td>0.00246</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00246</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00261</td>\n",
       "      <td>0.03566</td>\n",
       "      <td>0.00245</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C1      C2      C3      C4      C5      C6      C7      C8      C9  \\\n",
       "0 0.03176 0.00247 0.00243 0.00240 0.00244 0.00240 0.00257 0.03562 0.00244   \n",
       "1 0.03205 0.00248 0.00244 0.00240 0.00245 0.00240 0.00258 0.03567 0.00244   \n",
       "2 0.03234 0.00248 0.00245 0.00240 0.00246 0.00240 0.00259 0.03569 0.00244   \n",
       "3 0.03261 0.00249 0.00246 0.00240 0.00246 0.00240 0.00260 0.03570 0.00244   \n",
       "4 0.03285 0.00249 0.00246 0.00240 0.00246 0.00240 0.00261 0.03566 0.00245   \n",
       "\n",
       "      C10  Class_label  \n",
       "0 0.00241      1.00000  \n",
       "1 0.00241      1.00000  \n",
       "2 0.00241      1.00000  \n",
       "3 0.00241      1.00000  \n",
       "4 0.00241      1.00000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test=read_data_Test(file_path_test)\n",
    "show_basic_dataframe_info(df_Test)\n",
    "df_Test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_Test['Class_label'].value_counts().plot(kind='bar',\n",
    "                                   title='Testing Samples count for each class')\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 20\n",
    "fig_size[1] = 10\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.ylabel('Total Samples')\n",
    "plt.xlabel('classes')\n",
    "plt.grid(True)\n",
    "plt.autoscale(axis='x',tight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>Class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00720</td>\n",
       "      <td>0.00242</td>\n",
       "      <td>0.00493</td>\n",
       "      <td>0.00242</td>\n",
       "      <td>0.00245</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.01634</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>0.00247</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00836</td>\n",
       "      <td>0.00243</td>\n",
       "      <td>0.00478</td>\n",
       "      <td>0.00242</td>\n",
       "      <td>0.00245</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>0.00312</td>\n",
       "      <td>0.01699</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>0.00247</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00949</td>\n",
       "      <td>0.00243</td>\n",
       "      <td>0.00464</td>\n",
       "      <td>0.00242</td>\n",
       "      <td>0.00246</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>0.00317</td>\n",
       "      <td>0.01762</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>0.00248</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01052</td>\n",
       "      <td>0.00243</td>\n",
       "      <td>0.00451</td>\n",
       "      <td>0.00242</td>\n",
       "      <td>0.00246</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>0.00322</td>\n",
       "      <td>0.01822</td>\n",
       "      <td>0.00242</td>\n",
       "      <td>0.00248</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01142</td>\n",
       "      <td>0.00243</td>\n",
       "      <td>0.00439</td>\n",
       "      <td>0.00242</td>\n",
       "      <td>0.00246</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>0.00327</td>\n",
       "      <td>0.01877</td>\n",
       "      <td>0.00242</td>\n",
       "      <td>0.00248</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C1      C2      C3      C4      C5      C6      C7      C8      C9  \\\n",
       "0 0.00720 0.00242 0.00493 0.00242 0.00245 0.00241 0.00308 0.01634 0.00241   \n",
       "1 0.00836 0.00243 0.00478 0.00242 0.00245 0.00241 0.00312 0.01699 0.00241   \n",
       "2 0.00949 0.00243 0.00464 0.00242 0.00246 0.00241 0.00317 0.01762 0.00241   \n",
       "3 0.01052 0.00243 0.00451 0.00242 0.00246 0.00241 0.00322 0.01822 0.00242   \n",
       "4 0.01142 0.00243 0.00439 0.00242 0.00246 0.00241 0.00327 0.01877 0.00242   \n",
       "\n",
       "      C10  Class_label  \n",
       "0 0.00247      1.00000  \n",
       "1 0.00247      1.00000  \n",
       "2 0.00248      1.00000  \n",
       "3 0.00248      1.00000  \n",
       "4 0.00248      1.00000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = \"{:,.5f}\".format\n",
    "df_Train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(df_Train.iloc[:,0:N_FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train.iloc[:,0:N_FEATURES]=scaler.transform(df_Train.iloc[:,0:N_FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>Class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.67597</td>\n",
       "      <td>-0.64137</td>\n",
       "      <td>-0.51809</td>\n",
       "      <td>-0.43726</td>\n",
       "      <td>-0.37267</td>\n",
       "      <td>-0.45614</td>\n",
       "      <td>-0.76033</td>\n",
       "      <td>-0.90886</td>\n",
       "      <td>-0.51943</td>\n",
       "      <td>-0.77849</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.67360</td>\n",
       "      <td>-0.64137</td>\n",
       "      <td>-0.51846</td>\n",
       "      <td>-0.43725</td>\n",
       "      <td>-0.37263</td>\n",
       "      <td>-0.45613</td>\n",
       "      <td>-0.76027</td>\n",
       "      <td>-0.90759</td>\n",
       "      <td>-0.51942</td>\n",
       "      <td>-0.77848</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.67130</td>\n",
       "      <td>-0.64136</td>\n",
       "      <td>-0.51882</td>\n",
       "      <td>-0.43725</td>\n",
       "      <td>-0.37260</td>\n",
       "      <td>-0.45613</td>\n",
       "      <td>-0.76019</td>\n",
       "      <td>-0.90634</td>\n",
       "      <td>-0.51942</td>\n",
       "      <td>-0.77847</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.66919</td>\n",
       "      <td>-0.64136</td>\n",
       "      <td>-0.51915</td>\n",
       "      <td>-0.43724</td>\n",
       "      <td>-0.37256</td>\n",
       "      <td>-0.45613</td>\n",
       "      <td>-0.76012</td>\n",
       "      <td>-0.90516</td>\n",
       "      <td>-0.51942</td>\n",
       "      <td>-0.77846</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.66736</td>\n",
       "      <td>-0.64135</td>\n",
       "      <td>-0.51946</td>\n",
       "      <td>-0.43724</td>\n",
       "      <td>-0.37252</td>\n",
       "      <td>-0.45612</td>\n",
       "      <td>-0.76004</td>\n",
       "      <td>-0.90409</td>\n",
       "      <td>-0.51942</td>\n",
       "      <td>-0.77845</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C1       C2       C3       C4       C5       C6       C7       C8  \\\n",
       "0 -0.67597 -0.64137 -0.51809 -0.43726 -0.37267 -0.45614 -0.76033 -0.90886   \n",
       "1 -0.67360 -0.64137 -0.51846 -0.43725 -0.37263 -0.45613 -0.76027 -0.90759   \n",
       "2 -0.67130 -0.64136 -0.51882 -0.43725 -0.37260 -0.45613 -0.76019 -0.90634   \n",
       "3 -0.66919 -0.64136 -0.51915 -0.43724 -0.37256 -0.45613 -0.76012 -0.90516   \n",
       "4 -0.66736 -0.64135 -0.51946 -0.43724 -0.37252 -0.45612 -0.76004 -0.90409   \n",
       "\n",
       "        C9      C10  Class_label  \n",
       "0 -0.51943 -0.77849      1.00000  \n",
       "1 -0.51942 -0.77848      1.00000  \n",
       "2 -0.51942 -0.77847      1.00000  \n",
       "3 -0.51942 -0.77846      1.00000  \n",
       "4 -0.51942 -0.77845      1.00000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = \"{:,.5f}\".format\n",
    "df_Train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>Class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.03176</td>\n",
       "      <td>0.00247</td>\n",
       "      <td>0.00243</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00244</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00257</td>\n",
       "      <td>0.03562</td>\n",
       "      <td>0.00244</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.03205</td>\n",
       "      <td>0.00248</td>\n",
       "      <td>0.00244</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00245</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00258</td>\n",
       "      <td>0.03567</td>\n",
       "      <td>0.00244</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03234</td>\n",
       "      <td>0.00248</td>\n",
       "      <td>0.00245</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00246</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00259</td>\n",
       "      <td>0.03569</td>\n",
       "      <td>0.00244</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03261</td>\n",
       "      <td>0.00249</td>\n",
       "      <td>0.00246</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00246</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00260</td>\n",
       "      <td>0.03570</td>\n",
       "      <td>0.00244</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.03285</td>\n",
       "      <td>0.00249</td>\n",
       "      <td>0.00246</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00246</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00261</td>\n",
       "      <td>0.03566</td>\n",
       "      <td>0.00245</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C1      C2      C3      C4      C5      C6      C7      C8      C9  \\\n",
       "0 0.03176 0.00247 0.00243 0.00240 0.00244 0.00240 0.00257 0.03562 0.00244   \n",
       "1 0.03205 0.00248 0.00244 0.00240 0.00245 0.00240 0.00258 0.03567 0.00244   \n",
       "2 0.03234 0.00248 0.00245 0.00240 0.00246 0.00240 0.00259 0.03569 0.00244   \n",
       "3 0.03261 0.00249 0.00246 0.00240 0.00246 0.00240 0.00260 0.03570 0.00244   \n",
       "4 0.03285 0.00249 0.00246 0.00240 0.00246 0.00240 0.00261 0.03566 0.00245   \n",
       "\n",
       "      C10  Class_label  \n",
       "0 0.00241      1.00000  \n",
       "1 0.00241      1.00000  \n",
       "2 0.00241      1.00000  \n",
       "3 0.00241      1.00000  \n",
       "4 0.00241      1.00000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = \"{:,.5f}\".format\n",
    "df_Test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Test.iloc[:,0:N_FEATURES]=scaler.transform(df_Test.iloc[:,0:N_FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>Class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.62585</td>\n",
       "      <td>-0.64122</td>\n",
       "      <td>-0.52438</td>\n",
       "      <td>-0.43732</td>\n",
       "      <td>-0.37277</td>\n",
       "      <td>-0.45618</td>\n",
       "      <td>-0.76115</td>\n",
       "      <td>-0.87110</td>\n",
       "      <td>-0.51936</td>\n",
       "      <td>-0.77862</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.62526</td>\n",
       "      <td>-0.64121</td>\n",
       "      <td>-0.52435</td>\n",
       "      <td>-0.43732</td>\n",
       "      <td>-0.37266</td>\n",
       "      <td>-0.45618</td>\n",
       "      <td>-0.76114</td>\n",
       "      <td>-0.87102</td>\n",
       "      <td>-0.51936</td>\n",
       "      <td>-0.77862</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.62467</td>\n",
       "      <td>-0.64120</td>\n",
       "      <td>-0.52433</td>\n",
       "      <td>-0.43731</td>\n",
       "      <td>-0.37256</td>\n",
       "      <td>-0.45618</td>\n",
       "      <td>-0.76112</td>\n",
       "      <td>-0.87096</td>\n",
       "      <td>-0.51935</td>\n",
       "      <td>-0.77862</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.62412</td>\n",
       "      <td>-0.64119</td>\n",
       "      <td>-0.52432</td>\n",
       "      <td>-0.43731</td>\n",
       "      <td>-0.37252</td>\n",
       "      <td>-0.45618</td>\n",
       "      <td>-0.76110</td>\n",
       "      <td>-0.87095</td>\n",
       "      <td>-0.51935</td>\n",
       "      <td>-0.77862</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.62363</td>\n",
       "      <td>-0.64117</td>\n",
       "      <td>-0.52432</td>\n",
       "      <td>-0.43731</td>\n",
       "      <td>-0.37250</td>\n",
       "      <td>-0.45618</td>\n",
       "      <td>-0.76109</td>\n",
       "      <td>-0.87102</td>\n",
       "      <td>-0.51934</td>\n",
       "      <td>-0.77862</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C1       C2       C3       C4       C5       C6       C7       C8  \\\n",
       "0 -0.62585 -0.64122 -0.52438 -0.43732 -0.37277 -0.45618 -0.76115 -0.87110   \n",
       "1 -0.62526 -0.64121 -0.52435 -0.43732 -0.37266 -0.45618 -0.76114 -0.87102   \n",
       "2 -0.62467 -0.64120 -0.52433 -0.43731 -0.37256 -0.45618 -0.76112 -0.87096   \n",
       "3 -0.62412 -0.64119 -0.52432 -0.43731 -0.37252 -0.45618 -0.76110 -0.87095   \n",
       "4 -0.62363 -0.64117 -0.52432 -0.43731 -0.37250 -0.45618 -0.76109 -0.87102   \n",
       "\n",
       "        C9      C10  Class_label  \n",
       "0 -0.51936 -0.77862      1.00000  \n",
       "1 -0.51936 -0.77862      1.00000  \n",
       "2 -0.51935 -0.77862      1.00000  \n",
       "3 -0.51935 -0.77862      1.00000  \n",
       "4 -0.51934 -0.77862      1.00000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = \"{:,.5f}\".format\n",
    "df_Test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train_size               C1       C2       C3       C4       C5       C6       C7  \\\n",
      "0       -0.67597 -0.64137 -0.51809 -0.43726 -0.37267 -0.45614 -0.76033   \n",
      "1       -0.67360 -0.64137 -0.51846 -0.43725 -0.37263 -0.45613 -0.76027   \n",
      "2       -0.67130 -0.64136 -0.51882 -0.43725 -0.37260 -0.45613 -0.76019   \n",
      "3       -0.66919 -0.64136 -0.51915 -0.43724 -0.37256 -0.45613 -0.76012   \n",
      "4       -0.66736 -0.64135 -0.51946 -0.43724 -0.37252 -0.45612 -0.76004   \n",
      "...          ...      ...      ...      ...      ...      ...      ...   \n",
      "4913995 -0.41884 -0.53465 -0.51323 -0.40183 -0.37198 -0.12141 -0.40729   \n",
      "4913996 -0.41807 -0.53565 -0.51350 -0.40268 -0.37201 -0.12358 -0.41240   \n",
      "4913997 -0.41719 -0.53653 -0.51373 -0.40340 -0.37204 -0.12541 -0.41689   \n",
      "4913998 -0.41631 -0.53720 -0.51391 -0.40398 -0.37206 -0.12681 -0.42065   \n",
      "4913999 -0.41548 -0.53759 -0.51405 -0.40443 -0.37207 -0.12785 -0.42364   \n",
      "\n",
      "              C8       C9      C10  Class_label  ActivityEncoded  \n",
      "0       -0.90886 -0.51943 -0.77849      1.00000                0  \n",
      "1       -0.90759 -0.51942 -0.77848      1.00000                0  \n",
      "2       -0.90634 -0.51942 -0.77847      1.00000                0  \n",
      "3       -0.90516 -0.51942 -0.77846      1.00000                0  \n",
      "4       -0.90409 -0.51942 -0.77845      1.00000                0  \n",
      "...          ...      ...      ...          ...              ...  \n",
      "4913995 -0.39564 -0.47499 -0.55484     52.00000               51  \n",
      "4913996 -0.40009 -0.47607 -0.55761     52.00000               51  \n",
      "4913997 -0.40381 -0.47698 -0.56004     52.00000               51  \n",
      "4913998 -0.40668 -0.47770 -0.56206     52.00000               51  \n",
      "4913999 -0.40884 -0.47823 -0.56368     52.00000               51  \n",
      "\n",
      "[4914000 rows x 12 columns]\n",
      "df_test_size               C1       C2       C3       C4       C5       C6       C7  \\\n",
      "0       -0.62585 -0.64122 -0.52438 -0.43732 -0.37277 -0.45618 -0.76115   \n",
      "1       -0.62526 -0.64121 -0.52435 -0.43732 -0.37266 -0.45618 -0.76114   \n",
      "2       -0.62467 -0.64120 -0.52433 -0.43731 -0.37256 -0.45618 -0.76112   \n",
      "3       -0.62412 -0.64119 -0.52432 -0.43731 -0.37252 -0.45618 -0.76110   \n",
      "4       -0.62363 -0.64117 -0.52432 -0.43731 -0.37250 -0.45618 -0.76109   \n",
      "...          ...      ...      ...      ...      ...      ...      ...   \n",
      "2105995 -0.31147 -0.33912 -0.49569 -0.43680 -0.33699  0.00274 -0.12585   \n",
      "2105996 -0.31374 -0.34048 -0.49635 -0.43682 -0.33721  0.00335 -0.13104   \n",
      "2105997 -0.31588 -0.34225 -0.49696 -0.43683 -0.33744  0.00360 -0.13579   \n",
      "2105998 -0.31774 -0.34387 -0.49742 -0.43683 -0.33762  0.00363 -0.13993   \n",
      "2105999 -0.31931 -0.34534 -0.49776 -0.43684 -0.33772  0.00354 -0.14341   \n",
      "\n",
      "              C8       C9      C10  Class_label  ActivityEncoded  \n",
      "0       -0.87110 -0.51936 -0.77862      1.00000                0  \n",
      "1       -0.87102 -0.51936 -0.77862      1.00000                0  \n",
      "2       -0.87096 -0.51935 -0.77862      1.00000                0  \n",
      "3       -0.87095 -0.51935 -0.77862      1.00000                0  \n",
      "4       -0.87102 -0.51934 -0.77862      1.00000                0  \n",
      "...          ...      ...      ...          ...              ...  \n",
      "2105995 -0.17566 -0.49431 -0.23361     52.00000               51  \n",
      "2105996 -0.18463 -0.49491 -0.24163     52.00000               51  \n",
      "2105997 -0.19212 -0.49544 -0.24852     52.00000               51  \n",
      "2105998 -0.19794 -0.49583 -0.25415     52.00000               51  \n",
      "2105999 -0.20227 -0.49608 -0.25854     52.00000               51  \n",
      "\n",
      "[2106000 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "LABEL = 'ActivityEncoded'\n",
    "# Transform the labels from String to Integer via LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "# Add a new column to the existing DataFrame with the encoded values\n",
    "df_Train[LABEL] = le.fit_transform(df_Train['Class_label'].values.ravel())\n",
    "# df_Valid[LABEL] = le.fit_transform(df_Valid['Class_label'].values.ravel())\n",
    "df_Test[LABEL] = le.fit_transform(df_Test['Class_label'].values.ravel())\n",
    "print('df_train_size',df_Train)\n",
    "# print('df_valid_size',df_Valid)\n",
    "print('df_test_size',df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of steps within one time segment\n",
    "TIME_PERIODS = 500\n",
    "# The steps to take from one segment to the next; if this value is equal to\n",
    "# TIME_PERIODS, then there is no overlap between the segments\n",
    "STEP_DISTANCE = 500\n",
    "# N_FEATURES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (9827, 500, 10)\n",
      "9827 training samples\n",
      "y_train shape:  (9827,)\n",
      "num_time_periods 500\n",
      "num_sensors 10\n",
      "class_list [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0]\n",
      "x_train shape: (500, 10)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "New y_train shape:  (9827, 52)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = create_segments_and_labels(df_Train,TIME_PERIODS,STEP_DISTANCE,N_FEATURES,LABEL)\n",
    "print('x_train shape: ', x_train.shape)\n",
    "# print(x_train)\n",
    "print(x_train.shape[0], 'training samples')\n",
    "print('y_train shape: ', y_train.shape)\n",
    "# Set input & output dimensions\n",
    "num_time_periods, num_sensors = x_train.shape[1], x_train.shape[2]\n",
    "print('num_time_periods',num_time_periods)\n",
    "print('num_sensors',num_sensors)\n",
    "num_classes = le.classes_.size\n",
    "print('class_list',list(le.classes_))\n",
    "# input_shape = (num_time_periods,num_sensors)\n",
    "# print(input_shape)\n",
    "input_shape = (num_time_periods,num_sensors)\n",
    "#x_train = x_train.reshape(x_train.shape[0], input_shape)\n",
    "print('x_train shape:', x_train[0].shape)\n",
    "# print('input_shape:', input_shape)\n",
    "x_train = x_train.astype('float32')\n",
    "# x_train = [torch.tensor(arr, dtype=torch.float32) for arr in x_train]\n",
    "# y_train = y_train.astype('float32')\n",
    "# print(y_train)\n",
    "y_train_hot = np_utils.to_categorical(y_train, num_classes)\n",
    "print(y_train_hot)\n",
    "# y_train_hot= [torch.tensor(arr, dtype=torch.uint8) for arr in y_train_hot]\n",
    "print('New y_train shape: ', y_train_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test shape:  (4211, 500, 10)\n",
      "4211 testing samples\n",
      "y_test shape:  (4211,)\n",
      "y_test_hot_shape:  (4211, 52)\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = create_segments_and_labels(df_Test,TIME_PERIODS,STEP_DISTANCE,N_FEATURES,LABEL)\n",
    "print('x_test shape: ', x_test.shape)\n",
    "# print(x_train)\n",
    "print(x_test.shape[0], 'testing samples')\n",
    "print('y_test shape: ', y_test.shape)\n",
    "# Set input_shape / reshape for Keras\n",
    "#x_test = x_test.reshape(x_test.shape[0], input_shape)\n",
    "x_test = x_test.astype('float32')\n",
    "# y_test = y_test.astype('float32')\n",
    "y_test_hot = np_utils.to_categorical(y_test, num_classes)\n",
    "print('y_test_hot_shape: ', y_test_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_outputs 52\n"
     ]
    }
   ],
   "source": [
    "# n_steps, n_length = 20, 25\n",
    "# n_steps, n_length= 10, 50\n",
    "# n_steps, n_length= 16, 32\n",
    "#n_steps, n_length = 20, 25\n",
    "# n_depth=10\n",
    "#x_train = x_train.reshape(x_train.shape[0], n_steps, n_length,n_depth)\n",
    "#print('x_train shape: ', x_train.shape)\n",
    "# x_valid = x_valid.reshape(x_valid.shape[0], n_steps, n_length, n_depth)\n",
    "# print('x_valid shape: ', x_valid.shape)\n",
    "#x_test = x_test.reshape(x_test.shape[0], n_steps, n_length,n_depth)\n",
    "#print('x_test shape: ', x_test.shape)\n",
    "n_outputs = y_train_hot.shape[1]\n",
    "print('n_outputs',n_outputs)\n",
    "# input_shape = (n_steps, n_length,n_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_vector =  n_length*n_depth\n",
    "#x_train = x_train.reshape(x_train.shape[0], n_steps, n_vector)\n",
    "#print('x_train shape: ', x_train.shape)\n",
    "#x_test = x_test.reshape(x_test.shape[0], n_steps, n_vector)\n",
    "#print('x_test shape: ', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = x_train.shape[1]\n",
    "n_channel = x_train.shape[-1]\n",
    "n_vector = 128\n",
    "n_heads = 8\n",
    "ff_dim = 2048\n",
    "N_depth = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.5):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential([layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim), ])\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out = self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24 Time to vector conversion\n",
    "class Time2Vector(Layer):\n",
    "  def __init__(self, seq_len, **kwargs):\n",
    "    super(Time2Vector, self).__init__()\n",
    "    self.seq_len = seq_len\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    '''Initialize weights and biases with shape (batch, seq_len)'''\n",
    "    self.weights_linear = self.add_weight(name='weight_linear',\n",
    "                                shape=(int(self.seq_len),),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "    \n",
    "    self.bias_linear = self.add_weight(name='bias_linear',\n",
    "                                shape=(int(self.seq_len),),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "    \n",
    "    self.weights_periodic = self.add_weight(name='weight_periodic',\n",
    "                                shape=(int(self.seq_len),),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "    self.bias_periodic = self.add_weight(name='bias_periodic',\n",
    "                                shape=(int(self.seq_len),),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "  def call(self, x):\n",
    "    '''Calculate linear and periodic time features'''\n",
    "    x = tf.math.reduce_mean(x[:,:,:4], axis=-1) \n",
    "    time_linear = self.weights_linear * x + self.bias_linear # Linear time feature\n",
    "    time_linear = tf.expand_dims(time_linear, axis=-1) # Add dimension (batch, seq_len, 1)\n",
    "    \n",
    "    time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)\n",
    "    time_periodic = tf.expand_dims(time_periodic, axis=-1) # Add dimension (batch, seq_len, 1)\n",
    "    return tf.concat([time_linear, time_periodic], axis=-1) # shape = (batch, seq_len, 2)\n",
    "   \n",
    "  def get_config(self): # Needed for saving and loading model with custom layer\n",
    "    config = super().get_config().copy()\n",
    "    config.update({'seq_len': self.seq_len})\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25 model creation\n",
    "def create_model():\n",
    "  '''Initialize time and transformer layers'''\n",
    "  time_embedding = Time2Vector(seq_len)\n",
    "  transformer_block1 = TransformerBlock(embed_dim = n_vector, num_heads = n_heads, ff_dim=ff_dim)\n",
    "#     '''Construct model'''\n",
    "  in_seq = Input(shape=(seq_len, n_channel))\n",
    "  x = in_seq\n",
    "  x1 = time_embedding(in_seq)\n",
    "  x = Concatenate(axis=-1)([x, x1])\n",
    "#   print(\"x_shape\",x.shape)    \n",
    "  x = Conv1D(n_vector, 9, padding='same', kernel_initializer='he_normal')(x)\n",
    "  x = Conv1D(n_vector, 5, padding='same', kernel_initializer='he_normal')(x)\n",
    "  print(\"x_shape\",x.shape) \n",
    "#   for n in range(N_depth):\n",
    "#     print(\"x_shape\",size(x))\n",
    "  x = transformer_block1(x)\n",
    "\n",
    "#   x = Conv1D(64, 5, padding='same', kernel_initializer='he_normal')(x)\n",
    "#   x = Conv1D(64, 3, padding='same', kernel_initializer='he_normal')(x)     \n",
    "#   print(\"x_shape\",x.shape) \n",
    "  x = Bidirectional(LSTM(200,return_sequences=True))(x)\n",
    "  x = Dropout(0.3)(x)\n",
    "  x = Bidirectional(LSTM(200,return_sequences=True))(x)\n",
    "  x = Dropout(0.3)(x)\n",
    "#   x = GlobalAveragePooling1D(data_format='channels_last')(x)\n",
    "  x = Flatten()(x)\n",
    "  x = Dropout(0.5)(x)\n",
    "  x = Dense(1024, activation='tanh')(x)\n",
    "  x = BatchNormalization(epsilon=1e-06, momentum=0.9, weights=None)(x)\n",
    "  x = Dropout(0.5)(x)  \n",
    "  x = Dense(512, activation='relu')(x)\n",
    "  x = Dropout(0.3)(x)\n",
    "  out = Dense(n_outputs, activation='softmax')(x)\n",
    "  model = Model(inputs=in_seq, outputs=out)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_shape (None, 500, 128)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Inputs to a layer should be tensors. Got: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-4ada26b23e1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 26 model summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-003d9ee9679e>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#   x = Conv1D(64, 3, padding='same', kernel_initializer='he_normal')(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#   print(\"x_shape\",x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ds_tf_gpu/lib/python3.9/site-packages/tensorflow/python/keras/layers/wrappers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0;31m# Applies the same workaround as in `RNN.__call__`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ds_tf_gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                                 input_list)\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ds_tf_gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1088\u001b[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ds_tf_gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ds_tf_gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    860\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ds_tf_gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2682\u001b[0m     \u001b[0;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2683\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2684\u001b[0;31m       input_spec.assert_input_compatibility(\n\u001b[0m\u001b[1;32m   2685\u001b[0m           self.input_spec, inputs, self.name)\n\u001b[1;32m   2686\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ds_tf_gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# have a `shape` attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Inputs to a layer should be tensors. Got: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Inputs to a layer should be tensors. Got: None"
     ]
    }
   ],
   "source": [
    "# 26 model summary\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS=[]\n",
    "for i in range(1,n_outputs+1,1):\n",
    "  LABELS.append (i)\n",
    "print(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "  initial_lrate = 1e-5\n",
    "  drop = 0.1\n",
    "  epochs_drop = 70.0\n",
    "  lrate = initial_lrate * tf.math.pow(drop,  \n",
    "          tf.math.floor((1+epoch)/epochs_drop))\n",
    "  return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrate = tf.keras.callbacks.LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam=optimizers.Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "checkpoint_filepath = '/media/naveen/nav/mat_codes/nina_DB1_codes/transformer/checkpoint.hdf5'\n",
    "# model.load_weights(checkpoint_filepath) \n",
    "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath,verbose=1, monitor='val_accuracy',save_weights_only=True,save_best_only=True)\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=50, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
    "model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='/media/naveen/nav/mat_codes/nina_DB1_codes/transformer/Model1.png',show_shapes=True,show_layer_names=True,dpi=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose, epochs, batch_size = 0, 200, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam=optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "# sgd=tfa.optimizers.SGDW(weight_decay=0.0001,learning_rate=0.1, momentum=0.9, nesterov=False, name='SGDW')\n",
    "# sgd=tf.optimizers.SGD(learning_rate=0.1, momentum=0.9, nesterov=False, name='SGD')\n",
    "#     tf.keras.utils.plot_model(model, to_file='/media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/olsson/CNN20X10/Model1.png',show_shapes=True,show_layer_names=True,dpi=96)\n",
    "\n",
    "csv_logger = CSVLogger('/media/naveen/nav/mat_codes/nina_DB1_codes/transformer/CNN_nina_20X10.csv', append=True, separator=';')\n",
    "history = model.fit(x_train, y_train_hot, epochs=epochs, batch_size=batch_size, callbacks=[csv_logger,checkpoint_callback,lrate,early],validation_data=(x_test, y_test_hot), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_index = history.history['val_accuracy'].index(max(history.history['val_accuracy']))\n",
    "print('epoch_number',best_index+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train accuracy and validation accuracy', history.history['accuracy'][best_index], history.history['val_accuracy'][best_index])\n",
    "model.load_weights(checkpoint_filepath) \n",
    "_, testaccuracy = model.evaluate(x_test, y_test_hot, batch_size=batch_size, verbose=1)\n",
    "print('test_accuracy',testaccuracy)\n",
    "# test_acc.append(testaccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_naveen/CNN25X20/CNN_LSTM_nina_5X97')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in history.history:\n",
    "    print(\"history\",i)\n",
    "# facecolor='black'\n",
    "DB1a=plt.figure(figsize=(10, 8),edgecolor='black')\n",
    "# ax=figDB4.add_axes((\"left\", \"bottom\", \"width\", \"height\"))\n",
    "ax= DB1a.add_axes((1,1,1,1))\n",
    "ax.spines[\"top\"].set_position((\"outward\", 0))\n",
    "ax.spines[\"bottom\"].set_position((\"data\", 0))\n",
    "ax.spines[\"left\"].set_position((\"axes\", 0))\n",
    "ax.spines[\"right\"].set_position((\"outward\", 0))\n",
    "\n",
    "ax.spines[\"top\"].set_color(\"black\")\n",
    "ax.spines[\"left\"].set_color(\"black\")\n",
    "ax.spines[\"right\"].set_color(\"black\")\n",
    "ax.spines[\"bottom\"].set_color(\"black\")\n",
    "\n",
    "# ax.spines[\"left\"].set_bounds(-.5, .5)\n",
    "# ax.spines[\"right\"].set_linestyle(\"--\")\n",
    "# ax.spines[\"bottom\"].set_linewidth(6)\n",
    "# ax.spines[\"bottom\"].set_capstyle(\"round\")\n",
    "\n",
    "# plt2.rcParams['figure.facecolor'] = 'white'\n",
    "plt.plot(history.history['accuracy'], 'r', label='Accuracy of training data')\n",
    "plt.plot(history.history['val_accuracy'], 'b', label='Accuracy of validation data')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Training Epoch')\n",
    "\n",
    "# plt2.ylim(0)\n",
    "# plt2.rcParams['figure.facecolor'] = 'white'\n",
    "\n",
    "# ax = fig.add_axes((left, bottom, width, height))\n",
    "ax.set(facecolor=\"white\")\n",
    "# ax.patch.set_alpha(1.0)\n",
    "plt.ylim(0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in history.history:\n",
    "    print(\"history\",i)\n",
    "# facecolor='black'\n",
    "# ax= figDB1.add_axes((1,1,1,1))\n",
    "# ax.spines[\"top\"].set_position((\"outward\", 0))\n",
    "# ax.spines[\"bottom\"].set_position((\"data\", 0))\n",
    "# ax.spines[\"left\"].set_position((\"axes\", 0))\n",
    "# ax.spines[\"right\"].set_position((\"outward\", 0))\n",
    "\n",
    "# ax.spines[\"top\"].set_color(\"black\")\n",
    "# ax.spines[\"left\"].set_color(\"black\")\n",
    "# ax.spines[\"right\"].set_color(\"black\")\n",
    "# ax.spines[\"bottom\"].set_color(\"black\") \n",
    "\n",
    "figDB1=plt.figure(figsize=(10, 8),edgecolor='black')\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 28}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "# SMALL_SIZE = 12\n",
    "# MEDIUM_SIZE = 14\n",
    "# BIGGER_SIZE = 18\n",
    "\n",
    "# figBPR.suptitle('test title', fontsize=20)\n",
    "#plt.rc('xlabel', fontsize=14, weight = 'bold')\n",
    "#plt.rc('ylabel', fontsize=14, weight = 'bold')\n",
    "\n",
    "# plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "# plt.rc('axes', labelsize=MEDIUM_SIZE )     # fontsize of the axes title\n",
    "# plt.rc('axes', labelsize=MEDIUM_SIZE, weight = 'bold')    # fontsize of the x and y labels\n",
    "# plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "# plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "# plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "# plt.rc('figure', titlesize=BIGGER_SIZE )  # fontsize of the figure title\n",
    "\n",
    "# ax=figDB1.add_axes((\"left\", \"bottom\", \"width\", \"height\"))\n",
    "# ax= figDB1.add_axes((1,1,1,1))\n",
    "# ax.spines[\"top\"].set_position((\"outward\", 0))\n",
    "# ax.spines[\"bottom\"].set_position((\"data\", 0))\n",
    "# ax.spines[\"left\"].set_position((\"axes\", 0))\n",
    "# ax.spines[\"right\"].set_position((\"outward\", 0))\n",
    "\n",
    "# ax.spines[\"top\"].set_color(\"black\")\n",
    "# ax.spines[\"left\"].set_color(\"black\")\n",
    "# ax.spines[\"right\"].set_color(\"black\")\n",
    "# ax.spines[\"bottom\"].set_color(\"black\")\n",
    "\n",
    "# ax.spines[\"left\"].set_bounds(-.5, .5)\n",
    "# ax.spines[\"right\"].set_linestyle(\"--\")\n",
    "ax.spines[\"top\"].set_linewidth(3)\n",
    "ax.spines[\"top\"].set_linestyle(\"-\")\n",
    "ax.spines[\"bottom\"].set_linewidth(3)\n",
    "ax.spines[\"bottom\"].set_linestyle(\"-\")\n",
    "ax.spines[\"left\"].set_linewidth(3)\n",
    "ax.spines[\"left\"].set_linestyle(\"-\")\n",
    "ax.spines[\"right\"].set_linewidth(3)\n",
    "ax.spines[\"right\"].set_linestyle(\"-\")\n",
    "# ax.spines[\"bottom\"].set_capstyle(\"round\")\n",
    "\n",
    "# plt2.rcParams['figure.facecolor'] = 'white'\n",
    "plt.plot(history.history['loss'], 'r-', linewidth=3, label='Loss on training data')\n",
    "plt.plot(history.history['val_loss'], 'b-', linewidth=3, label='Loss on validation data')\n",
    "# plt.title('Loss curve for NinaPro DB1',fontsize=18, weight = 'bold')\n",
    "\n",
    "plt.ylabel('Loss',fontsize=30, weight = 'bold')\n",
    "plt.xlabel('no. of training epochs',fontsize=30, weight = 'bold')\n",
    "# plt2.ylim(0)\n",
    "# plt2.rcParams['figure.facecolor'] = 'white'\n",
    "\n",
    "# ax = fig.add_axes((left, bottom, width, height))\n",
    "ax.set(facecolor=\"white\")\n",
    "# ax.patch.set_alpha(1.0)\n",
    "plt.ylim(0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figDB1.savefig('/media/naveen/nav/plots/NinaPro_DB1_25X20.eps',transparent=False)\n",
    "# figDB1.savefig('/media/naveen/nav/plots/NinaPro_DB1_25X20.pdf',transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_filepath) \n",
    "_, testaccuracy = model.evaluate(x_test, y_test_hot, batch_size=batch_size, verbose=1)\n",
    "print('test_accuracy',testaccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(x_train)\n",
    "# Take the class with the highest probability from the train predictions\n",
    "max_y_pred_train = np.argmax(y_pred_train, axis=1)\n",
    "#max_y_train = np.argmax(y_train, axis=1)\n",
    "show_confusion_matrix(y_train, max_y_pred_train)\n",
    "print(classification_report(y_train, max_y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(x_test)\n",
    "# Take the class with the highest probability from the test predictions\n",
    "max_y_pred_test = np.argmax(y_pred_test, axis=1)\n",
    "max_y_test = np.argmax(y_test_hot, axis=1)\n",
    "show_confusion_matrix(max_y_test, max_y_pred_test)\n",
    "print(classification_report(max_y_test, max_y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 25 model creation\n",
    "# def create_model():\n",
    "#   '''Initialize time and transformer layers'''\n",
    "#   time_embedding = Time2Vector(seq_len)\n",
    "#   # print('time_embedding',time_embedding)\n",
    "#   attn_layer1 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "#   attn_layer2 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "#   attn_layer3 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "#   attn_layer4 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "#   attn_layer5 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "\n",
    "#   '''Construct model'''\n",
    "#   in_seq = Input(shape=(seq_len, n_vector))\n",
    "#   x = in_seq\n",
    "#   print(\"x_shape\",x.shape)\n",
    "#   x = time_embedding(in_seq)\n",
    "#   print(\"x1_shape\",x.shape)\n",
    "#   x = Concatenate(axis=-1)([in_seq, x])\n",
    "#   x = attn_layer1((x, x, x))\n",
    "#   x = attn_layer2((x, x, x))\n",
    "# #   x = attn_layer3((x, x, x))\n",
    "# #   x = attn_layer4((x, x, x))\n",
    "# #   x = attn_layer5((x, x, x))\n",
    "# #   x = GlobalAveragePooling1D(data_format='channels_first')(x)\n",
    "# #   x = TimeDistributed(Flatten())(x)\n",
    "# # #   x = Flatten()(x)\n",
    "# #   x = Bidirectional(LSTM(200,return_sequences=True))(x)\n",
    "# #   x = Dropout(0.3)(x)\n",
    "# #   x = Bidirectional(LSTM(200,return_sequences=True))(x)\n",
    "# #   x = Dropout(0.3)(x)\n",
    "# #   x = Flatten()(x)\n",
    "# #   time_embedding1 = Time2Vector(n_vector)\n",
    "# #   y = tf.transpose(x,perm=[0,2, 1])\n",
    "# # #   print(\"y_shape\",y.shape)  \n",
    "# # #   in_seq2 = Input(shape=(n_vector, seq_len))\n",
    "# # #   y = in_seq2\n",
    "# # #   y = time_embedding1(in_seq2)\n",
    "# # #   y = Concatenate(axis=-1)([in_seq2, y])\n",
    "# # #   print(\"y_shape\",y.shape)  \n",
    "# #   y = attn_layer3((y, y, y))\n",
    "# #   y = attn_layer4((y, y, y))\n",
    "    \n",
    "#   x = Flatten()(x)\n",
    "#   x = Dense(2048, activation='tanh')(x)\n",
    "#   x = BatchNormalization(epsilon=1e-06, momentum=0.9, weights=None)(x)\n",
    "# #   x1 = Flatten()(x1)\n",
    "# #   x1 = Dropout(0.1)(x1)\n",
    "# #   x1 = Dense(1024, activation='tanh')(x1)\n",
    "# #   x1 = BatchNormalization(epsilon=1e-06, momentum=0.9, weights=None)(x1)  \n",
    "# #   x1 = Flatten()(x1)  \n",
    "\n",
    "# #   y = Flatten()(y)\n",
    "# #   y = Dense(2048, activation='tanh')(y)\n",
    "# #   y = BatchNormalization(epsilon=1e-06, momentum=0.9, weights=None)(y)\n",
    "# # #   y = Flatten()(y)\n",
    "# # #   y = Dropout(0.1)(y)\n",
    "# # #   y = Dense(1024, activation='tanh')(y)\n",
    "# # #   y = BatchNormalization(epsilon=1e-06, momentum=0.9, weights=None)(y)  \n",
    "# #   y = Flatten()(y) \n",
    "# # #   y = Dropout(0.1)(y)\n",
    "# #   z = concatenate([x1, y])\n",
    "#   x = Dense(1024, activation='tanh')(x)\n",
    "#   x = BatchNormalization(epsilon=1e-06, momentum=0.9, weights=None)(x)\n",
    "#   x = Dense(512, activation='relu')(x)\n",
    "#   x = Dropout(0.1)(x)\n",
    "#   out = Dense(n_outputs, activation='softmax')(x)\n",
    "\n",
    "#   model = Model(inputs=in_seq, outputs=out)\n",
    "#   # adam=optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "#   # model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
