{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "# get_ipython().magic(u'matplotlib auto')\n",
    "import tensorflow as tf\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()\n",
    "# import torch\n",
    "from tensorflow import keras\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Activation\n",
    "from tensorflow import reshape\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.layers import Conv1D,Conv2D, MaxPooling1D,AveragePooling1D\n",
    "from tensorflow.keras.layers import Input, LocallyConnected1D\n",
    "from tensorflow.keras.layers import SeparableConv1D, Bidirectional\n",
    "from tensorflow.keras.layers import LocallyConnected2D\n",
    "from tensorflow.keras.layers import ZeroPadding2D,ZeroPadding1D, MaxPooling2D, Bidirectional\n",
    "from tensorflow.keras.regularizers import l2,l1\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import CSVLogger,LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "# import coremltools\n",
    "# from torch import nn, optim\n",
    "# import torch.nn.functional as F\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "#from IPython.display import display, HTML\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of steps within one time segment\n",
    "TIME_PERIODS = 400\n",
    "# The steps to take from one segment to the next; if this value is equal to\n",
    "# TIME_PERIODS, then there is no overlap between the segments\n",
    "STEP_DISTANCE = 400\n",
    "N_FEATURES = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'Class_label']\n"
     ]
    }
   ],
   "source": [
    "column_names = ['C'+str(j) for j in range(1, N_FEATURES+1)]\n",
    "lst = ['Class_label']\n",
    "column_names = column_names+lst\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_Train(file_path_Train):\n",
    "    df_Train = pd.read_csv(file_path_Train,header=None,names=column_names)\n",
    "    # Last column has a \";\" character which must be removed ...\n",
    "    df_Train['Class_label'].replace(regex=True,inplace=True,to_replace=r';',value=r'')\n",
    "    # ... and then this column must be transformed to float explicitly\n",
    "    df_Train['Class_label'] = df_Train['Class_label'].apply(convert_to_float)\n",
    "    # This is very important otherwise the model will not fit and loss\n",
    "    # will show up as NAN\n",
    "    df_Train.dropna(axis=0, how='any', inplace=True)\n",
    "    return df_Train\n",
    "def convert_to_float(x):\n",
    "    try:\n",
    "        return np.float(x)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_basic_dataframe_info(dataframe):\n",
    "    # Shape and how many rows and columns\n",
    "    print('Number of columns in the dataframe: %i' % (dataframe.shape[1]))\n",
    "    print('Number of rows in the dataframe: %i\\n' % (dataframe.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_Test(file_path_Test):\n",
    "    df_Test = pd.read_csv(file_path_Test,header=None,names=column_names)\n",
    "    # Last column has a \";\" character which must be removed ...\n",
    "    df_Test['Class_label'].replace(regex=True,inplace=True,to_replace=r';',value=r'')\n",
    "    # ... and then this column must be transformed to float explicitly\n",
    "    df_Test['Class_label'] = df_Test['Class_label'].apply(convert_to_float)\n",
    "    # This is very important otherwise the model will not fit and loss\n",
    "    # will show up as NAN\n",
    "    df_Test.dropna(axis=0, how='any', inplace=True)\n",
    "    return df_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " pd.options.display.float_format = \"{:,.5f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 function to segment data into trial lengths (trial length =513 samples in this dataset)\n",
    "def create_segments_and_labels(df, time_steps,step,n_features, label_name):\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - time_steps, step):\n",
    "      for j in range(1, n_features+1):\n",
    "        L = ('C'+str(j)) \n",
    "        segments.append(df[str(L)].values[i: i + time_steps])\n",
    "      label = stats.mode(df[label_name][i: i + time_steps])[0][0]\n",
    "      labels.append(label)\n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, time_steps, n_features)\n",
    "    labels = np.asarray(labels)\n",
    "    return reshaped_segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose, epochs, batch_size = 0, 120, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "   initial_lrate = 1e-3\n",
    "   drop = 0.1\n",
    "   epochs_drop = 40.0\n",
    "   lrate = initial_lrate * tf.math.pow(drop,  \n",
    "           tf.math.floor((1+epoch)/epochs_drop))\n",
    "   return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrate = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
    "test_acc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "path='/media/naveen/nav/mat_codes/nina_DB4_codes/naveen_prep_nlw/sub_wise_process_TT/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_data,n_channel):\n",
    "    inputs=input_data\n",
    "    print(inputs.shape)\n",
    "    l_y=[]\n",
    "    for i in range(0,n_channel):\n",
    "        ip=inputs[:,:,i]\n",
    "        print('ip_shape',ip.shape)\n",
    "#         ip1=tf.convert_to_tensor(ip, dtype=tf.float32)\n",
    "        ip=tf.reshape(ip,(tf.shape(ip)[0],400,1))\n",
    "        print('ip_shape',ip.shape)\n",
    "        x = Conv1D(64, kernel_size=3,kernel_initializer=\"he_normal\",kernel_regularizer=l1(1e-04), \\\n",
    "               padding='same',input_shape=ip.shape)(ip)\n",
    "        print('conv1_o',x.shape)\n",
    "        x = BatchNormalization(epsilon=1e-06, momentum=0.9, weights=None)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x= Conv1D(filters=64, kernel_size=3,padding=\"same\", kernel_regularizer=l2(5e-04),kernel_initializer=\"he_normal\",strides=1)(x)\n",
    "        x= BatchNormalization(epsilon=1e-06, momentum=0.9, weights=None)(x)\n",
    "        x= Activation('relu')(x)\n",
    "        x= LocallyConnected1D(64, kernel_size=1, kernel_regularizer=l2(5e-04),kernel_initializer=\"he_normal\",strides=1,padding='valid')(x)\n",
    "        x= BatchNormalization(epsilon=1e-06, momentum=0.9, weights=None)(x)\n",
    "        x= Activation('relu')(x)\n",
    "        x= LocallyConnected1D(64, kernel_size=1, kernel_regularizer=l2(5e-04),kernel_initializer=\"he_normal\",strides=1,padding='valid')(x)\n",
    "        x= BatchNormalization(epsilon=1e-06, momentum=0.9, weights=None)(x)\n",
    "        x= Activation('relu')(x)\n",
    "        y= Dropout(0.5)(x)\n",
    "        l_y.append(y)\n",
    "    y_stack=tf.stack(l_y, axis=2)   \n",
    "    return y_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_length =  400\n",
    "n_depth=12\n",
    "n_channel=12\n",
    "n_outputs=52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model():\n",
    "    inputs = Input(shape=(n_length,n_depth),name=\"main\")\n",
    "    p=conv_block(inputs,12)\n",
    "    print(p.shape)\n",
    "    print(type(p))\n",
    "#     print(y.shape)\n",
    "    y=Flatten()(p)\n",
    "    print(y.shape)\n",
    "    y= Dense(512, kernel_initializer=\"he_normal\")(y)\n",
    "    y= BatchNormalization(epsilon=1e-06, momentum=0.9, weights=None)(y)\n",
    "    y= Activation('relu')(y)\n",
    "    y= Dropout(0.5)(y)\n",
    "    y= Dense(512, kernel_initializer=\"he_normal\")(y)\n",
    "    y= BatchNormalization(epsilon=1e-06, momentum=0.9, weights=None)(y)\n",
    "    y= Activation('relu')(y)\n",
    "    y= Dropout(0.5)(y)\n",
    "    y= Dense(128, kernel_initializer=\"he_normal\")(y)\n",
    "    y= BatchNormalization(epsilon=1e-06, momentum=0.9, weights=None)(y)\n",
    "    y= Activation('relu')(y)\n",
    "    outputs=Dense(n_outputs, activation='softmax')(y)\n",
    "    print(outputs.shape)\n",
    "#     wei_mscnn_model = Model(inputs,sub_inputs], outputs)\n",
    "    print('inputs_shape',inputs.shape)\n",
    "    final_model = Model(inputs,outputs,name=\"wei_mscnn_model\")\n",
    "    return final_model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 400, 12)\n",
      "ip_shape (None, 400)\n",
      "ip_shape (None, 400, 1)\n",
      "conv1_o (None, 400, 64)\n",
      "ip_shape (None, 400)\n",
      "ip_shape (None, 400, 1)\n",
      "conv1_o (None, 400, 64)\n",
      "ip_shape (None, 400)\n",
      "ip_shape (None, 400, 1)\n",
      "conv1_o (None, 400, 64)\n",
      "ip_shape (None, 400)\n",
      "ip_shape (None, 400, 1)\n",
      "conv1_o (None, 400, 64)\n",
      "ip_shape (None, 400)\n",
      "ip_shape (None, 400, 1)\n",
      "conv1_o (None, 400, 64)\n",
      "ip_shape (None, 400)\n",
      "ip_shape (None, 400, 1)\n",
      "conv1_o (None, 400, 64)\n",
      "ip_shape (None, 400)\n",
      "ip_shape (None, 400, 1)\n",
      "conv1_o (None, 400, 64)\n",
      "ip_shape (None, 400)\n",
      "ip_shape (None, 400, 1)\n",
      "conv1_o (None, 400, 64)\n",
      "ip_shape (None, 400)\n",
      "ip_shape (None, 400, 1)\n",
      "conv1_o (None, 400, 64)\n",
      "ip_shape (None, 400)\n",
      "ip_shape (None, 400, 1)\n",
      "conv1_o (None, 400, 64)\n",
      "ip_shape (None, 400)\n",
      "ip_shape (None, 400, 1)\n",
      "conv1_o (None, 400, 64)\n",
      "ip_shape (None, 400)\n",
      "ip_shape (None, 400, 1)\n",
      "conv1_o (None, 400, 64)\n",
      "(None, 400, 12, 64)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(None, 307200)\n",
      "(None, 52)\n",
      "inputs_shape (None, 400, 12)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = generate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/naveen/nav/mat_codes/nina_DB4_codes/naveen_prep_nlw/sub_wise_process_TT/S1_tr.csv\n",
      "Number of columns in the dataframe: 13\n",
      "Number of rows in the dataframe: 2080000\n",
      "\n",
      "/media/naveen/nav/mat_codes/nina_DB4_codes/naveen_prep_nlw/sub_wise_process_TT/S1_tt.csv\n",
      "Number of columns in the dataframe: 13\n",
      "Number of rows in the dataframe: 1040000\n",
      "\n",
      "x_train shape:  (5199, 400, 12)\n",
      "5199 training samples\n",
      "y_train shape:  (5199,)\n",
      "num_time_periods 400\n",
      "num_sensors 12\n",
      "class_list [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0]\n",
      "x_train shape: (400, 12)\n",
      "input_shape: (400, 12)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "New y_train shape:  (5199, 52)\n",
      "x_test shape:  (2599, 400, 12)\n",
      "2599 testing samples\n",
      "y_test shape:  (2599,)\n",
      "x_train shape:  (5199, 400, 12)\n",
      "x_test shape:  (2599, 400, 12)\n",
      "n_outputs 52\n",
      "Model: \"wei_mscnn_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main (InputLayer)               [(None, 400, 12)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_8 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_10 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_12 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_14 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_16 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_18 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_20 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_22 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_1 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_2 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_3 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_4 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_5 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_10[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_6 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_12[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_7 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_14[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_8 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_16[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_9 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_18[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_10 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_20[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_11 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_22[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [()]                 0           tf_op_layer_Shape_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_5 (Te [()]                 0           tf_op_layer_Shape_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_7 (Te [()]                 0           tf_op_layer_Shape_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_9 (Te [()]                 0           tf_op_layer_Shape_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_11 (T [()]                 0           tf_op_layer_Shape_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_13 (T [()]                 0           tf_op_layer_Shape_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_15 (T [()]                 0           tf_op_layer_Shape_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_17 (T [()]                 0           tf_op_layer_Shape_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_19 (T [()]                 0           tf_op_layer_Shape_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_21 (T [()]                 0           tf_op_layer_Shape_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_23 (T [()]                 0           tf_op_layer_Shape_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape/shape (Tens [(3,)]               0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1/shape (Te [(3,)]               0           tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2/shape (Te [(3,)]               0           tf_op_layer_strided_slice_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3/shape (Te [(3,)]               0           tf_op_layer_strided_slice_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4/shape (Te [(3,)]               0           tf_op_layer_strided_slice_9[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5/shape (Te [(3,)]               0           tf_op_layer_strided_slice_11[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6/shape (Te [(3,)]               0           tf_op_layer_strided_slice_13[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7/shape (Te [(3,)]               0           tf_op_layer_strided_slice_15[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8/shape (Te [(3,)]               0           tf_op_layer_strided_slice_17[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9/shape (Te [(3,)]               0           tf_op_layer_strided_slice_19[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_10/shape (T [(3,)]               0           tf_op_layer_strided_slice_21[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_11/shape (T [(3,)]               0           tf_op_layer_strided_slice_23[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 400, 1)]     0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 tf_op_layer_Reshape/shape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_2[0][0]\n",
      "                                                                 tf_op_layer_Reshape_1/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_4[0][0]\n",
      "                                                                 tf_op_layer_Reshape_2/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_6[0][0]\n",
      "                                                                 tf_op_layer_Reshape_3/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_8[0][0]\n",
      "                                                                 tf_op_layer_Reshape_4/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_10[0][0\n",
      "                                                                 tf_op_layer_Reshape_5/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_12[0][0\n",
      "                                                                 tf_op_layer_Reshape_6/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_14[0][0\n",
      "                                                                 tf_op_layer_Reshape_7/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_16[0][0\n",
      "                                                                 tf_op_layer_Reshape_8/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_18[0][0\n",
      "                                                                 tf_op_layer_Reshape_9/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_10 (TensorF [(None, 400, 1)]     0           tf_op_layer_strided_slice_20[0][0\n",
      "                                                                 tf_op_layer_Reshape_10/shape[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_11 (TensorF [(None, 400, 1)]     0           tf_op_layer_strided_slice_22[0][0\n",
      "                                                                 tf_op_layer_Reshape_11/shape[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 400, 64)      256         tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 400, 64)      256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 400, 64)      256         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 400, 64)      256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 400, 64)      256         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 400, 64)      256         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 400, 64)      256         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 400, 64)      256         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 400, 64)      256         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 400, 64)      256         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 400, 64)      256         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 400, 64)      256         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 400, 64)      256         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 400, 64)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 400, 64)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 400, 64)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 400, 64)      0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 400, 64)      0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 400, 64)      0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 400, 64)      0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 400, 64)      0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 400, 64)      0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 400, 64)      0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 400, 64)      0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 400, 64)      0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 400, 64)      12352       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 400, 64)      12352       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 400, 64)      12352       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 400, 64)      12352       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 400, 64)      12352       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 400, 64)      12352       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 400, 64)      12352       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 400, 64)      12352       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 400, 64)      12352       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 400, 64)      12352       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 400, 64)      12352       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 400, 64)      12352       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 400, 64)      256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 400, 64)      256         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 400, 64)      256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 400, 64)      256         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 400, 64)      256         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 400, 64)      256         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 400, 64)      256         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 400, 64)      256         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 400, 64)      256         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 400, 64)      256         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 400, 64)      256         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 400, 64)      256         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 400, 64)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 400, 64)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 400, 64)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 400, 64)      0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 400, 64)      0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 400, 64)      0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 400, 64)      0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 400, 64)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 400, 64)      0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 400, 64)      0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 400, 64)      0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 400, 64)      0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d (LocallyCon (None, 400, 64)      1664000     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_2 (LocallyC (None, 400, 64)      1664000     activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_4 (LocallyC (None, 400, 64)      1664000     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_6 (LocallyC (None, 400, 64)      1664000     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_8 (LocallyC (None, 400, 64)      1664000     activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_10 (Locally (None, 400, 64)      1664000     activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_12 (Locally (None, 400, 64)      1664000     activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_14 (Locally (None, 400, 64)      1664000     activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_16 (Locally (None, 400, 64)      1664000     activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_18 (Locally (None, 400, 64)      1664000     activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_20 (Locally (None, 400, 64)      1664000     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_22 (Locally (None, 400, 64)      1664000     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 400, 64)      256         locally_connected1d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 400, 64)      256         locally_connected1d_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 400, 64)      256         locally_connected1d_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 400, 64)      256         locally_connected1d_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 400, 64)      256         locally_connected1d_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 400, 64)      256         locally_connected1d_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 400, 64)      256         locally_connected1d_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 400, 64)      256         locally_connected1d_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 400, 64)      256         locally_connected1d_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 400, 64)      256         locally_connected1d_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 400, 64)      256         locally_connected1d_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 400, 64)      256         locally_connected1d_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 400, 64)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 400, 64)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 400, 64)      0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 400, 64)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 400, 64)      0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 400, 64)      0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 400, 64)      0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 400, 64)      0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 400, 64)      0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 400, 64)      0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 400, 64)      0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 400, 64)      0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_1 (LocallyC (None, 400, 64)      1664000     activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_3 (LocallyC (None, 400, 64)      1664000     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_5 (LocallyC (None, 400, 64)      1664000     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_7 (LocallyC (None, 400, 64)      1664000     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_9 (LocallyC (None, 400, 64)      1664000     activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_11 (Locally (None, 400, 64)      1664000     activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_13 (Locally (None, 400, 64)      1664000     activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_15 (Locally (None, 400, 64)      1664000     activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_17 (Locally (None, 400, 64)      1664000     activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_19 (Locally (None, 400, 64)      1664000     activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_21 (Locally (None, 400, 64)      1664000     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_23 (Locally (None, 400, 64)      1664000     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 400, 64)      256         locally_connected1d_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 400, 64)      256         locally_connected1d_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 400, 64)      256         locally_connected1d_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 400, 64)      256         locally_connected1d_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 400, 64)      256         locally_connected1d_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 400, 64)      256         locally_connected1d_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 400, 64)      256         locally_connected1d_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 400, 64)      256         locally_connected1d_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 400, 64)      256         locally_connected1d_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 400, 64)      256         locally_connected1d_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 400, 64)      256         locally_connected1d_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 400, 64)      256         locally_connected1d_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 400, 64)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 400, 64)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 400, 64)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 400, 64)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 400, 64)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 400, 64)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 400, 64)      0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 400, 64)      0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 400, 64)      0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 400, 64)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 400, 64)      0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 400, 64)      0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 400, 64)      0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 400, 64)      0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 400, 64)      0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 400, 64)      0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 400, 64)      0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 400, 64)      0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 400, 64)      0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 400, 64)      0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 400, 64)      0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 400, 64)      0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 400, 64)      0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 400, 64)      0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_stack (TensorFlowOp [(None, 400, 12, 64) 0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "                                                                 dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 307200)       0           tf_op_layer_stack[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          157286912   flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 512)          0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 512)          0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          262656      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 512)          0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 512)          0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          65664       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 128)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 128)          0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 52)           6708        activation_50[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 197,726,132\n",
      "Trainable params: 197,717,684\n",
      "Non-trainable params: 8,448\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 6.2324 - accuracy: 0.0616\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.19931, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 148s 908ms/step - loss: 6.2324 - accuracy: 0.0616 - val_loss: 5.0986 - val_accuracy: 0.1993 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 4.6579 - accuracy: 0.1789\n",
      "Epoch 00002: val_accuracy improved from 0.19931 to 0.24971, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 63s 388ms/step - loss: 4.6579 - accuracy: 0.1789 - val_loss: 4.0282 - val_accuracy: 0.2497 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.7857 - accuracy: 0.2468\n",
      "Epoch 00003: val_accuracy improved from 0.24971 to 0.28742, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 63s 384ms/step - loss: 3.7857 - accuracy: 0.2468 - val_loss: 3.4743 - val_accuracy: 0.2874 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.3844 - accuracy: 0.2652\n",
      "Epoch 00004: val_accuracy did not improve from 0.28742\n",
      "163/163 [==============================] - 55s 340ms/step - loss: 3.3844 - accuracy: 0.2652 - val_loss: 3.2739 - val_accuracy: 0.2863 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.1157 - accuracy: 0.3078\n",
      "Epoch 00005: val_accuracy improved from 0.28742 to 0.31127, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 61s 374ms/step - loss: 3.1157 - accuracy: 0.3078 - val_loss: 3.1163 - val_accuracy: 0.3113 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.9455 - accuracy: 0.3449\n",
      "Epoch 00006: val_accuracy improved from 0.31127 to 0.34052, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 61s 374ms/step - loss: 2.9455 - accuracy: 0.3449 - val_loss: 2.9893 - val_accuracy: 0.3405 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.7990 - accuracy: 0.3722\n",
      "Epoch 00007: val_accuracy did not improve from 0.34052\n",
      "163/163 [==============================] - 55s 339ms/step - loss: 2.7990 - accuracy: 0.3722 - val_loss: 2.9861 - val_accuracy: 0.3344 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.7411 - accuracy: 0.3787\n",
      "Epoch 00008: val_accuracy did not improve from 0.34052\n",
      "163/163 [==============================] - 55s 339ms/step - loss: 2.7411 - accuracy: 0.3787 - val_loss: 2.9413 - val_accuracy: 0.3397 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.6481 - accuracy: 0.4103\n",
      "Epoch 00009: val_accuracy did not improve from 0.34052\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.6481 - accuracy: 0.4103 - val_loss: 3.0030 - val_accuracy: 0.3397 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.5916 - accuracy: 0.4316\n",
      "Epoch 00010: val_accuracy improved from 0.34052 to 0.34706, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 60s 370ms/step - loss: 2.5916 - accuracy: 0.4316 - val_loss: 3.0374 - val_accuracy: 0.3471 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.4857 - accuracy: 0.4559\n",
      "Epoch 00011: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.4857 - accuracy: 0.4559 - val_loss: 3.0224 - val_accuracy: 0.3382 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.4503 - accuracy: 0.4745\n",
      "Epoch 00012: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.4503 - accuracy: 0.4745 - val_loss: 3.1003 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.3503 - accuracy: 0.5084\n",
      "Epoch 00013: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 2.3503 - accuracy: 0.5084 - val_loss: 3.0928 - val_accuracy: 0.3386 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.3013 - accuracy: 0.5295\n",
      "Epoch 00014: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.3013 - accuracy: 0.5295 - val_loss: 3.2513 - val_accuracy: 0.3201 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.2594 - accuracy: 0.5486\n",
      "Epoch 00015: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.2594 - accuracy: 0.5486 - val_loss: 3.2778 - val_accuracy: 0.3344 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.1974 - accuracy: 0.5624\n",
      "Epoch 00016: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 2.1974 - accuracy: 0.5624 - val_loss: 3.3264 - val_accuracy: 0.3236 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.1781 - accuracy: 0.5768\n",
      "Epoch 00017: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.1781 - accuracy: 0.5768 - val_loss: 3.3608 - val_accuracy: 0.3259 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.1004 - accuracy: 0.6022\n",
      "Epoch 00018: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 2.1004 - accuracy: 0.6022 - val_loss: 3.4414 - val_accuracy: 0.3244 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.0820 - accuracy: 0.6213\n",
      "Epoch 00019: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 2.0820 - accuracy: 0.6213 - val_loss: 3.5886 - val_accuracy: 0.3178 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.0159 - accuracy: 0.6455\n",
      "Epoch 00020: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.0159 - accuracy: 0.6455 - val_loss: 3.5666 - val_accuracy: 0.3132 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.0232 - accuracy: 0.6505\n",
      "Epoch 00021: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.0232 - accuracy: 0.6505 - val_loss: 3.6110 - val_accuracy: 0.3182 - lr: 0.0010\n",
      "Epoch 22/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.9045 - accuracy: 0.6842\n",
      "Epoch 00022: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.9045 - accuracy: 0.6842 - val_loss: 3.7624 - val_accuracy: 0.2982 - lr: 0.0010\n",
      "Epoch 23/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.9341 - accuracy: 0.6847\n",
      "Epoch 00023: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.9341 - accuracy: 0.6847 - val_loss: 3.8301 - val_accuracy: 0.3093 - lr: 0.0010\n",
      "Epoch 24/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8972 - accuracy: 0.6953\n",
      "Epoch 00024: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 1.8972 - accuracy: 0.6953 - val_loss: 3.8308 - val_accuracy: 0.3105 - lr: 0.0010\n",
      "Epoch 25/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8730 - accuracy: 0.7094\n",
      "Epoch 00025: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 1.8730 - accuracy: 0.7094 - val_loss: 4.0175 - val_accuracy: 0.2940 - lr: 0.0010\n",
      "Epoch 26/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8707 - accuracy: 0.7201\n",
      "Epoch 00026: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.8707 - accuracy: 0.7201 - val_loss: 3.9593 - val_accuracy: 0.2947 - lr: 0.0010\n",
      "Epoch 27/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8376 - accuracy: 0.7311\n",
      "Epoch 00027: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 1.8376 - accuracy: 0.7311 - val_loss: 3.9695 - val_accuracy: 0.3055 - lr: 0.0010\n",
      "Epoch 28/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8746 - accuracy: 0.7401\n",
      "Epoch 00028: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 1.8746 - accuracy: 0.7401 - val_loss: 4.0845 - val_accuracy: 0.3013 - lr: 0.0010\n",
      "Epoch 29/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8170 - accuracy: 0.7501\n",
      "Epoch 00029: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.8170 - accuracy: 0.7501 - val_loss: 4.1183 - val_accuracy: 0.3005 - lr: 0.0010\n",
      "Epoch 30/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7627 - accuracy: 0.7609\n",
      "Epoch 00030: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.7627 - accuracy: 0.7609 - val_loss: 4.1923 - val_accuracy: 0.2820 - lr: 0.0010\n",
      "Epoch 31/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7128 - accuracy: 0.7742\n",
      "Epoch 00031: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.7128 - accuracy: 0.7742 - val_loss: 4.1922 - val_accuracy: 0.2832 - lr: 0.0010\n",
      "Epoch 32/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7497 - accuracy: 0.7780\n",
      "Epoch 00032: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.7497 - accuracy: 0.7780 - val_loss: 4.2885 - val_accuracy: 0.2874 - lr: 0.0010\n",
      "Epoch 33/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7873 - accuracy: 0.7694\n",
      "Epoch 00033: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.7873 - accuracy: 0.7694 - val_loss: 4.4923 - val_accuracy: 0.2809 - lr: 0.0010\n",
      "Epoch 34/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7172 - accuracy: 0.7955\n",
      "Epoch 00034: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.7172 - accuracy: 0.7955 - val_loss: 4.5339 - val_accuracy: 0.2836 - lr: 0.0010\n",
      "Epoch 35/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6726 - accuracy: 0.8075\n",
      "Epoch 00035: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.6726 - accuracy: 0.8075 - val_loss: 4.4251 - val_accuracy: 0.2909 - lr: 0.0010\n",
      "Epoch 36/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6925 - accuracy: 0.8136\n",
      "Epoch 00036: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.6925 - accuracy: 0.8136 - val_loss: 4.5201 - val_accuracy: 0.2828 - lr: 0.0010\n",
      "Epoch 37/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7022 - accuracy: 0.8127\n",
      "Epoch 00037: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.7022 - accuracy: 0.8127 - val_loss: 4.5236 - val_accuracy: 0.2805 - lr: 0.0010\n",
      "Epoch 38/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6632 - accuracy: 0.8192\n",
      "Epoch 00038: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.6632 - accuracy: 0.8192 - val_loss: 4.6826 - val_accuracy: 0.2774 - lr: 0.0010\n",
      "Epoch 39/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6485 - accuracy: 0.8240\n",
      "Epoch 00039: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.6485 - accuracy: 0.8240 - val_loss: 4.5838 - val_accuracy: 0.2909 - lr: 0.0010\n",
      "Epoch 40/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4618 - accuracy: 0.8690\n",
      "Epoch 00040: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.4618 - accuracy: 0.8690 - val_loss: 4.3328 - val_accuracy: 0.2913 - lr: 1.0000e-04\n",
      "Epoch 41/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.2886 - accuracy: 0.9009\n",
      "Epoch 00041: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.2886 - accuracy: 0.9009 - val_loss: 4.2657 - val_accuracy: 0.2947 - lr: 1.0000e-04\n",
      "Epoch 42/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.2227 - accuracy: 0.9050\n",
      "Epoch 00042: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.2227 - accuracy: 0.9050 - val_loss: 4.2988 - val_accuracy: 0.2866 - lr: 1.0000e-04\n",
      "Epoch 43/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.1773 - accuracy: 0.9088\n",
      "Epoch 00043: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.1773 - accuracy: 0.9088 - val_loss: 4.2796 - val_accuracy: 0.2805 - lr: 1.0000e-04\n",
      "Epoch 44/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0913 - accuracy: 0.9250\n",
      "Epoch 00044: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.0913 - accuracy: 0.9250 - val_loss: 4.2696 - val_accuracy: 0.2828 - lr: 1.0000e-04\n",
      "Epoch 45/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0520 - accuracy: 0.9275\n",
      "Epoch 00045: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.0520 - accuracy: 0.9275 - val_loss: 4.2869 - val_accuracy: 0.2805 - lr: 1.0000e-04\n",
      "Epoch 46/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0053 - accuracy: 0.9317\n",
      "Epoch 00046: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.0053 - accuracy: 0.9317 - val_loss: 4.2369 - val_accuracy: 0.2797 - lr: 1.0000e-04\n",
      "Epoch 47/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9668 - accuracy: 0.9371\n",
      "Epoch 00047: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 0.9668 - accuracy: 0.9371 - val_loss: 4.2255 - val_accuracy: 0.2774 - lr: 1.0000e-04\n",
      "Epoch 48/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9311 - accuracy: 0.9390\n",
      "Epoch 00048: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.9311 - accuracy: 0.9390 - val_loss: 4.1689 - val_accuracy: 0.2743 - lr: 1.0000e-04\n",
      "Epoch 49/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9114 - accuracy: 0.9394\n",
      "Epoch 00049: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.9114 - accuracy: 0.9394 - val_loss: 4.1585 - val_accuracy: 0.2828 - lr: 1.0000e-04\n",
      "Epoch 50/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8668 - accuracy: 0.9483\n",
      "Epoch 00050: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.8668 - accuracy: 0.9483 - val_loss: 4.1941 - val_accuracy: 0.2778 - lr: 1.0000e-04\n",
      "Epoch 51/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8377 - accuracy: 0.9479\n",
      "Epoch 00051: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 0.8377 - accuracy: 0.9479 - val_loss: 4.1885 - val_accuracy: 0.2813 - lr: 1.0000e-04\n",
      "Epoch 52/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8118 - accuracy: 0.9506\n",
      "Epoch 00052: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.8118 - accuracy: 0.9506 - val_loss: 4.1852 - val_accuracy: 0.2736 - lr: 1.0000e-04\n",
      "Epoch 53/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - ETA: 0s - loss: 0.7991 - accuracy: 0.9465\n",
      "Epoch 00053: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.7991 - accuracy: 0.9465 - val_loss: 4.1538 - val_accuracy: 0.2855 - lr: 1.0000e-04\n",
      "Epoch 54/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7764 - accuracy: 0.9454\n",
      "Epoch 00054: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.7764 - accuracy: 0.9454 - val_loss: 4.1886 - val_accuracy: 0.2820 - lr: 1.0000e-04\n",
      "Epoch 55/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7506 - accuracy: 0.9508\n",
      "Epoch 00055: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.7506 - accuracy: 0.9508 - val_loss: 4.1247 - val_accuracy: 0.2828 - lr: 1.0000e-04\n",
      "Epoch 56/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7238 - accuracy: 0.9552\n",
      "Epoch 00056: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.7238 - accuracy: 0.9552 - val_loss: 4.1659 - val_accuracy: 0.2863 - lr: 1.0000e-04\n",
      "Epoch 57/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7022 - accuracy: 0.9558\n",
      "Epoch 00057: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.7022 - accuracy: 0.9558 - val_loss: 4.1890 - val_accuracy: 0.2820 - lr: 1.0000e-04\n",
      "Epoch 58/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6796 - accuracy: 0.9590\n",
      "Epoch 00058: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.6796 - accuracy: 0.9590 - val_loss: 4.1411 - val_accuracy: 0.2824 - lr: 1.0000e-04\n",
      "Epoch 59/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6604 - accuracy: 0.9596\n",
      "Epoch 00059: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.6604 - accuracy: 0.9596 - val_loss: 4.1573 - val_accuracy: 0.2813 - lr: 1.0000e-04\n",
      "Epoch 60/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6378 - accuracy: 0.9636\n",
      "Epoch 00060: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.6378 - accuracy: 0.9636 - val_loss: 4.1582 - val_accuracy: 0.2820 - lr: 1.0000e-04\n",
      "Epoch 61/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6301 - accuracy: 0.9625\n",
      "Epoch 00061: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.6301 - accuracy: 0.9625 - val_loss: 4.1824 - val_accuracy: 0.2809 - lr: 1.0000e-04\n",
      "Epoch 62/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6118 - accuracy: 0.9623\n",
      "Epoch 00062: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.6118 - accuracy: 0.9623 - val_loss: 4.1502 - val_accuracy: 0.2801 - lr: 1.0000e-04\n",
      "Epoch 63/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6036 - accuracy: 0.9610\n",
      "Epoch 00063: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.6036 - accuracy: 0.9610 - val_loss: 4.2085 - val_accuracy: 0.2751 - lr: 1.0000e-04\n",
      "Epoch 64/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5898 - accuracy: 0.9617\n",
      "Epoch 00064: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.5898 - accuracy: 0.9617 - val_loss: 4.1799 - val_accuracy: 0.2782 - lr: 1.0000e-04\n",
      "Epoch 65/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5792 - accuracy: 0.9633\n",
      "Epoch 00065: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.5792 - accuracy: 0.9633 - val_loss: 4.1382 - val_accuracy: 0.2743 - lr: 1.0000e-04\n",
      "Epoch 66/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5649 - accuracy: 0.9640\n",
      "Epoch 00066: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 0.5649 - accuracy: 0.9640 - val_loss: 4.2610 - val_accuracy: 0.2805 - lr: 1.0000e-04\n",
      "Epoch 67/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5438 - accuracy: 0.9660\n",
      "Epoch 00067: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.5438 - accuracy: 0.9660 - val_loss: 4.1975 - val_accuracy: 0.2824 - lr: 1.0000e-04\n",
      "Epoch 68/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5435 - accuracy: 0.9658\n",
      "Epoch 00068: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.5435 - accuracy: 0.9658 - val_loss: 4.2067 - val_accuracy: 0.2728 - lr: 1.0000e-04\n",
      "Epoch 69/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5337 - accuracy: 0.9652\n",
      "Epoch 00069: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.5337 - accuracy: 0.9652 - val_loss: 4.2643 - val_accuracy: 0.2763 - lr: 1.0000e-04\n",
      "Epoch 70/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5176 - accuracy: 0.9681\n",
      "Epoch 00070: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.5176 - accuracy: 0.9681 - val_loss: 4.1828 - val_accuracy: 0.2832 - lr: 1.0000e-04\n",
      "Epoch 71/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5103 - accuracy: 0.9677\n",
      "Epoch 00071: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.5103 - accuracy: 0.9677 - val_loss: 4.1832 - val_accuracy: 0.2786 - lr: 1.0000e-04\n",
      "Epoch 72/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5058 - accuracy: 0.9661\n",
      "Epoch 00072: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.5058 - accuracy: 0.9661 - val_loss: 4.1628 - val_accuracy: 0.2763 - lr: 1.0000e-04\n",
      "Epoch 73/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4911 - accuracy: 0.9665\n",
      "Epoch 00073: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4911 - accuracy: 0.9665 - val_loss: 4.1697 - val_accuracy: 0.2866 - lr: 1.0000e-04\n",
      "Epoch 74/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4998 - accuracy: 0.9623\n",
      "Epoch 00074: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4998 - accuracy: 0.9623 - val_loss: 4.2461 - val_accuracy: 0.2786 - lr: 1.0000e-04\n",
      "Epoch 75/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4763 - accuracy: 0.9685\n",
      "Epoch 00075: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4763 - accuracy: 0.9685 - val_loss: 4.2135 - val_accuracy: 0.2728 - lr: 1.0000e-04\n",
      "Epoch 76/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4611 - accuracy: 0.9713\n",
      "Epoch 00076: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4611 - accuracy: 0.9713 - val_loss: 4.1944 - val_accuracy: 0.2751 - lr: 1.0000e-04\n",
      "Epoch 77/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4755 - accuracy: 0.9656\n",
      "Epoch 00077: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4755 - accuracy: 0.9656 - val_loss: 4.2806 - val_accuracy: 0.2639 - lr: 1.0000e-04\n",
      "Epoch 78/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4601 - accuracy: 0.9692\n",
      "Epoch 00078: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4601 - accuracy: 0.9692 - val_loss: 4.2532 - val_accuracy: 0.2716 - lr: 1.0000e-04\n",
      "Epoch 79/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4596 - accuracy: 0.9696\n",
      "Epoch 00079: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4596 - accuracy: 0.9696 - val_loss: 4.2222 - val_accuracy: 0.2732 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4403 - accuracy: 0.9733\n",
      "Epoch 00080: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4403 - accuracy: 0.9733 - val_loss: 4.2108 - val_accuracy: 0.2740 - lr: 1.0000e-05\n",
      "Epoch 81/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4384 - accuracy: 0.9736\n",
      "Epoch 00081: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4384 - accuracy: 0.9736 - val_loss: 4.2564 - val_accuracy: 0.2759 - lr: 1.0000e-05\n",
      "Epoch 82/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4372 - accuracy: 0.9710\n",
      "Epoch 00082: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4372 - accuracy: 0.9710 - val_loss: 4.2489 - val_accuracy: 0.2774 - lr: 1.0000e-05\n",
      "Epoch 83/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4347 - accuracy: 0.9721\n",
      "Epoch 00083: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4347 - accuracy: 0.9721 - val_loss: 4.2449 - val_accuracy: 0.2716 - lr: 1.0000e-05\n",
      "Epoch 84/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4335 - accuracy: 0.9723\n",
      "Epoch 00084: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4335 - accuracy: 0.9723 - val_loss: 4.2418 - val_accuracy: 0.2766 - lr: 1.0000e-05\n",
      "Epoch 85/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4326 - accuracy: 0.9748\n",
      "Epoch 00085: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4326 - accuracy: 0.9748 - val_loss: 4.2114 - val_accuracy: 0.2828 - lr: 1.0000e-05\n",
      "Epoch 86/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4297 - accuracy: 0.9733\n",
      "Epoch 00086: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4297 - accuracy: 0.9733 - val_loss: 4.2547 - val_accuracy: 0.2828 - lr: 1.0000e-05\n",
      "Epoch 87/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4242 - accuracy: 0.9754\n",
      "Epoch 00087: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 0.4242 - accuracy: 0.9754 - val_loss: 4.2378 - val_accuracy: 0.2755 - lr: 1.0000e-05\n",
      "Epoch 88/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4284 - accuracy: 0.9713\n",
      "Epoch 00088: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4284 - accuracy: 0.9713 - val_loss: 4.2188 - val_accuracy: 0.2751 - lr: 1.0000e-05\n",
      "Epoch 89/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4232 - accuracy: 0.9738\n",
      "Epoch 00089: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4232 - accuracy: 0.9738 - val_loss: 4.2168 - val_accuracy: 0.2755 - lr: 1.0000e-05\n",
      "Epoch 90/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4262 - accuracy: 0.9738\n",
      "Epoch 00090: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4262 - accuracy: 0.9738 - val_loss: 4.2367 - val_accuracy: 0.2790 - lr: 1.0000e-05\n",
      "Epoch 91/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4258 - accuracy: 0.9742\n",
      "Epoch 00091: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4258 - accuracy: 0.9742 - val_loss: 4.2236 - val_accuracy: 0.2828 - lr: 1.0000e-05\n",
      "Epoch 92/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4182 - accuracy: 0.9783\n",
      "Epoch 00092: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.4182 - accuracy: 0.9783 - val_loss: 4.2247 - val_accuracy: 0.2747 - lr: 1.0000e-05\n",
      "Epoch 93/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4164 - accuracy: 0.9756\n",
      "Epoch 00093: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4164 - accuracy: 0.9756 - val_loss: 4.2735 - val_accuracy: 0.2759 - lr: 1.0000e-05\n",
      "Epoch 94/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4166 - accuracy: 0.9748\n",
      "Epoch 00094: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4166 - accuracy: 0.9748 - val_loss: 4.2233 - val_accuracy: 0.2736 - lr: 1.0000e-05\n",
      "Epoch 95/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4146 - accuracy: 0.9738\n",
      "Epoch 00095: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4146 - accuracy: 0.9738 - val_loss: 4.2941 - val_accuracy: 0.2697 - lr: 1.0000e-05\n",
      "Epoch 96/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4214 - accuracy: 0.9731\n",
      "Epoch 00096: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4214 - accuracy: 0.9731 - val_loss: 4.2802 - val_accuracy: 0.2670 - lr: 1.0000e-05\n",
      "Epoch 97/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4065 - accuracy: 0.9804\n",
      "Epoch 00097: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4065 - accuracy: 0.9804 - val_loss: 4.2053 - val_accuracy: 0.2747 - lr: 1.0000e-05\n",
      "Epoch 98/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4021 - accuracy: 0.9792\n",
      "Epoch 00098: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4021 - accuracy: 0.9792 - val_loss: 4.2031 - val_accuracy: 0.2782 - lr: 1.0000e-05\n",
      "Epoch 99/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4092 - accuracy: 0.9758\n",
      "Epoch 00099: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4092 - accuracy: 0.9758 - val_loss: 4.2385 - val_accuracy: 0.2766 - lr: 1.0000e-05\n",
      "Epoch 100/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4030 - accuracy: 0.9796\n",
      "Epoch 00100: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4030 - accuracy: 0.9796 - val_loss: 4.2603 - val_accuracy: 0.2778 - lr: 1.0000e-05\n",
      "Epoch 101/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4072 - accuracy: 0.9771\n",
      "Epoch 00101: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.4072 - accuracy: 0.9771 - val_loss: 4.2803 - val_accuracy: 0.2816 - lr: 1.0000e-05\n",
      "Epoch 102/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4159 - accuracy: 0.9738\n",
      "Epoch 00102: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4159 - accuracy: 0.9738 - val_loss: 4.2117 - val_accuracy: 0.2816 - lr: 1.0000e-05\n",
      "Epoch 103/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4068 - accuracy: 0.9777\n",
      "Epoch 00103: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4068 - accuracy: 0.9777 - val_loss: 4.2559 - val_accuracy: 0.2720 - lr: 1.0000e-05\n",
      "Epoch 104/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4058 - accuracy: 0.9767\n",
      "Epoch 00104: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4058 - accuracy: 0.9767 - val_loss: 4.2224 - val_accuracy: 0.2805 - lr: 1.0000e-05\n",
      "Epoch 105/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3980 - accuracy: 0.9781\n",
      "Epoch 00105: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3980 - accuracy: 0.9781 - val_loss: 4.2478 - val_accuracy: 0.2770 - lr: 1.0000e-05\n",
      "Epoch 106/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4029 - accuracy: 0.9769\n",
      "Epoch 00106: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4029 - accuracy: 0.9769 - val_loss: 4.2718 - val_accuracy: 0.2828 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3974 - accuracy: 0.9781\n",
      "Epoch 00107: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3974 - accuracy: 0.9781 - val_loss: 4.2049 - val_accuracy: 0.2786 - lr: 1.0000e-05\n",
      "Epoch 108/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4002 - accuracy: 0.9781\n",
      "Epoch 00108: val_accuracy did not improve from 0.34706\n",
      "163/163 [==============================] - 55s 338ms/step - loss: 0.4002 - accuracy: 0.9781 - val_loss: 4.3143 - val_accuracy: 0.2824 - lr: 1.0000e-05\n",
      "epoch_number 10\n",
      "train accuracy and validation accuracy 0.4316214621067047 0.3470565676689148\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 3.0374 - accuracy: 0.3471\n",
      "test_accuracy 0.3470565676689148\n",
      "[0.3470565676689148]\n",
      "test_mean for %d subjects: 1\n",
      "0.3470565676689148\n",
      "/media/naveen/nav/mat_codes/nina_DB4_codes/naveen_prep_nlw/sub_wise_process_TT/S2_tr.csv\n",
      "Number of columns in the dataframe: 13\n",
      "Number of rows in the dataframe: 2080000\n",
      "\n",
      "/media/naveen/nav/mat_codes/nina_DB4_codes/naveen_prep_nlw/sub_wise_process_TT/S2_tt.csv\n",
      "Number of columns in the dataframe: 13\n",
      "Number of rows in the dataframe: 1040000\n",
      "\n",
      "x_train shape:  (5199, 400, 12)\n",
      "5199 training samples\n",
      "y_train shape:  (5199,)\n",
      "num_time_periods 400\n",
      "num_sensors 12\n",
      "class_list [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0]\n",
      "x_train shape: (400, 12)\n",
      "input_shape: (400, 12)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "New y_train shape:  (5199, 52)\n",
      "x_test shape:  (2599, 400, 12)\n",
      "2599 testing samples\n",
      "y_test shape:  (2599,)\n",
      "x_train shape:  (5199, 400, 12)\n",
      "x_test shape:  (2599, 400, 12)\n",
      "n_outputs 52\n",
      "Model: \"wei_mscnn_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main (InputLayer)               [(None, 400, 12)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_8 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_10 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_12 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_14 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_16 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_18 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_20 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_22 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_1 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_2 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_3 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_4 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_5 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_10[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_6 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_12[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_7 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_14[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_8 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_16[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_9 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_18[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_10 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_20[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_11 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_22[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [()]                 0           tf_op_layer_Shape_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_5 (Te [()]                 0           tf_op_layer_Shape_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_7 (Te [()]                 0           tf_op_layer_Shape_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_9 (Te [()]                 0           tf_op_layer_Shape_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_11 (T [()]                 0           tf_op_layer_Shape_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_13 (T [()]                 0           tf_op_layer_Shape_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_15 (T [()]                 0           tf_op_layer_Shape_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_17 (T [()]                 0           tf_op_layer_Shape_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_19 (T [()]                 0           tf_op_layer_Shape_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_21 (T [()]                 0           tf_op_layer_Shape_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_23 (T [()]                 0           tf_op_layer_Shape_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape/shape (Tens [(3,)]               0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1/shape (Te [(3,)]               0           tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2/shape (Te [(3,)]               0           tf_op_layer_strided_slice_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3/shape (Te [(3,)]               0           tf_op_layer_strided_slice_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4/shape (Te [(3,)]               0           tf_op_layer_strided_slice_9[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5/shape (Te [(3,)]               0           tf_op_layer_strided_slice_11[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6/shape (Te [(3,)]               0           tf_op_layer_strided_slice_13[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7/shape (Te [(3,)]               0           tf_op_layer_strided_slice_15[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8/shape (Te [(3,)]               0           tf_op_layer_strided_slice_17[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9/shape (Te [(3,)]               0           tf_op_layer_strided_slice_19[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_10/shape (T [(3,)]               0           tf_op_layer_strided_slice_21[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_11/shape (T [(3,)]               0           tf_op_layer_strided_slice_23[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 400, 1)]     0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 tf_op_layer_Reshape/shape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_2[0][0]\n",
      "                                                                 tf_op_layer_Reshape_1/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_4[0][0]\n",
      "                                                                 tf_op_layer_Reshape_2/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_6[0][0]\n",
      "                                                                 tf_op_layer_Reshape_3/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_8[0][0]\n",
      "                                                                 tf_op_layer_Reshape_4/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_10[0][0\n",
      "                                                                 tf_op_layer_Reshape_5/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_12[0][0\n",
      "                                                                 tf_op_layer_Reshape_6/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_14[0][0\n",
      "                                                                 tf_op_layer_Reshape_7/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_16[0][0\n",
      "                                                                 tf_op_layer_Reshape_8/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_18[0][0\n",
      "                                                                 tf_op_layer_Reshape_9/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_10 (TensorF [(None, 400, 1)]     0           tf_op_layer_strided_slice_20[0][0\n",
      "                                                                 tf_op_layer_Reshape_10/shape[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_11 (TensorF [(None, 400, 1)]     0           tf_op_layer_strided_slice_22[0][0\n",
      "                                                                 tf_op_layer_Reshape_11/shape[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 400, 64)      256         tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 400, 64)      256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 400, 64)      256         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 400, 64)      256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 400, 64)      256         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 400, 64)      256         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 400, 64)      256         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 400, 64)      256         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 400, 64)      256         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 400, 64)      256         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 400, 64)      256         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 400, 64)      256         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 400, 64)      256         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 400, 64)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 400, 64)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 400, 64)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 400, 64)      0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 400, 64)      0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 400, 64)      0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 400, 64)      0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 400, 64)      0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 400, 64)      0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 400, 64)      0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 400, 64)      0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 400, 64)      0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 400, 64)      12352       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 400, 64)      12352       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 400, 64)      12352       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 400, 64)      12352       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 400, 64)      12352       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 400, 64)      12352       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 400, 64)      12352       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 400, 64)      12352       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 400, 64)      12352       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 400, 64)      12352       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 400, 64)      12352       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 400, 64)      12352       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 400, 64)      256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 400, 64)      256         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 400, 64)      256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 400, 64)      256         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 400, 64)      256         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 400, 64)      256         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 400, 64)      256         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 400, 64)      256         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 400, 64)      256         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 400, 64)      256         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 400, 64)      256         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 400, 64)      256         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 400, 64)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 400, 64)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 400, 64)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 400, 64)      0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 400, 64)      0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 400, 64)      0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 400, 64)      0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 400, 64)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 400, 64)      0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 400, 64)      0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 400, 64)      0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 400, 64)      0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d (LocallyCon (None, 400, 64)      1664000     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_2 (LocallyC (None, 400, 64)      1664000     activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_4 (LocallyC (None, 400, 64)      1664000     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_6 (LocallyC (None, 400, 64)      1664000     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_8 (LocallyC (None, 400, 64)      1664000     activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_10 (Locally (None, 400, 64)      1664000     activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_12 (Locally (None, 400, 64)      1664000     activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_14 (Locally (None, 400, 64)      1664000     activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_16 (Locally (None, 400, 64)      1664000     activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_18 (Locally (None, 400, 64)      1664000     activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_20 (Locally (None, 400, 64)      1664000     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_22 (Locally (None, 400, 64)      1664000     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 400, 64)      256         locally_connected1d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 400, 64)      256         locally_connected1d_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 400, 64)      256         locally_connected1d_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 400, 64)      256         locally_connected1d_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 400, 64)      256         locally_connected1d_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 400, 64)      256         locally_connected1d_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 400, 64)      256         locally_connected1d_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 400, 64)      256         locally_connected1d_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 400, 64)      256         locally_connected1d_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 400, 64)      256         locally_connected1d_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 400, 64)      256         locally_connected1d_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 400, 64)      256         locally_connected1d_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 400, 64)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 400, 64)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 400, 64)      0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 400, 64)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 400, 64)      0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 400, 64)      0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 400, 64)      0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 400, 64)      0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 400, 64)      0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 400, 64)      0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 400, 64)      0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 400, 64)      0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_1 (LocallyC (None, 400, 64)      1664000     activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_3 (LocallyC (None, 400, 64)      1664000     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_5 (LocallyC (None, 400, 64)      1664000     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_7 (LocallyC (None, 400, 64)      1664000     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_9 (LocallyC (None, 400, 64)      1664000     activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_11 (Locally (None, 400, 64)      1664000     activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_13 (Locally (None, 400, 64)      1664000     activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_15 (Locally (None, 400, 64)      1664000     activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_17 (Locally (None, 400, 64)      1664000     activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_19 (Locally (None, 400, 64)      1664000     activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_21 (Locally (None, 400, 64)      1664000     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_23 (Locally (None, 400, 64)      1664000     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 400, 64)      256         locally_connected1d_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 400, 64)      256         locally_connected1d_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 400, 64)      256         locally_connected1d_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 400, 64)      256         locally_connected1d_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 400, 64)      256         locally_connected1d_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 400, 64)      256         locally_connected1d_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 400, 64)      256         locally_connected1d_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 400, 64)      256         locally_connected1d_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 400, 64)      256         locally_connected1d_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 400, 64)      256         locally_connected1d_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 400, 64)      256         locally_connected1d_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 400, 64)      256         locally_connected1d_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 400, 64)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 400, 64)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 400, 64)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 400, 64)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 400, 64)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 400, 64)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 400, 64)      0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 400, 64)      0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 400, 64)      0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 400, 64)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 400, 64)      0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 400, 64)      0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 400, 64)      0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 400, 64)      0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 400, 64)      0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 400, 64)      0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 400, 64)      0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 400, 64)      0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 400, 64)      0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 400, 64)      0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 400, 64)      0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 400, 64)      0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 400, 64)      0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 400, 64)      0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_stack (TensorFlowOp [(None, 400, 12, 64) 0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "                                                                 dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 307200)       0           tf_op_layer_stack[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          157286912   flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 512)          0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 512)          0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          262656      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 512)          0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 512)          0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          65664       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 128)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 128)          0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 52)           6708        activation_50[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 197,726,132\n",
      "Trainable params: 197,717,684\n",
      "Non-trainable params: 8,448\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 4.1134 - accuracy: 0.1235\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.21547, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 123s 756ms/step - loss: 4.1134 - accuracy: 0.1235 - val_loss: 3.3780 - val_accuracy: 0.2155 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.3822 - accuracy: 0.2064\n",
      "Epoch 00002: val_accuracy improved from 0.21547 to 0.24086, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 61s 374ms/step - loss: 3.3822 - accuracy: 0.2064 - val_loss: 3.2804 - val_accuracy: 0.2409 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.2493 - accuracy: 0.2539\n",
      "Epoch 00003: val_accuracy improved from 0.24086 to 0.28396, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 61s 375ms/step - loss: 3.2493 - accuracy: 0.2539 - val_loss: 3.2178 - val_accuracy: 0.2840 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.2041 - accuracy: 0.2839\n",
      "Epoch 00004: val_accuracy did not improve from 0.28396\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 3.2041 - accuracy: 0.2839 - val_loss: 3.2889 - val_accuracy: 0.2701 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.0814 - accuracy: 0.3181\n",
      "Epoch 00005: val_accuracy did not improve from 0.28396\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 3.0814 - accuracy: 0.3181 - val_loss: 3.2547 - val_accuracy: 0.2805 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.0591 - accuracy: 0.3428\n",
      "Epoch 00006: val_accuracy improved from 0.28396 to 0.29588, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 60s 370ms/step - loss: 3.0591 - accuracy: 0.3428 - val_loss: 3.2529 - val_accuracy: 0.2959 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.9880 - accuracy: 0.3518\n",
      "Epoch 00007: val_accuracy improved from 0.29588 to 0.31628, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 60s 370ms/step - loss: 2.9880 - accuracy: 0.3518 - val_loss: 3.2337 - val_accuracy: 0.3163 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.9359 - accuracy: 0.3781\n",
      "Epoch 00008: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 56s 341ms/step - loss: 2.9359 - accuracy: 0.3781 - val_loss: 3.2098 - val_accuracy: 0.3109 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.8639 - accuracy: 0.3897\n",
      "Epoch 00009: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 2.8639 - accuracy: 0.3897 - val_loss: 3.2895 - val_accuracy: 0.3159 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.7740 - accuracy: 0.4224\n",
      "Epoch 00010: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.7740 - accuracy: 0.4224 - val_loss: 3.3399 - val_accuracy: 0.3028 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.7364 - accuracy: 0.4543\n",
      "Epoch 00011: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 2.7364 - accuracy: 0.4543 - val_loss: 3.3748 - val_accuracy: 0.3078 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.6653 - accuracy: 0.4612\n",
      "Epoch 00012: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 2.6653 - accuracy: 0.4612 - val_loss: 3.4155 - val_accuracy: 0.2970 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.6086 - accuracy: 0.4849\n",
      "Epoch 00013: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 2.6086 - accuracy: 0.4849 - val_loss: 3.4370 - val_accuracy: 0.3020 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.5788 - accuracy: 0.5089\n",
      "Epoch 00014: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 2.5788 - accuracy: 0.5089 - val_loss: 3.5819 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.5272 - accuracy: 0.5139\n",
      "Epoch 00015: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 2.5272 - accuracy: 0.5139 - val_loss: 3.5861 - val_accuracy: 0.2863 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.4721 - accuracy: 0.5368\n",
      "Epoch 00016: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.4721 - accuracy: 0.5368 - val_loss: 3.6204 - val_accuracy: 0.2874 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.4301 - accuracy: 0.5574\n",
      "Epoch 00017: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 338ms/step - loss: 2.4301 - accuracy: 0.5574 - val_loss: 3.6558 - val_accuracy: 0.2936 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.3468 - accuracy: 0.5826\n",
      "Epoch 00018: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.3468 - accuracy: 0.5826 - val_loss: 3.6705 - val_accuracy: 0.2920 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.3239 - accuracy: 0.5920\n",
      "Epoch 00019: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 2.3239 - accuracy: 0.5920 - val_loss: 3.7642 - val_accuracy: 0.2974 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.2488 - accuracy: 0.6234\n",
      "Epoch 00020: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.2488 - accuracy: 0.6234 - val_loss: 3.8415 - val_accuracy: 0.2920 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.2315 - accuracy: 0.6307\n",
      "Epoch 00021: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.2315 - accuracy: 0.6307 - val_loss: 3.8295 - val_accuracy: 0.2843 - lr: 0.0010\n",
      "Epoch 22/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.1688 - accuracy: 0.6428\n",
      "Epoch 00022: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 2.1688 - accuracy: 0.6428 - val_loss: 3.9989 - val_accuracy: 0.2670 - lr: 0.0010\n",
      "Epoch 23/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.1653 - accuracy: 0.6532\n",
      "Epoch 00023: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 2.1653 - accuracy: 0.6532 - val_loss: 3.9021 - val_accuracy: 0.2897 - lr: 0.0010\n",
      "Epoch 24/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.0894 - accuracy: 0.6688\n",
      "Epoch 00024: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.0894 - accuracy: 0.6688 - val_loss: 4.0246 - val_accuracy: 0.2813 - lr: 0.0010\n",
      "Epoch 25/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.1036 - accuracy: 0.6742\n",
      "Epoch 00025: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.1036 - accuracy: 0.6742 - val_loss: 4.0553 - val_accuracy: 0.2828 - lr: 0.0010\n",
      "Epoch 26/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.0889 - accuracy: 0.6822\n",
      "Epoch 00026: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 2.0889 - accuracy: 0.6822 - val_loss: 4.1234 - val_accuracy: 0.2747 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.9961 - accuracy: 0.7028\n",
      "Epoch 00027: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.9961 - accuracy: 0.7028 - val_loss: 4.1264 - val_accuracy: 0.2863 - lr: 0.0010\n",
      "Epoch 28/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.9516 - accuracy: 0.7086\n",
      "Epoch 00028: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.9516 - accuracy: 0.7086 - val_loss: 4.0652 - val_accuracy: 0.2859 - lr: 0.0010\n",
      "Epoch 29/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.9638 - accuracy: 0.7163\n",
      "Epoch 00029: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.9638 - accuracy: 0.7163 - val_loss: 4.3025 - val_accuracy: 0.2793 - lr: 0.0010\n",
      "Epoch 30/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.9450 - accuracy: 0.7215\n",
      "Epoch 00030: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 1.9450 - accuracy: 0.7215 - val_loss: 4.2553 - val_accuracy: 0.2747 - lr: 0.0010\n",
      "Epoch 31/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.9039 - accuracy: 0.7351\n",
      "Epoch 00031: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.9039 - accuracy: 0.7351 - val_loss: 4.2650 - val_accuracy: 0.2601 - lr: 0.0010\n",
      "Epoch 32/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8589 - accuracy: 0.7434\n",
      "Epoch 00032: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.8589 - accuracy: 0.7434 - val_loss: 4.2870 - val_accuracy: 0.2840 - lr: 0.0010\n",
      "Epoch 33/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8971 - accuracy: 0.7355\n",
      "Epoch 00033: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.8971 - accuracy: 0.7355 - val_loss: 4.4592 - val_accuracy: 0.2647 - lr: 0.0010\n",
      "Epoch 34/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8767 - accuracy: 0.7530\n",
      "Epoch 00034: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.8767 - accuracy: 0.7530 - val_loss: 4.3288 - val_accuracy: 0.2751 - lr: 0.0010\n",
      "Epoch 35/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8117 - accuracy: 0.7569\n",
      "Epoch 00035: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 1.8117 - accuracy: 0.7569 - val_loss: 4.4387 - val_accuracy: 0.2636 - lr: 0.0010\n",
      "Epoch 36/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7533 - accuracy: 0.7705\n",
      "Epoch 00036: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.7533 - accuracy: 0.7705 - val_loss: 4.4463 - val_accuracy: 0.2832 - lr: 0.0010\n",
      "Epoch 37/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7480 - accuracy: 0.7682\n",
      "Epoch 00037: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 1.7480 - accuracy: 0.7682 - val_loss: 4.4039 - val_accuracy: 0.2716 - lr: 0.0010\n",
      "Epoch 38/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7876 - accuracy: 0.7796\n",
      "Epoch 00038: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.7876 - accuracy: 0.7796 - val_loss: 4.5401 - val_accuracy: 0.2674 - lr: 0.0010\n",
      "Epoch 39/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7429 - accuracy: 0.7773\n",
      "Epoch 00039: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.7429 - accuracy: 0.7773 - val_loss: 4.6271 - val_accuracy: 0.2632 - lr: 0.0010\n",
      "Epoch 40/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5944 - accuracy: 0.8182\n",
      "Epoch 00040: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.5944 - accuracy: 0.8182 - val_loss: 4.3223 - val_accuracy: 0.2759 - lr: 1.0000e-04\n",
      "Epoch 41/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4397 - accuracy: 0.8417\n",
      "Epoch 00041: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 1.4397 - accuracy: 0.8417 - val_loss: 4.2660 - val_accuracy: 0.2820 - lr: 1.0000e-04\n",
      "Epoch 42/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3403 - accuracy: 0.8617\n",
      "Epoch 00042: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.3403 - accuracy: 0.8617 - val_loss: 4.1983 - val_accuracy: 0.2790 - lr: 1.0000e-04\n",
      "Epoch 43/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.2673 - accuracy: 0.8692\n",
      "Epoch 00043: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.2673 - accuracy: 0.8692 - val_loss: 4.2453 - val_accuracy: 0.2797 - lr: 1.0000e-04\n",
      "Epoch 44/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.2293 - accuracy: 0.8698\n",
      "Epoch 00044: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.2293 - accuracy: 0.8698 - val_loss: 4.2117 - val_accuracy: 0.2732 - lr: 1.0000e-04\n",
      "Epoch 45/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.1430 - accuracy: 0.8890\n",
      "Epoch 00045: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.1430 - accuracy: 0.8890 - val_loss: 4.1641 - val_accuracy: 0.2797 - lr: 1.0000e-04\n",
      "Epoch 46/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.1213 - accuracy: 0.8840\n",
      "Epoch 00046: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 1.1213 - accuracy: 0.8840 - val_loss: 4.1201 - val_accuracy: 0.2851 - lr: 1.0000e-04\n",
      "Epoch 47/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0842 - accuracy: 0.8838\n",
      "Epoch 00047: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.0842 - accuracy: 0.8838 - val_loss: 4.1070 - val_accuracy: 0.2790 - lr: 1.0000e-04\n",
      "Epoch 48/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0454 - accuracy: 0.8881\n",
      "Epoch 00048: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.0454 - accuracy: 0.8881 - val_loss: 4.1317 - val_accuracy: 0.2770 - lr: 1.0000e-04\n",
      "Epoch 49/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0337 - accuracy: 0.8832\n",
      "Epoch 00049: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.0337 - accuracy: 0.8832 - val_loss: 4.1106 - val_accuracy: 0.2778 - lr: 1.0000e-04\n",
      "Epoch 50/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9909 - accuracy: 0.8967\n",
      "Epoch 00050: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.9909 - accuracy: 0.8967 - val_loss: 4.1279 - val_accuracy: 0.2840 - lr: 1.0000e-04\n",
      "Epoch 51/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9426 - accuracy: 0.8982\n",
      "Epoch 00051: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.9426 - accuracy: 0.8982 - val_loss: 4.1070 - val_accuracy: 0.2843 - lr: 1.0000e-04\n",
      "Epoch 52/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9361 - accuracy: 0.9013\n",
      "Epoch 00052: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.9361 - accuracy: 0.9013 - val_loss: 4.0558 - val_accuracy: 0.2755 - lr: 1.0000e-04\n",
      "Epoch 53/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9071 - accuracy: 0.9036\n",
      "Epoch 00053: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.9071 - accuracy: 0.9036 - val_loss: 4.0814 - val_accuracy: 0.2786 - lr: 1.0000e-04\n",
      "Epoch 54/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8663 - accuracy: 0.9125\n",
      "Epoch 00054: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.8663 - accuracy: 0.9125 - val_loss: 4.1459 - val_accuracy: 0.2716 - lr: 1.0000e-04\n",
      "Epoch 55/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8701 - accuracy: 0.9063\n",
      "Epoch 00055: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.8701 - accuracy: 0.9063 - val_loss: 4.0971 - val_accuracy: 0.2743 - lr: 1.0000e-04\n",
      "Epoch 56/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8341 - accuracy: 0.9115\n",
      "Epoch 00056: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.8341 - accuracy: 0.9115 - val_loss: 4.1245 - val_accuracy: 0.2778 - lr: 1.0000e-04\n",
      "Epoch 57/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8203 - accuracy: 0.9115\n",
      "Epoch 00057: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.8203 - accuracy: 0.9115 - val_loss: 4.0718 - val_accuracy: 0.2736 - lr: 1.0000e-04\n",
      "Epoch 58/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7940 - accuracy: 0.9169\n",
      "Epoch 00058: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.7940 - accuracy: 0.9169 - val_loss: 4.1165 - val_accuracy: 0.2736 - lr: 1.0000e-04\n",
      "Epoch 59/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7683 - accuracy: 0.9211\n",
      "Epoch 00059: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.7683 - accuracy: 0.9211 - val_loss: 4.0823 - val_accuracy: 0.2716 - lr: 1.0000e-04\n",
      "Epoch 60/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7669 - accuracy: 0.9146\n",
      "Epoch 00060: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 0.7669 - accuracy: 0.9146 - val_loss: 4.1013 - val_accuracy: 0.2693 - lr: 1.0000e-04\n",
      "Epoch 61/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7448 - accuracy: 0.9206\n",
      "Epoch 00061: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.7448 - accuracy: 0.9206 - val_loss: 4.1266 - val_accuracy: 0.2666 - lr: 1.0000e-04\n",
      "Epoch 62/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7318 - accuracy: 0.9208\n",
      "Epoch 00062: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.7318 - accuracy: 0.9208 - val_loss: 4.1604 - val_accuracy: 0.2778 - lr: 1.0000e-04\n",
      "Epoch 63/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7241 - accuracy: 0.9206\n",
      "Epoch 00063: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.7241 - accuracy: 0.9206 - val_loss: 4.1405 - val_accuracy: 0.2655 - lr: 1.0000e-04\n",
      "Epoch 64/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6940 - accuracy: 0.9267\n",
      "Epoch 00064: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.6940 - accuracy: 0.9267 - val_loss: 4.1363 - val_accuracy: 0.2620 - lr: 1.0000e-04\n",
      "Epoch 65/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.9256\n",
      "Epoch 00065: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.6932 - accuracy: 0.9256 - val_loss: 4.1523 - val_accuracy: 0.2693 - lr: 1.0000e-04\n",
      "Epoch 66/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6763 - accuracy: 0.9306\n",
      "Epoch 00066: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.6763 - accuracy: 0.9306 - val_loss: 4.1587 - val_accuracy: 0.2728 - lr: 1.0000e-04\n",
      "Epoch 67/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6717 - accuracy: 0.9236\n",
      "Epoch 00067: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.6717 - accuracy: 0.9236 - val_loss: 4.1353 - val_accuracy: 0.2701 - lr: 1.0000e-04\n",
      "Epoch 68/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6459 - accuracy: 0.9279\n",
      "Epoch 00068: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 0.6459 - accuracy: 0.9279 - val_loss: 4.1524 - val_accuracy: 0.2659 - lr: 1.0000e-04\n",
      "Epoch 69/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6429 - accuracy: 0.9288\n",
      "Epoch 00069: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.6429 - accuracy: 0.9288 - val_loss: 4.1649 - val_accuracy: 0.2670 - lr: 1.0000e-04\n",
      "Epoch 70/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6266 - accuracy: 0.9309\n",
      "Epoch 00070: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 0.6266 - accuracy: 0.9309 - val_loss: 4.1749 - val_accuracy: 0.2740 - lr: 1.0000e-04\n",
      "Epoch 71/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6076 - accuracy: 0.9344\n",
      "Epoch 00071: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.6076 - accuracy: 0.9344 - val_loss: 4.2558 - val_accuracy: 0.2682 - lr: 1.0000e-04\n",
      "Epoch 72/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5941 - accuracy: 0.9415\n",
      "Epoch 00072: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.5941 - accuracy: 0.9415 - val_loss: 4.1841 - val_accuracy: 0.2666 - lr: 1.0000e-04\n",
      "Epoch 73/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5813 - accuracy: 0.9413\n",
      "Epoch 00073: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.5813 - accuracy: 0.9413 - val_loss: 4.1714 - val_accuracy: 0.2713 - lr: 1.0000e-04\n",
      "Epoch 74/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5815 - accuracy: 0.9398\n",
      "Epoch 00074: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.5815 - accuracy: 0.9398 - val_loss: 4.2064 - val_accuracy: 0.2709 - lr: 1.0000e-04\n",
      "Epoch 75/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5584 - accuracy: 0.9454\n",
      "Epoch 00075: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.5584 - accuracy: 0.9454 - val_loss: 4.2098 - val_accuracy: 0.2686 - lr: 1.0000e-04\n",
      "Epoch 76/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5573 - accuracy: 0.9461\n",
      "Epoch 00076: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.5573 - accuracy: 0.9461 - val_loss: 4.2820 - val_accuracy: 0.2663 - lr: 1.0000e-04\n",
      "Epoch 77/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5337 - accuracy: 0.9473\n",
      "Epoch 00077: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.5337 - accuracy: 0.9473 - val_loss: 4.3001 - val_accuracy: 0.2666 - lr: 1.0000e-04\n",
      "Epoch 78/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5391 - accuracy: 0.9494\n",
      "Epoch 00078: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.5391 - accuracy: 0.9494 - val_loss: 4.2575 - val_accuracy: 0.2689 - lr: 1.0000e-04\n",
      "Epoch 79/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5443 - accuracy: 0.9452\n",
      "Epoch 00079: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.5443 - accuracy: 0.9452 - val_loss: 4.2618 - val_accuracy: 0.2628 - lr: 1.0000e-04\n",
      "Epoch 80/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5345 - accuracy: 0.9456\n",
      "Epoch 00080: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.5345 - accuracy: 0.9456 - val_loss: 4.2777 - val_accuracy: 0.2666 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5199 - accuracy: 0.9492\n",
      "Epoch 00081: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.5199 - accuracy: 0.9492 - val_loss: 4.2266 - val_accuracy: 0.2639 - lr: 1.0000e-05\n",
      "Epoch 82/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5112 - accuracy: 0.9527\n",
      "Epoch 00082: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.5112 - accuracy: 0.9527 - val_loss: 4.2504 - val_accuracy: 0.2682 - lr: 1.0000e-05\n",
      "Epoch 83/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5116 - accuracy: 0.9517\n",
      "Epoch 00083: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.5116 - accuracy: 0.9517 - val_loss: 4.2416 - val_accuracy: 0.2674 - lr: 1.0000e-05\n",
      "Epoch 84/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5121 - accuracy: 0.9554\n",
      "Epoch 00084: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 0.5121 - accuracy: 0.9554 - val_loss: 4.2591 - val_accuracy: 0.2686 - lr: 1.0000e-05\n",
      "Epoch 85/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5219 - accuracy: 0.9456\n",
      "Epoch 00085: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.5219 - accuracy: 0.9456 - val_loss: 4.2813 - val_accuracy: 0.2639 - lr: 1.0000e-05\n",
      "Epoch 86/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5103 - accuracy: 0.9504\n",
      "Epoch 00086: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.5103 - accuracy: 0.9504 - val_loss: 4.2468 - val_accuracy: 0.2651 - lr: 1.0000e-05\n",
      "Epoch 87/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5123 - accuracy: 0.9519\n",
      "Epoch 00087: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.5123 - accuracy: 0.9519 - val_loss: 4.2879 - val_accuracy: 0.2651 - lr: 1.0000e-05\n",
      "Epoch 88/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5134 - accuracy: 0.9496\n",
      "Epoch 00088: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.5134 - accuracy: 0.9496 - val_loss: 4.2433 - val_accuracy: 0.2628 - lr: 1.0000e-05\n",
      "Epoch 89/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4908 - accuracy: 0.9585\n",
      "Epoch 00089: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.4908 - accuracy: 0.9585 - val_loss: 4.3254 - val_accuracy: 0.2674 - lr: 1.0000e-05\n",
      "Epoch 90/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4964 - accuracy: 0.9561\n",
      "Epoch 00090: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4964 - accuracy: 0.9561 - val_loss: 4.3022 - val_accuracy: 0.2632 - lr: 1.0000e-05\n",
      "Epoch 91/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4940 - accuracy: 0.9544\n",
      "Epoch 00091: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4940 - accuracy: 0.9544 - val_loss: 4.2579 - val_accuracy: 0.2609 - lr: 1.0000e-05\n",
      "Epoch 92/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4895 - accuracy: 0.9571\n",
      "Epoch 00092: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4895 - accuracy: 0.9571 - val_loss: 4.2547 - val_accuracy: 0.2613 - lr: 1.0000e-05\n",
      "Epoch 93/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4893 - accuracy: 0.9594\n",
      "Epoch 00093: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4893 - accuracy: 0.9594 - val_loss: 4.2559 - val_accuracy: 0.2624 - lr: 1.0000e-05\n",
      "Epoch 94/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4981 - accuracy: 0.9510\n",
      "Epoch 00094: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4981 - accuracy: 0.9510 - val_loss: 4.3012 - val_accuracy: 0.2620 - lr: 1.0000e-05\n",
      "Epoch 95/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4883 - accuracy: 0.9542\n",
      "Epoch 00095: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4883 - accuracy: 0.9542 - val_loss: 4.3018 - val_accuracy: 0.2639 - lr: 1.0000e-05\n",
      "Epoch 96/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4946 - accuracy: 0.9515\n",
      "Epoch 00096: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 0.4946 - accuracy: 0.9515 - val_loss: 4.2962 - val_accuracy: 0.2616 - lr: 1.0000e-05\n",
      "Epoch 97/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4828 - accuracy: 0.9594\n",
      "Epoch 00097: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4828 - accuracy: 0.9594 - val_loss: 4.2640 - val_accuracy: 0.2639 - lr: 1.0000e-05\n",
      "Epoch 98/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4903 - accuracy: 0.9523\n",
      "Epoch 00098: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4903 - accuracy: 0.9523 - val_loss: 4.2969 - val_accuracy: 0.2639 - lr: 1.0000e-05\n",
      "Epoch 99/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4869 - accuracy: 0.9596\n",
      "Epoch 00099: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4869 - accuracy: 0.9596 - val_loss: 4.3124 - val_accuracy: 0.2647 - lr: 1.0000e-05\n",
      "Epoch 100/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4821 - accuracy: 0.9552\n",
      "Epoch 00100: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4821 - accuracy: 0.9552 - val_loss: 4.2907 - val_accuracy: 0.2643 - lr: 1.0000e-05\n",
      "Epoch 101/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4822 - accuracy: 0.9581\n",
      "Epoch 00101: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4822 - accuracy: 0.9581 - val_loss: 4.2812 - val_accuracy: 0.2616 - lr: 1.0000e-05\n",
      "Epoch 102/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4707 - accuracy: 0.9636\n",
      "Epoch 00102: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4707 - accuracy: 0.9636 - val_loss: 4.3115 - val_accuracy: 0.2663 - lr: 1.0000e-05\n",
      "Epoch 103/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4825 - accuracy: 0.9575\n",
      "Epoch 00103: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4825 - accuracy: 0.9575 - val_loss: 4.2613 - val_accuracy: 0.2655 - lr: 1.0000e-05\n",
      "Epoch 104/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4826 - accuracy: 0.9536\n",
      "Epoch 00104: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4826 - accuracy: 0.9536 - val_loss: 4.3111 - val_accuracy: 0.2616 - lr: 1.0000e-05\n",
      "Epoch 105/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4890 - accuracy: 0.9540\n",
      "Epoch 00105: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4890 - accuracy: 0.9540 - val_loss: 4.2471 - val_accuracy: 0.2620 - lr: 1.0000e-05\n",
      "Epoch 106/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4819 - accuracy: 0.9544\n",
      "Epoch 00106: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4819 - accuracy: 0.9544 - val_loss: 4.2832 - val_accuracy: 0.2651 - lr: 1.0000e-05\n",
      "Epoch 107/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4662 - accuracy: 0.9615\n",
      "Epoch 00107: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4662 - accuracy: 0.9615 - val_loss: 4.2466 - val_accuracy: 0.2666 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4824 - accuracy: 0.9544\n",
      "Epoch 00108: val_accuracy did not improve from 0.31628\n",
      "163/163 [==============================] - 55s 339ms/step - loss: 0.4824 - accuracy: 0.9544 - val_loss: 4.2379 - val_accuracy: 0.2636 - lr: 1.0000e-05\n",
      "epoch_number 7\n",
      "train accuracy and validation accuracy 0.351798415184021 0.3162754774093628\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 3.2337 - accuracy: 0.3163\n",
      "test_accuracy 0.3162754774093628\n",
      "[0.3470565676689148, 0.3162754774093628]\n",
      "test_mean for %d subjects: 2\n",
      "0.3316660225391388\n",
      "/media/naveen/nav/mat_codes/nina_DB4_codes/naveen_prep_nlw/sub_wise_process_TT/S3_tr.csv\n",
      "Number of columns in the dataframe: 13\n",
      "Number of rows in the dataframe: 2080000\n",
      "\n",
      "/media/naveen/nav/mat_codes/nina_DB4_codes/naveen_prep_nlw/sub_wise_process_TT/S3_tt.csv\n",
      "Number of columns in the dataframe: 13\n",
      "Number of rows in the dataframe: 1040000\n",
      "\n",
      "x_train shape:  (5199, 400, 12)\n",
      "5199 training samples\n",
      "y_train shape:  (5199,)\n",
      "num_time_periods 400\n",
      "num_sensors 12\n",
      "class_list [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0]\n",
      "x_train shape: (400, 12)\n",
      "input_shape: (400, 12)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "New y_train shape:  (5199, 52)\n",
      "x_test shape:  (2599, 400, 12)\n",
      "2599 testing samples\n",
      "y_test shape:  (2599,)\n",
      "x_train shape:  (5199, 400, 12)\n",
      "x_test shape:  (2599, 400, 12)\n",
      "n_outputs 52\n",
      "Model: \"wei_mscnn_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main (InputLayer)               [(None, 400, 12)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_8 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_10 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_12 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_14 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_16 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_18 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_20 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_22 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_1 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_2 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_3 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_4 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_5 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_10[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_6 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_12[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_7 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_14[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_8 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_16[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_9 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_18[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_10 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_20[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_11 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_22[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [()]                 0           tf_op_layer_Shape_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_5 (Te [()]                 0           tf_op_layer_Shape_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_7 (Te [()]                 0           tf_op_layer_Shape_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_9 (Te [()]                 0           tf_op_layer_Shape_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_11 (T [()]                 0           tf_op_layer_Shape_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_13 (T [()]                 0           tf_op_layer_Shape_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_15 (T [()]                 0           tf_op_layer_Shape_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_17 (T [()]                 0           tf_op_layer_Shape_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_19 (T [()]                 0           tf_op_layer_Shape_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_21 (T [()]                 0           tf_op_layer_Shape_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_23 (T [()]                 0           tf_op_layer_Shape_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape/shape (Tens [(3,)]               0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1/shape (Te [(3,)]               0           tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2/shape (Te [(3,)]               0           tf_op_layer_strided_slice_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3/shape (Te [(3,)]               0           tf_op_layer_strided_slice_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4/shape (Te [(3,)]               0           tf_op_layer_strided_slice_9[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5/shape (Te [(3,)]               0           tf_op_layer_strided_slice_11[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6/shape (Te [(3,)]               0           tf_op_layer_strided_slice_13[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7/shape (Te [(3,)]               0           tf_op_layer_strided_slice_15[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8/shape (Te [(3,)]               0           tf_op_layer_strided_slice_17[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9/shape (Te [(3,)]               0           tf_op_layer_strided_slice_19[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_10/shape (T [(3,)]               0           tf_op_layer_strided_slice_21[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_11/shape (T [(3,)]               0           tf_op_layer_strided_slice_23[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 400, 1)]     0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 tf_op_layer_Reshape/shape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_2[0][0]\n",
      "                                                                 tf_op_layer_Reshape_1/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_4[0][0]\n",
      "                                                                 tf_op_layer_Reshape_2/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_6[0][0]\n",
      "                                                                 tf_op_layer_Reshape_3/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_8[0][0]\n",
      "                                                                 tf_op_layer_Reshape_4/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_10[0][0\n",
      "                                                                 tf_op_layer_Reshape_5/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_12[0][0\n",
      "                                                                 tf_op_layer_Reshape_6/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_14[0][0\n",
      "                                                                 tf_op_layer_Reshape_7/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_16[0][0\n",
      "                                                                 tf_op_layer_Reshape_8/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_18[0][0\n",
      "                                                                 tf_op_layer_Reshape_9/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_10 (TensorF [(None, 400, 1)]     0           tf_op_layer_strided_slice_20[0][0\n",
      "                                                                 tf_op_layer_Reshape_10/shape[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_11 (TensorF [(None, 400, 1)]     0           tf_op_layer_strided_slice_22[0][0\n",
      "                                                                 tf_op_layer_Reshape_11/shape[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 400, 64)      256         tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 400, 64)      256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 400, 64)      256         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 400, 64)      256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 400, 64)      256         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 400, 64)      256         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 400, 64)      256         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 400, 64)      256         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 400, 64)      256         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 400, 64)      256         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 400, 64)      256         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 400, 64)      256         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 400, 64)      256         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 400, 64)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 400, 64)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 400, 64)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 400, 64)      0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 400, 64)      0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 400, 64)      0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 400, 64)      0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 400, 64)      0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 400, 64)      0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 400, 64)      0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 400, 64)      0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 400, 64)      0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 400, 64)      12352       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 400, 64)      12352       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 400, 64)      12352       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 400, 64)      12352       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 400, 64)      12352       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 400, 64)      12352       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 400, 64)      12352       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 400, 64)      12352       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 400, 64)      12352       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 400, 64)      12352       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 400, 64)      12352       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 400, 64)      12352       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 400, 64)      256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 400, 64)      256         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 400, 64)      256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 400, 64)      256         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 400, 64)      256         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 400, 64)      256         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 400, 64)      256         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 400, 64)      256         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 400, 64)      256         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 400, 64)      256         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 400, 64)      256         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 400, 64)      256         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 400, 64)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 400, 64)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 400, 64)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 400, 64)      0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 400, 64)      0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 400, 64)      0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 400, 64)      0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 400, 64)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 400, 64)      0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 400, 64)      0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 400, 64)      0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 400, 64)      0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d (LocallyCon (None, 400, 64)      1664000     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_2 (LocallyC (None, 400, 64)      1664000     activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_4 (LocallyC (None, 400, 64)      1664000     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_6 (LocallyC (None, 400, 64)      1664000     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_8 (LocallyC (None, 400, 64)      1664000     activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_10 (Locally (None, 400, 64)      1664000     activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_12 (Locally (None, 400, 64)      1664000     activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_14 (Locally (None, 400, 64)      1664000     activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_16 (Locally (None, 400, 64)      1664000     activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_18 (Locally (None, 400, 64)      1664000     activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_20 (Locally (None, 400, 64)      1664000     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_22 (Locally (None, 400, 64)      1664000     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 400, 64)      256         locally_connected1d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 400, 64)      256         locally_connected1d_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 400, 64)      256         locally_connected1d_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 400, 64)      256         locally_connected1d_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 400, 64)      256         locally_connected1d_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 400, 64)      256         locally_connected1d_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 400, 64)      256         locally_connected1d_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 400, 64)      256         locally_connected1d_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 400, 64)      256         locally_connected1d_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 400, 64)      256         locally_connected1d_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 400, 64)      256         locally_connected1d_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 400, 64)      256         locally_connected1d_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 400, 64)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 400, 64)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 400, 64)      0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 400, 64)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 400, 64)      0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 400, 64)      0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 400, 64)      0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 400, 64)      0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 400, 64)      0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 400, 64)      0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 400, 64)      0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 400, 64)      0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_1 (LocallyC (None, 400, 64)      1664000     activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_3 (LocallyC (None, 400, 64)      1664000     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_5 (LocallyC (None, 400, 64)      1664000     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_7 (LocallyC (None, 400, 64)      1664000     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_9 (LocallyC (None, 400, 64)      1664000     activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_11 (Locally (None, 400, 64)      1664000     activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_13 (Locally (None, 400, 64)      1664000     activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_15 (Locally (None, 400, 64)      1664000     activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_17 (Locally (None, 400, 64)      1664000     activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_19 (Locally (None, 400, 64)      1664000     activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_21 (Locally (None, 400, 64)      1664000     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_23 (Locally (None, 400, 64)      1664000     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 400, 64)      256         locally_connected1d_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 400, 64)      256         locally_connected1d_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 400, 64)      256         locally_connected1d_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 400, 64)      256         locally_connected1d_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 400, 64)      256         locally_connected1d_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 400, 64)      256         locally_connected1d_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 400, 64)      256         locally_connected1d_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 400, 64)      256         locally_connected1d_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 400, 64)      256         locally_connected1d_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 400, 64)      256         locally_connected1d_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 400, 64)      256         locally_connected1d_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 400, 64)      256         locally_connected1d_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 400, 64)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 400, 64)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 400, 64)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 400, 64)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 400, 64)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 400, 64)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 400, 64)      0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 400, 64)      0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 400, 64)      0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 400, 64)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 400, 64)      0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 400, 64)      0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 400, 64)      0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 400, 64)      0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 400, 64)      0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 400, 64)      0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 400, 64)      0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 400, 64)      0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 400, 64)      0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 400, 64)      0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 400, 64)      0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 400, 64)      0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 400, 64)      0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 400, 64)      0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_stack (TensorFlowOp [(None, 400, 12, 64) 0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "                                                                 dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 307200)       0           tf_op_layer_stack[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          157286912   flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 512)          0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 512)          0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          262656      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 512)          0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 512)          0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          65664       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 128)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 128)          0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 52)           6708        activation_50[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 197,726,132\n",
      "Trainable params: 197,717,684\n",
      "Non-trainable params: 8,448\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - ETA: 0s - loss: 4.0066 - accuracy: 0.1287\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.22162, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 127s 776ms/step - loss: 4.0066 - accuracy: 0.1287 - val_loss: 3.2364 - val_accuracy: 0.2216 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.3139 - accuracy: 0.2189\n",
      "Epoch 00002: val_accuracy improved from 0.22162 to 0.25317, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 61s 372ms/step - loss: 3.3139 - accuracy: 0.2189 - val_loss: 3.1514 - val_accuracy: 0.2532 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.1747 - accuracy: 0.2745\n",
      "Epoch 00003: val_accuracy improved from 0.25317 to 0.28973, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 62s 381ms/step - loss: 3.1747 - accuracy: 0.2745 - val_loss: 3.1254 - val_accuracy: 0.2897 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.0945 - accuracy: 0.3128\n",
      "Epoch 00004: val_accuracy improved from 0.28973 to 0.29704, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 60s 369ms/step - loss: 3.0945 - accuracy: 0.3128 - val_loss: 3.1612 - val_accuracy: 0.2970 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.0093 - accuracy: 0.3381\n",
      "Epoch 00005: val_accuracy improved from 0.29704 to 0.30781, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 60s 370ms/step - loss: 3.0093 - accuracy: 0.3381 - val_loss: 3.1478 - val_accuracy: 0.3078 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.8959 - accuracy: 0.3699\n",
      "Epoch 00006: val_accuracy did not improve from 0.30781\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 2.8959 - accuracy: 0.3699 - val_loss: 3.2446 - val_accuracy: 0.2851 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.8584 - accuracy: 0.4076\n",
      "Epoch 00007: val_accuracy did not improve from 0.30781\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.8584 - accuracy: 0.4076 - val_loss: 3.2064 - val_accuracy: 0.3028 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.7564 - accuracy: 0.4280\n",
      "Epoch 00008: val_accuracy improved from 0.30781 to 0.30973, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 60s 369ms/step - loss: 2.7564 - accuracy: 0.4280 - val_loss: 3.2920 - val_accuracy: 0.3097 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.7253 - accuracy: 0.4601\n",
      "Epoch 00009: val_accuracy did not improve from 0.30973\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.7253 - accuracy: 0.4601 - val_loss: 3.3405 - val_accuracy: 0.2993 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.6427 - accuracy: 0.4801\n",
      "Epoch 00010: val_accuracy did not improve from 0.30973\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 2.6427 - accuracy: 0.4801 - val_loss: 3.3807 - val_accuracy: 0.3070 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.5763 - accuracy: 0.5118\n",
      "Epoch 00011: val_accuracy did not improve from 0.30973\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.5763 - accuracy: 0.5118 - val_loss: 3.4682 - val_accuracy: 0.3078 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.4708 - accuracy: 0.5465\n",
      "Epoch 00012: val_accuracy did not improve from 0.30973\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.4708 - accuracy: 0.5465 - val_loss: 3.5245 - val_accuracy: 0.3055 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.4174 - accuracy: 0.5632\n",
      "Epoch 00013: val_accuracy improved from 0.30973 to 0.31666, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 60s 368ms/step - loss: 2.4174 - accuracy: 0.5632 - val_loss: 3.5372 - val_accuracy: 0.3167 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.4045 - accuracy: 0.5766\n",
      "Epoch 00014: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 2.4045 - accuracy: 0.5766 - val_loss: 3.6474 - val_accuracy: 0.3082 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.2877 - accuracy: 0.6059\n",
      "Epoch 00015: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.2877 - accuracy: 0.6059 - val_loss: 3.6629 - val_accuracy: 0.3093 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.2976 - accuracy: 0.6143\n",
      "Epoch 00016: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.2976 - accuracy: 0.6143 - val_loss: 3.7401 - val_accuracy: 0.3059 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.1940 - accuracy: 0.6526\n",
      "Epoch 00017: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.1940 - accuracy: 0.6526 - val_loss: 3.8371 - val_accuracy: 0.2874 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.1346 - accuracy: 0.6646\n",
      "Epoch 00018: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.1346 - accuracy: 0.6646 - val_loss: 3.8554 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.1150 - accuracy: 0.6792\n",
      "Epoch 00019: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.1150 - accuracy: 0.6792 - val_loss: 3.9323 - val_accuracy: 0.2882 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.0211 - accuracy: 0.6997\n",
      "Epoch 00020: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 2.0211 - accuracy: 0.6997 - val_loss: 3.9166 - val_accuracy: 0.2947 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.0264 - accuracy: 0.7030\n",
      "Epoch 00021: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 2.0264 - accuracy: 0.7030 - val_loss: 4.0321 - val_accuracy: 0.2870 - lr: 0.0010\n",
      "Epoch 22/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.0198 - accuracy: 0.7153\n",
      "Epoch 00022: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 2.0198 - accuracy: 0.7153 - val_loss: 4.2495 - val_accuracy: 0.2651 - lr: 0.0010\n",
      "Epoch 23/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.9313 - accuracy: 0.7326\n",
      "Epoch 00023: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.9313 - accuracy: 0.7326 - val_loss: 4.0866 - val_accuracy: 0.3017 - lr: 0.0010\n",
      "Epoch 24/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8571 - accuracy: 0.7584\n",
      "Epoch 00024: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.8571 - accuracy: 0.7584 - val_loss: 4.1129 - val_accuracy: 0.2913 - lr: 0.0010\n",
      "Epoch 25/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8805 - accuracy: 0.7542\n",
      "Epoch 00025: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.8805 - accuracy: 0.7542 - val_loss: 4.3221 - val_accuracy: 0.2993 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8392 - accuracy: 0.7755\n",
      "Epoch 00026: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.8392 - accuracy: 0.7755 - val_loss: 4.2893 - val_accuracy: 0.2751 - lr: 0.0010\n",
      "Epoch 27/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7295 - accuracy: 0.7915\n",
      "Epoch 00027: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.7295 - accuracy: 0.7915 - val_loss: 4.3289 - val_accuracy: 0.2901 - lr: 0.0010\n",
      "Epoch 28/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7425 - accuracy: 0.7948\n",
      "Epoch 00028: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.7425 - accuracy: 0.7948 - val_loss: 4.2990 - val_accuracy: 0.2863 - lr: 0.0010\n",
      "Epoch 29/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7381 - accuracy: 0.7990\n",
      "Epoch 00029: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.7381 - accuracy: 0.7990 - val_loss: 4.4315 - val_accuracy: 0.2820 - lr: 0.0010\n",
      "Epoch 30/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7187 - accuracy: 0.8042\n",
      "Epoch 00030: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.7187 - accuracy: 0.8042 - val_loss: 4.4019 - val_accuracy: 0.2816 - lr: 0.0010\n",
      "Epoch 31/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7370 - accuracy: 0.8025\n",
      "Epoch 00031: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.7370 - accuracy: 0.8025 - val_loss: 4.5462 - val_accuracy: 0.2751 - lr: 0.0010\n",
      "Epoch 32/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6817 - accuracy: 0.8163\n",
      "Epoch 00032: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.6817 - accuracy: 0.8163 - val_loss: 4.5717 - val_accuracy: 0.2663 - lr: 0.0010\n",
      "Epoch 33/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6333 - accuracy: 0.8248\n",
      "Epoch 00033: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.6333 - accuracy: 0.8248 - val_loss: 4.5578 - val_accuracy: 0.2655 - lr: 0.0010\n",
      "Epoch 34/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5844 - accuracy: 0.8344\n",
      "Epoch 00034: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.5844 - accuracy: 0.8344 - val_loss: 4.5246 - val_accuracy: 0.2828 - lr: 0.0010\n",
      "Epoch 35/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5560 - accuracy: 0.8427\n",
      "Epoch 00035: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.5560 - accuracy: 0.8427 - val_loss: 4.5842 - val_accuracy: 0.2759 - lr: 0.0010\n",
      "Epoch 36/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5879 - accuracy: 0.8419\n",
      "Epoch 00036: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.5879 - accuracy: 0.8419 - val_loss: 4.7878 - val_accuracy: 0.2528 - lr: 0.0010\n",
      "Epoch 37/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5964 - accuracy: 0.8427\n",
      "Epoch 00037: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 1.5964 - accuracy: 0.8427 - val_loss: 4.7237 - val_accuracy: 0.2786 - lr: 0.0010\n",
      "Epoch 38/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5898 - accuracy: 0.8400\n",
      "Epoch 00038: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.5898 - accuracy: 0.8400 - val_loss: 4.6354 - val_accuracy: 0.2759 - lr: 0.0010\n",
      "Epoch 39/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4271 - accuracy: 0.8663\n",
      "Epoch 00039: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.4271 - accuracy: 0.8663 - val_loss: 4.6529 - val_accuracy: 0.2655 - lr: 0.0010\n",
      "Epoch 40/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.2405 - accuracy: 0.9017\n",
      "Epoch 00040: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.2405 - accuracy: 0.9017 - val_loss: 4.4461 - val_accuracy: 0.2893 - lr: 1.0000e-04\n",
      "Epoch 41/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.1423 - accuracy: 0.9175\n",
      "Epoch 00041: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.1423 - accuracy: 0.9175 - val_loss: 4.4163 - val_accuracy: 0.2728 - lr: 1.0000e-04\n",
      "Epoch 42/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0772 - accuracy: 0.9265\n",
      "Epoch 00042: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.0772 - accuracy: 0.9265 - val_loss: 4.3752 - val_accuracy: 0.2809 - lr: 1.0000e-04\n",
      "Epoch 43/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0307 - accuracy: 0.9331\n",
      "Epoch 00043: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.0307 - accuracy: 0.9331 - val_loss: 4.3274 - val_accuracy: 0.2828 - lr: 1.0000e-04\n",
      "Epoch 44/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9793 - accuracy: 0.9352\n",
      "Epoch 00044: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.9793 - accuracy: 0.9352 - val_loss: 4.3223 - val_accuracy: 0.2836 - lr: 1.0000e-04\n",
      "Epoch 45/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9337 - accuracy: 0.9465\n",
      "Epoch 00045: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.9337 - accuracy: 0.9465 - val_loss: 4.2952 - val_accuracy: 0.2766 - lr: 1.0000e-04\n",
      "Epoch 46/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9182 - accuracy: 0.9396\n",
      "Epoch 00046: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.9182 - accuracy: 0.9396 - val_loss: 4.2973 - val_accuracy: 0.2836 - lr: 1.0000e-04\n",
      "Epoch 47/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8590 - accuracy: 0.9529\n",
      "Epoch 00047: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.8590 - accuracy: 0.9529 - val_loss: 4.2740 - val_accuracy: 0.2782 - lr: 1.0000e-04\n",
      "Epoch 48/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8381 - accuracy: 0.9504\n",
      "Epoch 00048: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.8381 - accuracy: 0.9504 - val_loss: 4.2995 - val_accuracy: 0.2770 - lr: 1.0000e-04\n",
      "Epoch 49/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8141 - accuracy: 0.9471\n",
      "Epoch 00049: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.8141 - accuracy: 0.9471 - val_loss: 4.2494 - val_accuracy: 0.2747 - lr: 1.0000e-04\n",
      "Epoch 50/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7944 - accuracy: 0.9525\n",
      "Epoch 00050: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.7944 - accuracy: 0.9525 - val_loss: 4.2534 - val_accuracy: 0.2809 - lr: 1.0000e-04\n",
      "Epoch 51/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7633 - accuracy: 0.9538\n",
      "Epoch 00051: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.7633 - accuracy: 0.9538 - val_loss: 4.2643 - val_accuracy: 0.2720 - lr: 1.0000e-04\n",
      "Epoch 52/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7389 - accuracy: 0.9552\n",
      "Epoch 00052: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.7389 - accuracy: 0.9552 - val_loss: 4.2386 - val_accuracy: 0.2763 - lr: 1.0000e-04\n",
      "Epoch 53/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7124 - accuracy: 0.9575\n",
      "Epoch 00053: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.7124 - accuracy: 0.9575 - val_loss: 4.2162 - val_accuracy: 0.2816 - lr: 1.0000e-04\n",
      "Epoch 54/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6856 - accuracy: 0.9613\n",
      "Epoch 00054: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.6856 - accuracy: 0.9613 - val_loss: 4.2179 - val_accuracy: 0.2736 - lr: 1.0000e-04\n",
      "Epoch 55/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6687 - accuracy: 0.9610\n",
      "Epoch 00055: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.6687 - accuracy: 0.9610 - val_loss: 4.1849 - val_accuracy: 0.2747 - lr: 1.0000e-04\n",
      "Epoch 56/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6569 - accuracy: 0.9588\n",
      "Epoch 00056: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.6569 - accuracy: 0.9588 - val_loss: 4.1797 - val_accuracy: 0.2724 - lr: 1.0000e-04\n",
      "Epoch 57/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6309 - accuracy: 0.9679\n",
      "Epoch 00057: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.6309 - accuracy: 0.9679 - val_loss: 4.1975 - val_accuracy: 0.2670 - lr: 1.0000e-04\n",
      "Epoch 58/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6156 - accuracy: 0.9652\n",
      "Epoch 00058: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.6156 - accuracy: 0.9652 - val_loss: 4.2057 - val_accuracy: 0.2670 - lr: 1.0000e-04\n",
      "Epoch 59/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5859 - accuracy: 0.9711\n",
      "Epoch 00059: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.5859 - accuracy: 0.9711 - val_loss: 4.2295 - val_accuracy: 0.2709 - lr: 1.0000e-04\n",
      "Epoch 60/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5907 - accuracy: 0.9619\n",
      "Epoch 00060: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.5907 - accuracy: 0.9619 - val_loss: 4.1708 - val_accuracy: 0.2686 - lr: 1.0000e-04\n",
      "Epoch 61/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5748 - accuracy: 0.9660\n",
      "Epoch 00061: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.5748 - accuracy: 0.9660 - val_loss: 4.1867 - val_accuracy: 0.2659 - lr: 1.0000e-04\n",
      "Epoch 62/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5545 - accuracy: 0.9704\n",
      "Epoch 00062: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.5545 - accuracy: 0.9704 - val_loss: 4.1992 - val_accuracy: 0.2736 - lr: 1.0000e-04\n",
      "Epoch 63/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5435 - accuracy: 0.9690\n",
      "Epoch 00063: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.5435 - accuracy: 0.9690 - val_loss: 4.2054 - val_accuracy: 0.2659 - lr: 1.0000e-04\n",
      "Epoch 64/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5396 - accuracy: 0.9654\n",
      "Epoch 00064: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.5396 - accuracy: 0.9654 - val_loss: 4.1901 - val_accuracy: 0.2720 - lr: 1.0000e-04\n",
      "Epoch 65/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5249 - accuracy: 0.9702\n",
      "Epoch 00065: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.5249 - accuracy: 0.9702 - val_loss: 4.1803 - val_accuracy: 0.2724 - lr: 1.0000e-04\n",
      "Epoch 66/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5126 - accuracy: 0.9688\n",
      "Epoch 00066: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.5126 - accuracy: 0.9688 - val_loss: 4.2140 - val_accuracy: 0.2709 - lr: 1.0000e-04\n",
      "Epoch 67/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4983 - accuracy: 0.9681\n",
      "Epoch 00067: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4983 - accuracy: 0.9681 - val_loss: 4.1852 - val_accuracy: 0.2705 - lr: 1.0000e-04\n",
      "Epoch 68/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4908 - accuracy: 0.9698\n",
      "Epoch 00068: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4908 - accuracy: 0.9698 - val_loss: 4.2567 - val_accuracy: 0.2666 - lr: 1.0000e-04\n",
      "Epoch 69/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4791 - accuracy: 0.9733\n",
      "Epoch 00069: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4791 - accuracy: 0.9733 - val_loss: 4.2393 - val_accuracy: 0.2647 - lr: 1.0000e-04\n",
      "Epoch 70/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4689 - accuracy: 0.9721\n",
      "Epoch 00070: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.4689 - accuracy: 0.9721 - val_loss: 4.2225 - val_accuracy: 0.2709 - lr: 1.0000e-04\n",
      "Epoch 71/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4608 - accuracy: 0.9729\n",
      "Epoch 00071: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4608 - accuracy: 0.9729 - val_loss: 4.2125 - val_accuracy: 0.2693 - lr: 1.0000e-04\n",
      "Epoch 72/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4502 - accuracy: 0.9746\n",
      "Epoch 00072: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4502 - accuracy: 0.9746 - val_loss: 4.2317 - val_accuracy: 0.2663 - lr: 1.0000e-04\n",
      "Epoch 73/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4369 - accuracy: 0.9754\n",
      "Epoch 00073: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4369 - accuracy: 0.9754 - val_loss: 4.2506 - val_accuracy: 0.2701 - lr: 1.0000e-04\n",
      "Epoch 74/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4426 - accuracy: 0.9713\n",
      "Epoch 00074: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4426 - accuracy: 0.9713 - val_loss: 4.2418 - val_accuracy: 0.2732 - lr: 1.0000e-04\n",
      "Epoch 75/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4268 - accuracy: 0.9744\n",
      "Epoch 00075: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4268 - accuracy: 0.9744 - val_loss: 4.2288 - val_accuracy: 0.2686 - lr: 1.0000e-04\n",
      "Epoch 76/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4216 - accuracy: 0.9725\n",
      "Epoch 00076: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4216 - accuracy: 0.9725 - val_loss: 4.2771 - val_accuracy: 0.2674 - lr: 1.0000e-04\n",
      "Epoch 77/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4209 - accuracy: 0.9729\n",
      "Epoch 00077: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4209 - accuracy: 0.9729 - val_loss: 4.2615 - val_accuracy: 0.2701 - lr: 1.0000e-04\n",
      "Epoch 78/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4092 - accuracy: 0.9736\n",
      "Epoch 00078: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4092 - accuracy: 0.9736 - val_loss: 4.2855 - val_accuracy: 0.2759 - lr: 1.0000e-04\n",
      "Epoch 79/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3921 - accuracy: 0.9794\n",
      "Epoch 00079: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3921 - accuracy: 0.9794 - val_loss: 4.3126 - val_accuracy: 0.2724 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3944 - accuracy: 0.9763\n",
      "Epoch 00080: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3944 - accuracy: 0.9763 - val_loss: 4.2578 - val_accuracy: 0.2682 - lr: 1.0000e-05\n",
      "Epoch 81/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3906 - accuracy: 0.9773\n",
      "Epoch 00081: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3906 - accuracy: 0.9773 - val_loss: 4.2961 - val_accuracy: 0.2701 - lr: 1.0000e-05\n",
      "Epoch 82/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3935 - accuracy: 0.9783\n",
      "Epoch 00082: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.3935 - accuracy: 0.9783 - val_loss: 4.2371 - val_accuracy: 0.2724 - lr: 1.0000e-05\n",
      "Epoch 83/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.9800\n",
      "Epoch 00083: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3833 - accuracy: 0.9800 - val_loss: 4.3105 - val_accuracy: 0.2659 - lr: 1.0000e-05\n",
      "Epoch 84/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3929 - accuracy: 0.9763\n",
      "Epoch 00084: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3929 - accuracy: 0.9763 - val_loss: 4.2865 - val_accuracy: 0.2747 - lr: 1.0000e-05\n",
      "Epoch 85/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3874 - accuracy: 0.9765\n",
      "Epoch 00085: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3874 - accuracy: 0.9765 - val_loss: 4.2663 - val_accuracy: 0.2713 - lr: 1.0000e-05\n",
      "Epoch 86/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3855 - accuracy: 0.9763\n",
      "Epoch 00086: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3855 - accuracy: 0.9763 - val_loss: 4.2338 - val_accuracy: 0.2709 - lr: 1.0000e-05\n",
      "Epoch 87/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3832 - accuracy: 0.9761\n",
      "Epoch 00087: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.3832 - accuracy: 0.9761 - val_loss: 4.2992 - val_accuracy: 0.2728 - lr: 1.0000e-05\n",
      "Epoch 88/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3770 - accuracy: 0.9794\n",
      "Epoch 00088: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.3770 - accuracy: 0.9794 - val_loss: 4.2409 - val_accuracy: 0.2713 - lr: 1.0000e-05\n",
      "Epoch 89/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3736 - accuracy: 0.9788\n",
      "Epoch 00089: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.3736 - accuracy: 0.9788 - val_loss: 4.2928 - val_accuracy: 0.2697 - lr: 1.0000e-05\n",
      "Epoch 90/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3724 - accuracy: 0.9806\n",
      "Epoch 00090: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.3724 - accuracy: 0.9806 - val_loss: 4.2472 - val_accuracy: 0.2732 - lr: 1.0000e-05\n",
      "Epoch 91/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3770 - accuracy: 0.9785\n",
      "Epoch 00091: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3770 - accuracy: 0.9785 - val_loss: 4.3246 - val_accuracy: 0.2659 - lr: 1.0000e-05\n",
      "Epoch 92/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3780 - accuracy: 0.9769\n",
      "Epoch 00092: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3780 - accuracy: 0.9769 - val_loss: 4.2590 - val_accuracy: 0.2732 - lr: 1.0000e-05\n",
      "Epoch 93/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3778 - accuracy: 0.9777\n",
      "Epoch 00093: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.3778 - accuracy: 0.9777 - val_loss: 4.2539 - val_accuracy: 0.2709 - lr: 1.0000e-05\n",
      "Epoch 94/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3683 - accuracy: 0.9786\n",
      "Epoch 00094: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3683 - accuracy: 0.9786 - val_loss: 4.3066 - val_accuracy: 0.2716 - lr: 1.0000e-05\n",
      "Epoch 95/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3664 - accuracy: 0.9810\n",
      "Epoch 00095: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3664 - accuracy: 0.9810 - val_loss: 4.2865 - val_accuracy: 0.2678 - lr: 1.0000e-05\n",
      "Epoch 96/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3692 - accuracy: 0.9783\n",
      "Epoch 00096: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.3692 - accuracy: 0.9783 - val_loss: 4.2796 - val_accuracy: 0.2682 - lr: 1.0000e-05\n",
      "Epoch 97/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3680 - accuracy: 0.9804\n",
      "Epoch 00097: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3680 - accuracy: 0.9804 - val_loss: 4.2837 - val_accuracy: 0.2716 - lr: 1.0000e-05\n",
      "Epoch 98/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3658 - accuracy: 0.9800\n",
      "Epoch 00098: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 0.3658 - accuracy: 0.9800 - val_loss: 4.2874 - val_accuracy: 0.2663 - lr: 1.0000e-05\n",
      "Epoch 99/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3764 - accuracy: 0.9750\n",
      "Epoch 00099: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 0.3764 - accuracy: 0.9750 - val_loss: 4.2652 - val_accuracy: 0.2697 - lr: 1.0000e-05\n",
      "Epoch 100/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3801 - accuracy: 0.9748\n",
      "Epoch 00100: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3801 - accuracy: 0.9748 - val_loss: 4.3318 - val_accuracy: 0.2682 - lr: 1.0000e-05\n",
      "Epoch 101/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3618 - accuracy: 0.9810\n",
      "Epoch 00101: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3618 - accuracy: 0.9810 - val_loss: 4.3240 - val_accuracy: 0.2720 - lr: 1.0000e-05\n",
      "Epoch 102/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3709 - accuracy: 0.9771\n",
      "Epoch 00102: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3709 - accuracy: 0.9771 - val_loss: 4.2736 - val_accuracy: 0.2693 - lr: 1.0000e-05\n",
      "Epoch 103/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3599 - accuracy: 0.9808\n",
      "Epoch 00103: val_accuracy did not improve from 0.31666\n",
      "163/163 [==============================] - 55s 338ms/step - loss: 0.3599 - accuracy: 0.9808 - val_loss: 4.2742 - val_accuracy: 0.2693 - lr: 1.0000e-05\n",
      "epoch_number 13\n",
      "train accuracy and validation accuracy 0.5631852149963379 0.3166602551937103\n",
      "82/82 [==============================] - 6s 73ms/step - loss: 3.5372 - accuracy: 0.3167\n",
      "test_accuracy 0.3166602551937103\n",
      "[0.3470565676689148, 0.3162754774093628, 0.3166602551937103]\n",
      "test_mean for %d subjects: 3\n",
      "0.32666410009066266\n",
      "/media/naveen/nav/mat_codes/nina_DB4_codes/naveen_prep_nlw/sub_wise_process_TT/S4_tr.csv\n",
      "Number of columns in the dataframe: 13\n",
      "Number of rows in the dataframe: 2080000\n",
      "\n",
      "/media/naveen/nav/mat_codes/nina_DB4_codes/naveen_prep_nlw/sub_wise_process_TT/S4_tt.csv\n",
      "Number of columns in the dataframe: 13\n",
      "Number of rows in the dataframe: 1040000\n",
      "\n",
      "x_train shape:  (5199, 400, 12)\n",
      "5199 training samples\n",
      "y_train shape:  (5199,)\n",
      "num_time_periods 400\n",
      "num_sensors 12\n",
      "class_list [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0]\n",
      "x_train shape: (400, 12)\n",
      "input_shape: (400, 12)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "New y_train shape:  (5199, 52)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test shape:  (2599, 400, 12)\n",
      "2599 testing samples\n",
      "y_test shape:  (2599,)\n",
      "x_train shape:  (5199, 400, 12)\n",
      "x_test shape:  (2599, 400, 12)\n",
      "n_outputs 52\n",
      "Model: \"wei_mscnn_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main (InputLayer)               [(None, 400, 12)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_8 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_10 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_12 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_14 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_16 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_18 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_20 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_22 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_1 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_2 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_3 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_4 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_5 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_10[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_6 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_12[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_7 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_14[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_8 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_16[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_9 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_18[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_10 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_20[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_11 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_22[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [()]                 0           tf_op_layer_Shape_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_5 (Te [()]                 0           tf_op_layer_Shape_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_7 (Te [()]                 0           tf_op_layer_Shape_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_9 (Te [()]                 0           tf_op_layer_Shape_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_11 (T [()]                 0           tf_op_layer_Shape_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_13 (T [()]                 0           tf_op_layer_Shape_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_15 (T [()]                 0           tf_op_layer_Shape_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_17 (T [()]                 0           tf_op_layer_Shape_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_19 (T [()]                 0           tf_op_layer_Shape_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_21 (T [()]                 0           tf_op_layer_Shape_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_23 (T [()]                 0           tf_op_layer_Shape_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape/shape (Tens [(3,)]               0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1/shape (Te [(3,)]               0           tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2/shape (Te [(3,)]               0           tf_op_layer_strided_slice_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3/shape (Te [(3,)]               0           tf_op_layer_strided_slice_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4/shape (Te [(3,)]               0           tf_op_layer_strided_slice_9[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5/shape (Te [(3,)]               0           tf_op_layer_strided_slice_11[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6/shape (Te [(3,)]               0           tf_op_layer_strided_slice_13[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7/shape (Te [(3,)]               0           tf_op_layer_strided_slice_15[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8/shape (Te [(3,)]               0           tf_op_layer_strided_slice_17[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9/shape (Te [(3,)]               0           tf_op_layer_strided_slice_19[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_10/shape (T [(3,)]               0           tf_op_layer_strided_slice_21[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_11/shape (T [(3,)]               0           tf_op_layer_strided_slice_23[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 400, 1)]     0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 tf_op_layer_Reshape/shape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_2[0][0]\n",
      "                                                                 tf_op_layer_Reshape_1/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_4[0][0]\n",
      "                                                                 tf_op_layer_Reshape_2/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_6[0][0]\n",
      "                                                                 tf_op_layer_Reshape_3/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_8[0][0]\n",
      "                                                                 tf_op_layer_Reshape_4/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_10[0][0\n",
      "                                                                 tf_op_layer_Reshape_5/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_12[0][0\n",
      "                                                                 tf_op_layer_Reshape_6/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_14[0][0\n",
      "                                                                 tf_op_layer_Reshape_7/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_16[0][0\n",
      "                                                                 tf_op_layer_Reshape_8/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_18[0][0\n",
      "                                                                 tf_op_layer_Reshape_9/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_10 (TensorF [(None, 400, 1)]     0           tf_op_layer_strided_slice_20[0][0\n",
      "                                                                 tf_op_layer_Reshape_10/shape[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_11 (TensorF [(None, 400, 1)]     0           tf_op_layer_strided_slice_22[0][0\n",
      "                                                                 tf_op_layer_Reshape_11/shape[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 400, 64)      256         tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 400, 64)      256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 400, 64)      256         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 400, 64)      256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 400, 64)      256         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 400, 64)      256         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 400, 64)      256         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 400, 64)      256         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 400, 64)      256         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 400, 64)      256         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 400, 64)      256         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 400, 64)      256         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 400, 64)      256         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 400, 64)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 400, 64)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 400, 64)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 400, 64)      0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 400, 64)      0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 400, 64)      0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 400, 64)      0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 400, 64)      0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 400, 64)      0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 400, 64)      0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 400, 64)      0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 400, 64)      0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 400, 64)      12352       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 400, 64)      12352       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 400, 64)      12352       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 400, 64)      12352       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 400, 64)      12352       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 400, 64)      12352       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 400, 64)      12352       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 400, 64)      12352       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 400, 64)      12352       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 400, 64)      12352       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 400, 64)      12352       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 400, 64)      12352       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 400, 64)      256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 400, 64)      256         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 400, 64)      256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 400, 64)      256         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 400, 64)      256         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 400, 64)      256         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 400, 64)      256         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 400, 64)      256         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 400, 64)      256         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 400, 64)      256         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 400, 64)      256         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 400, 64)      256         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 400, 64)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 400, 64)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 400, 64)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 400, 64)      0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 400, 64)      0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 400, 64)      0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 400, 64)      0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 400, 64)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 400, 64)      0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 400, 64)      0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 400, 64)      0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 400, 64)      0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d (LocallyCon (None, 400, 64)      1664000     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_2 (LocallyC (None, 400, 64)      1664000     activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_4 (LocallyC (None, 400, 64)      1664000     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_6 (LocallyC (None, 400, 64)      1664000     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_8 (LocallyC (None, 400, 64)      1664000     activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_10 (Locally (None, 400, 64)      1664000     activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_12 (Locally (None, 400, 64)      1664000     activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_14 (Locally (None, 400, 64)      1664000     activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_16 (Locally (None, 400, 64)      1664000     activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_18 (Locally (None, 400, 64)      1664000     activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_20 (Locally (None, 400, 64)      1664000     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_22 (Locally (None, 400, 64)      1664000     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 400, 64)      256         locally_connected1d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 400, 64)      256         locally_connected1d_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 400, 64)      256         locally_connected1d_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 400, 64)      256         locally_connected1d_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 400, 64)      256         locally_connected1d_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 400, 64)      256         locally_connected1d_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 400, 64)      256         locally_connected1d_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 400, 64)      256         locally_connected1d_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 400, 64)      256         locally_connected1d_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 400, 64)      256         locally_connected1d_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 400, 64)      256         locally_connected1d_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 400, 64)      256         locally_connected1d_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 400, 64)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 400, 64)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 400, 64)      0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 400, 64)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 400, 64)      0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 400, 64)      0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 400, 64)      0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 400, 64)      0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 400, 64)      0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 400, 64)      0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 400, 64)      0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 400, 64)      0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_1 (LocallyC (None, 400, 64)      1664000     activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_3 (LocallyC (None, 400, 64)      1664000     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_5 (LocallyC (None, 400, 64)      1664000     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_7 (LocallyC (None, 400, 64)      1664000     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_9 (LocallyC (None, 400, 64)      1664000     activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_11 (Locally (None, 400, 64)      1664000     activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_13 (Locally (None, 400, 64)      1664000     activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_15 (Locally (None, 400, 64)      1664000     activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_17 (Locally (None, 400, 64)      1664000     activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_19 (Locally (None, 400, 64)      1664000     activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_21 (Locally (None, 400, 64)      1664000     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_23 (Locally (None, 400, 64)      1664000     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 400, 64)      256         locally_connected1d_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 400, 64)      256         locally_connected1d_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 400, 64)      256         locally_connected1d_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 400, 64)      256         locally_connected1d_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 400, 64)      256         locally_connected1d_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 400, 64)      256         locally_connected1d_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 400, 64)      256         locally_connected1d_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 400, 64)      256         locally_connected1d_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 400, 64)      256         locally_connected1d_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 400, 64)      256         locally_connected1d_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 400, 64)      256         locally_connected1d_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 400, 64)      256         locally_connected1d_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 400, 64)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 400, 64)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 400, 64)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 400, 64)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 400, 64)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 400, 64)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 400, 64)      0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 400, 64)      0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 400, 64)      0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 400, 64)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 400, 64)      0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 400, 64)      0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 400, 64)      0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 400, 64)      0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 400, 64)      0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 400, 64)      0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 400, 64)      0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 400, 64)      0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 400, 64)      0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 400, 64)      0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 400, 64)      0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 400, 64)      0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 400, 64)      0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 400, 64)      0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_stack (TensorFlowOp [(None, 400, 12, 64) 0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "                                                                 dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 307200)       0           tf_op_layer_stack[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          157286912   flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 512)          0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 512)          0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          262656      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 512)          0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 512)          0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          65664       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 128)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 128)          0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 52)           6708        activation_50[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 197,726,132\n",
      "Trainable params: 197,717,684\n",
      "Non-trainable params: 8,448\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - ETA: 0s - loss: 4.3346 - accuracy: 0.1391\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.24356, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 124s 763ms/step - loss: 4.3346 - accuracy: 0.1391 - val_loss: 3.3452 - val_accuracy: 0.2436 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.2697 - accuracy: 0.2460\n",
      "Epoch 00002: val_accuracy improved from 0.24356 to 0.30204, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 61s 374ms/step - loss: 3.2697 - accuracy: 0.2460 - val_loss: 3.0909 - val_accuracy: 0.3020 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.0951 - accuracy: 0.3062\n",
      "Epoch 00003: val_accuracy improved from 0.30204 to 0.34398, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 61s 376ms/step - loss: 3.0951 - accuracy: 0.3062 - val_loss: 3.0706 - val_accuracy: 0.3440 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.9538 - accuracy: 0.3628\n",
      "Epoch 00004: val_accuracy did not improve from 0.34398\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.9538 - accuracy: 0.3628 - val_loss: 3.0923 - val_accuracy: 0.3421 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.8560 - accuracy: 0.4049\n",
      "Epoch 00005: val_accuracy improved from 0.34398 to 0.35937, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 61s 372ms/step - loss: 2.8560 - accuracy: 0.4049 - val_loss: 3.0969 - val_accuracy: 0.3594 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.7885 - accuracy: 0.4382\n",
      "Epoch 00006: val_accuracy improved from 0.35937 to 0.36014, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 61s 375ms/step - loss: 2.7885 - accuracy: 0.4382 - val_loss: 3.0568 - val_accuracy: 0.3601 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.6597 - accuracy: 0.4718\n",
      "Epoch 00007: val_accuracy did not improve from 0.36014\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 2.6597 - accuracy: 0.4718 - val_loss: 3.1307 - val_accuracy: 0.3586 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.5818 - accuracy: 0.4962\n",
      "Epoch 00008: val_accuracy did not improve from 0.36014\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.5818 - accuracy: 0.4962 - val_loss: 3.1978 - val_accuracy: 0.3598 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.5199 - accuracy: 0.5186\n",
      "Epoch 00009: val_accuracy improved from 0.36014 to 0.36437, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 60s 370ms/step - loss: 2.5199 - accuracy: 0.5186 - val_loss: 3.2089 - val_accuracy: 0.3644 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.4169 - accuracy: 0.5538\n",
      "Epoch 00010: val_accuracy did not improve from 0.36437\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.4169 - accuracy: 0.5538 - val_loss: 3.2998 - val_accuracy: 0.3578 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.3450 - accuracy: 0.5840\n",
      "Epoch 00011: val_accuracy did not improve from 0.36437\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 2.3450 - accuracy: 0.5840 - val_loss: 3.3303 - val_accuracy: 0.3544 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.2325 - accuracy: 0.6186\n",
      "Epoch 00012: val_accuracy did not improve from 0.36437\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.2325 - accuracy: 0.6186 - val_loss: 3.3510 - val_accuracy: 0.3540 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.2294 - accuracy: 0.6286\n",
      "Epoch 00013: val_accuracy did not improve from 0.36437\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 2.2294 - accuracy: 0.6286 - val_loss: 3.4386 - val_accuracy: 0.3551 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.1446 - accuracy: 0.6455\n",
      "Epoch 00014: val_accuracy did not improve from 0.36437\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.1446 - accuracy: 0.6455 - val_loss: 3.5486 - val_accuracy: 0.3301 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.0624 - accuracy: 0.6774\n",
      "Epoch 00015: val_accuracy improved from 0.36437 to 0.36553, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 60s 370ms/step - loss: 2.0624 - accuracy: 0.6774 - val_loss: 3.4805 - val_accuracy: 0.3655 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.0247 - accuracy: 0.7005\n",
      "Epoch 00016: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.0247 - accuracy: 0.7005 - val_loss: 3.6061 - val_accuracy: 0.3409 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.9932 - accuracy: 0.6953\n",
      "Epoch 00017: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.9932 - accuracy: 0.6953 - val_loss: 3.6868 - val_accuracy: 0.3313 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.9573 - accuracy: 0.7165\n",
      "Epoch 00018: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.9573 - accuracy: 0.7165 - val_loss: 3.6082 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8757 - accuracy: 0.7398\n",
      "Epoch 00019: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.8757 - accuracy: 0.7398 - val_loss: 3.6960 - val_accuracy: 0.3440 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8605 - accuracy: 0.7480\n",
      "Epoch 00020: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.8605 - accuracy: 0.7480 - val_loss: 3.7725 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7979 - accuracy: 0.7600\n",
      "Epoch 00021: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.7979 - accuracy: 0.7600 - val_loss: 3.7643 - val_accuracy: 0.3328 - lr: 0.0010\n",
      "Epoch 22/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7381 - accuracy: 0.7726\n",
      "Epoch 00022: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.7381 - accuracy: 0.7726 - val_loss: 3.8141 - val_accuracy: 0.3463 - lr: 0.0010\n",
      "Epoch 23/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7330 - accuracy: 0.7886\n",
      "Epoch 00023: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.7330 - accuracy: 0.7886 - val_loss: 3.9060 - val_accuracy: 0.3332 - lr: 0.0010\n",
      "Epoch 24/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7147 - accuracy: 0.7828\n",
      "Epoch 00024: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.7147 - accuracy: 0.7828 - val_loss: 3.9647 - val_accuracy: 0.3397 - lr: 0.0010\n",
      "Epoch 25/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6725 - accuracy: 0.7990\n",
      "Epoch 00025: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.6725 - accuracy: 0.7990 - val_loss: 3.9554 - val_accuracy: 0.3274 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6678 - accuracy: 0.7982\n",
      "Epoch 00026: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.6678 - accuracy: 0.7982 - val_loss: 3.9904 - val_accuracy: 0.3367 - lr: 0.0010\n",
      "Epoch 27/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5955 - accuracy: 0.8184\n",
      "Epoch 00027: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.5955 - accuracy: 0.8184 - val_loss: 3.9613 - val_accuracy: 0.3278 - lr: 0.0010\n",
      "Epoch 28/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6209 - accuracy: 0.8157\n",
      "Epoch 00028: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.6209 - accuracy: 0.8157 - val_loss: 3.9852 - val_accuracy: 0.3278 - lr: 0.0010\n",
      "Epoch 29/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5936 - accuracy: 0.8252\n",
      "Epoch 00029: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.5936 - accuracy: 0.8252 - val_loss: 4.1688 - val_accuracy: 0.3163 - lr: 0.0010\n",
      "Epoch 30/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4749 - accuracy: 0.8377\n",
      "Epoch 00030: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.4749 - accuracy: 0.8377 - val_loss: 3.9289 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 31/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4601 - accuracy: 0.8388\n",
      "Epoch 00031: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.4601 - accuracy: 0.8388 - val_loss: 4.0229 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 32/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4934 - accuracy: 0.8436\n",
      "Epoch 00032: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.4934 - accuracy: 0.8436 - val_loss: 4.1436 - val_accuracy: 0.3093 - lr: 0.0010\n",
      "Epoch 33/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4473 - accuracy: 0.8492\n",
      "Epoch 00033: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.4473 - accuracy: 0.8492 - val_loss: 4.0442 - val_accuracy: 0.3317 - lr: 0.0010\n",
      "Epoch 34/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3911 - accuracy: 0.8619\n",
      "Epoch 00034: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.3911 - accuracy: 0.8619 - val_loss: 4.1682 - val_accuracy: 0.3244 - lr: 0.0010\n",
      "Epoch 35/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4143 - accuracy: 0.8552\n",
      "Epoch 00035: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.4143 - accuracy: 0.8552 - val_loss: 4.2981 - val_accuracy: 0.3201 - lr: 0.0010\n",
      "Epoch 36/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4560 - accuracy: 0.8554\n",
      "Epoch 00036: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.4560 - accuracy: 0.8554 - val_loss: 4.2395 - val_accuracy: 0.3209 - lr: 0.0010\n",
      "Epoch 37/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4380 - accuracy: 0.8607\n",
      "Epoch 00037: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.4380 - accuracy: 0.8607 - val_loss: 4.3267 - val_accuracy: 0.3317 - lr: 0.0010\n",
      "Epoch 38/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3989 - accuracy: 0.8657\n",
      "Epoch 00038: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.3989 - accuracy: 0.8657 - val_loss: 4.1899 - val_accuracy: 0.3328 - lr: 0.0010\n",
      "Epoch 39/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3142 - accuracy: 0.8777\n",
      "Epoch 00039: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 1.3142 - accuracy: 0.8777 - val_loss: 4.2257 - val_accuracy: 0.3313 - lr: 0.0010\n",
      "Epoch 40/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.1759 - accuracy: 0.9059\n",
      "Epoch 00040: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.1759 - accuracy: 0.9059 - val_loss: 4.0691 - val_accuracy: 0.3397 - lr: 1.0000e-04\n",
      "Epoch 41/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0860 - accuracy: 0.9211\n",
      "Epoch 00041: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 1.0860 - accuracy: 0.9211 - val_loss: 3.9970 - val_accuracy: 0.3374 - lr: 1.0000e-04\n",
      "Epoch 42/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0328 - accuracy: 0.9283\n",
      "Epoch 00042: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.0328 - accuracy: 0.9283 - val_loss: 3.9966 - val_accuracy: 0.3371 - lr: 1.0000e-04\n",
      "Epoch 43/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9664 - accuracy: 0.9421\n",
      "Epoch 00043: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.9664 - accuracy: 0.9421 - val_loss: 3.9948 - val_accuracy: 0.3317 - lr: 1.0000e-04\n",
      "Epoch 44/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9324 - accuracy: 0.9411\n",
      "Epoch 00044: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.9324 - accuracy: 0.9411 - val_loss: 4.0066 - val_accuracy: 0.3324 - lr: 1.0000e-04\n",
      "Epoch 45/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8888 - accuracy: 0.9477\n",
      "Epoch 00045: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.8888 - accuracy: 0.9477 - val_loss: 3.9406 - val_accuracy: 0.3340 - lr: 1.0000e-04\n",
      "Epoch 46/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8645 - accuracy: 0.9456\n",
      "Epoch 00046: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.8645 - accuracy: 0.9456 - val_loss: 3.8833 - val_accuracy: 0.3347 - lr: 1.0000e-04\n",
      "Epoch 47/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8303 - accuracy: 0.9511\n",
      "Epoch 00047: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.8303 - accuracy: 0.9511 - val_loss: 3.9191 - val_accuracy: 0.3367 - lr: 1.0000e-04\n",
      "Epoch 48/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8094 - accuracy: 0.9531\n",
      "Epoch 00048: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.8094 - accuracy: 0.9531 - val_loss: 3.8770 - val_accuracy: 0.3340 - lr: 1.0000e-04\n",
      "Epoch 49/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7797 - accuracy: 0.9571\n",
      "Epoch 00049: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.7797 - accuracy: 0.9571 - val_loss: 3.8547 - val_accuracy: 0.3355 - lr: 1.0000e-04\n",
      "Epoch 50/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7573 - accuracy: 0.9560\n",
      "Epoch 00050: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.7573 - accuracy: 0.9560 - val_loss: 3.8512 - val_accuracy: 0.3386 - lr: 1.0000e-04\n",
      "Epoch 51/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7314 - accuracy: 0.9586\n",
      "Epoch 00051: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.7314 - accuracy: 0.9586 - val_loss: 3.8778 - val_accuracy: 0.3324 - lr: 1.0000e-04\n",
      "Epoch 52/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7037 - accuracy: 0.9621\n",
      "Epoch 00052: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.7037 - accuracy: 0.9621 - val_loss: 3.8683 - val_accuracy: 0.3313 - lr: 1.0000e-04\n",
      "Epoch 53/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7048 - accuracy: 0.9567\n",
      "Epoch 00053: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.7048 - accuracy: 0.9567 - val_loss: 3.8723 - val_accuracy: 0.3255 - lr: 1.0000e-04\n",
      "Epoch 54/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6707 - accuracy: 0.9629\n",
      "Epoch 00054: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.6707 - accuracy: 0.9629 - val_loss: 3.8159 - val_accuracy: 0.3309 - lr: 1.0000e-04\n",
      "Epoch 55/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6483 - accuracy: 0.9671\n",
      "Epoch 00055: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.6483 - accuracy: 0.9671 - val_loss: 3.8730 - val_accuracy: 0.3359 - lr: 1.0000e-04\n",
      "Epoch 56/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6254 - accuracy: 0.9677\n",
      "Epoch 00056: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.6254 - accuracy: 0.9677 - val_loss: 3.8240 - val_accuracy: 0.3313 - lr: 1.0000e-04\n",
      "Epoch 57/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6228 - accuracy: 0.9635\n",
      "Epoch 00057: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.6228 - accuracy: 0.9635 - val_loss: 3.8356 - val_accuracy: 0.3317 - lr: 1.0000e-04\n",
      "Epoch 58/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6151 - accuracy: 0.9631\n",
      "Epoch 00058: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.6151 - accuracy: 0.9631 - val_loss: 3.8473 - val_accuracy: 0.3209 - lr: 1.0000e-04\n",
      "Epoch 59/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5871 - accuracy: 0.9650\n",
      "Epoch 00059: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.5871 - accuracy: 0.9650 - val_loss: 3.8377 - val_accuracy: 0.3270 - lr: 1.0000e-04\n",
      "Epoch 60/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5727 - accuracy: 0.9679\n",
      "Epoch 00060: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.5727 - accuracy: 0.9679 - val_loss: 3.8448 - val_accuracy: 0.3228 - lr: 1.0000e-04\n",
      "Epoch 61/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5541 - accuracy: 0.9696\n",
      "Epoch 00061: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.5541 - accuracy: 0.9696 - val_loss: 3.8182 - val_accuracy: 0.3247 - lr: 1.0000e-04\n",
      "Epoch 62/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5429 - accuracy: 0.9685\n",
      "Epoch 00062: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.5429 - accuracy: 0.9685 - val_loss: 3.8471 - val_accuracy: 0.3297 - lr: 1.0000e-04\n",
      "Epoch 63/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5361 - accuracy: 0.9677\n",
      "Epoch 00063: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.5361 - accuracy: 0.9677 - val_loss: 3.7806 - val_accuracy: 0.3259 - lr: 1.0000e-04\n",
      "Epoch 64/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5167 - accuracy: 0.9736\n",
      "Epoch 00064: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.5167 - accuracy: 0.9736 - val_loss: 3.8526 - val_accuracy: 0.3286 - lr: 1.0000e-04\n",
      "Epoch 65/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5162 - accuracy: 0.9667\n",
      "Epoch 00065: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 0.5162 - accuracy: 0.9667 - val_loss: 3.8145 - val_accuracy: 0.3267 - lr: 1.0000e-04\n",
      "Epoch 66/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4971 - accuracy: 0.9723\n",
      "Epoch 00066: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4971 - accuracy: 0.9723 - val_loss: 3.8446 - val_accuracy: 0.3232 - lr: 1.0000e-04\n",
      "Epoch 67/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4873 - accuracy: 0.9715\n",
      "Epoch 00067: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4873 - accuracy: 0.9715 - val_loss: 3.8332 - val_accuracy: 0.3270 - lr: 1.0000e-04\n",
      "Epoch 68/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4754 - accuracy: 0.9717\n",
      "Epoch 00068: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 0.4754 - accuracy: 0.9717 - val_loss: 3.8291 - val_accuracy: 0.3217 - lr: 1.0000e-04\n",
      "Epoch 69/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4675 - accuracy: 0.9748\n",
      "Epoch 00069: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4675 - accuracy: 0.9748 - val_loss: 3.8511 - val_accuracy: 0.3186 - lr: 1.0000e-04\n",
      "Epoch 70/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4754 - accuracy: 0.9679\n",
      "Epoch 00070: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4754 - accuracy: 0.9679 - val_loss: 3.9042 - val_accuracy: 0.3201 - lr: 1.0000e-04\n",
      "Epoch 71/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4607 - accuracy: 0.9671\n",
      "Epoch 00071: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4607 - accuracy: 0.9671 - val_loss: 3.8861 - val_accuracy: 0.3244 - lr: 1.0000e-04\n",
      "Epoch 72/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4391 - accuracy: 0.9769\n",
      "Epoch 00072: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4391 - accuracy: 0.9769 - val_loss: 3.8108 - val_accuracy: 0.3224 - lr: 1.0000e-04\n",
      "Epoch 73/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4352 - accuracy: 0.9754\n",
      "Epoch 00073: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4352 - accuracy: 0.9754 - val_loss: 3.8186 - val_accuracy: 0.3305 - lr: 1.0000e-04\n",
      "Epoch 74/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4320 - accuracy: 0.9736\n",
      "Epoch 00074: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.4320 - accuracy: 0.9736 - val_loss: 3.8261 - val_accuracy: 0.3228 - lr: 1.0000e-04\n",
      "Epoch 75/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4132 - accuracy: 0.9783\n",
      "Epoch 00075: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4132 - accuracy: 0.9783 - val_loss: 3.8318 - val_accuracy: 0.3213 - lr: 1.0000e-04\n",
      "Epoch 76/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4153 - accuracy: 0.9756\n",
      "Epoch 00076: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4153 - accuracy: 0.9756 - val_loss: 3.8230 - val_accuracy: 0.3290 - lr: 1.0000e-04\n",
      "Epoch 77/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4025 - accuracy: 0.9783\n",
      "Epoch 00077: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4025 - accuracy: 0.9783 - val_loss: 3.9042 - val_accuracy: 0.3174 - lr: 1.0000e-04\n",
      "Epoch 78/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4023 - accuracy: 0.9725\n",
      "Epoch 00078: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4023 - accuracy: 0.9725 - val_loss: 3.8837 - val_accuracy: 0.3220 - lr: 1.0000e-04\n",
      "Epoch 79/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3982 - accuracy: 0.9738\n",
      "Epoch 00079: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3982 - accuracy: 0.9738 - val_loss: 3.8869 - val_accuracy: 0.3178 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3894 - accuracy: 0.9786\n",
      "Epoch 00080: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3894 - accuracy: 0.9786 - val_loss: 3.9453 - val_accuracy: 0.3190 - lr: 1.0000e-05\n",
      "Epoch 81/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3924 - accuracy: 0.9775\n",
      "Epoch 00081: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3924 - accuracy: 0.9775 - val_loss: 3.8908 - val_accuracy: 0.3174 - lr: 1.0000e-05\n",
      "Epoch 82/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3841 - accuracy: 0.9771\n",
      "Epoch 00082: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3841 - accuracy: 0.9771 - val_loss: 3.8456 - val_accuracy: 0.3228 - lr: 1.0000e-05\n",
      "Epoch 83/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3844 - accuracy: 0.9777\n",
      "Epoch 00083: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 0.3844 - accuracy: 0.9777 - val_loss: 3.8628 - val_accuracy: 0.3267 - lr: 1.0000e-05\n",
      "Epoch 84/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3797 - accuracy: 0.9781\n",
      "Epoch 00084: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.3797 - accuracy: 0.9781 - val_loss: 3.8696 - val_accuracy: 0.3270 - lr: 1.0000e-05\n",
      "Epoch 85/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3753 - accuracy: 0.9812\n",
      "Epoch 00085: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3753 - accuracy: 0.9812 - val_loss: 3.8922 - val_accuracy: 0.3294 - lr: 1.0000e-05\n",
      "Epoch 86/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3791 - accuracy: 0.9786\n",
      "Epoch 00086: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3791 - accuracy: 0.9786 - val_loss: 3.8507 - val_accuracy: 0.3259 - lr: 1.0000e-05\n",
      "Epoch 87/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3757 - accuracy: 0.9790\n",
      "Epoch 00087: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3757 - accuracy: 0.9790 - val_loss: 3.8154 - val_accuracy: 0.3240 - lr: 1.0000e-05\n",
      "Epoch 88/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3735 - accuracy: 0.9804\n",
      "Epoch 00088: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3735 - accuracy: 0.9804 - val_loss: 3.8309 - val_accuracy: 0.3247 - lr: 1.0000e-05\n",
      "Epoch 89/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3762 - accuracy: 0.9810\n",
      "Epoch 00089: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3762 - accuracy: 0.9810 - val_loss: 3.8574 - val_accuracy: 0.3278 - lr: 1.0000e-05\n",
      "Epoch 90/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3714 - accuracy: 0.9794\n",
      "Epoch 00090: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3714 - accuracy: 0.9794 - val_loss: 3.8727 - val_accuracy: 0.3255 - lr: 1.0000e-05\n",
      "Epoch 91/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3742 - accuracy: 0.9786\n",
      "Epoch 00091: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3742 - accuracy: 0.9786 - val_loss: 3.8762 - val_accuracy: 0.3236 - lr: 1.0000e-05\n",
      "Epoch 92/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3721 - accuracy: 0.9769\n",
      "Epoch 00092: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3721 - accuracy: 0.9769 - val_loss: 3.9081 - val_accuracy: 0.3240 - lr: 1.0000e-05\n",
      "Epoch 93/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3752 - accuracy: 0.9796\n",
      "Epoch 00093: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3752 - accuracy: 0.9796 - val_loss: 3.8634 - val_accuracy: 0.3236 - lr: 1.0000e-05\n",
      "Epoch 94/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3753 - accuracy: 0.9771\n",
      "Epoch 00094: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3753 - accuracy: 0.9771 - val_loss: 3.8886 - val_accuracy: 0.3213 - lr: 1.0000e-05\n",
      "Epoch 95/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3675 - accuracy: 0.9833\n",
      "Epoch 00095: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3675 - accuracy: 0.9833 - val_loss: 3.8605 - val_accuracy: 0.3220 - lr: 1.0000e-05\n",
      "Epoch 96/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3640 - accuracy: 0.9825\n",
      "Epoch 00096: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3640 - accuracy: 0.9825 - val_loss: 3.8595 - val_accuracy: 0.3267 - lr: 1.0000e-05\n",
      "Epoch 97/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3731 - accuracy: 0.9775\n",
      "Epoch 00097: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3731 - accuracy: 0.9775 - val_loss: 3.8302 - val_accuracy: 0.3247 - lr: 1.0000e-05\n",
      "Epoch 98/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3566 - accuracy: 0.9852\n",
      "Epoch 00098: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3566 - accuracy: 0.9852 - val_loss: 3.8958 - val_accuracy: 0.3259 - lr: 1.0000e-05\n",
      "Epoch 99/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3640 - accuracy: 0.9829\n",
      "Epoch 00099: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.3640 - accuracy: 0.9829 - val_loss: 3.9090 - val_accuracy: 0.3232 - lr: 1.0000e-05\n",
      "Epoch 100/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3693 - accuracy: 0.9790\n",
      "Epoch 00100: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.3693 - accuracy: 0.9790 - val_loss: 3.8713 - val_accuracy: 0.3236 - lr: 1.0000e-05\n",
      "Epoch 101/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3591 - accuracy: 0.9812\n",
      "Epoch 00101: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3591 - accuracy: 0.9812 - val_loss: 3.8682 - val_accuracy: 0.3205 - lr: 1.0000e-05\n",
      "Epoch 102/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3589 - accuracy: 0.9806\n",
      "Epoch 00102: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3589 - accuracy: 0.9806 - val_loss: 3.9113 - val_accuracy: 0.3244 - lr: 1.0000e-05\n",
      "Epoch 103/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3541 - accuracy: 0.9829\n",
      "Epoch 00103: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3541 - accuracy: 0.9829 - val_loss: 3.8662 - val_accuracy: 0.3220 - lr: 1.0000e-05\n",
      "Epoch 104/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3645 - accuracy: 0.9777\n",
      "Epoch 00104: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3645 - accuracy: 0.9777 - val_loss: 3.8489 - val_accuracy: 0.3263 - lr: 1.0000e-05\n",
      "Epoch 105/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3610 - accuracy: 0.9813\n",
      "Epoch 00105: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3610 - accuracy: 0.9813 - val_loss: 3.9089 - val_accuracy: 0.3232 - lr: 1.0000e-05\n",
      "Epoch 106/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3612 - accuracy: 0.9817\n",
      "Epoch 00106: val_accuracy did not improve from 0.36553\n",
      "163/163 [==============================] - 55s 338ms/step - loss: 0.3612 - accuracy: 0.9817 - val_loss: 3.8700 - val_accuracy: 0.3290 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_number 15\n",
      "train accuracy and validation accuracy 0.677437961101532 0.3655252158641815\n",
      "82/82 [==============================] - 6s 75ms/step - loss: 3.4805 - accuracy: 0.3655\n",
      "test_accuracy 0.3655252158641815\n",
      "[0.3470565676689148, 0.3162754774093628, 0.3166602551937103, 0.3655252158641815]\n",
      "test_mean for %d subjects: 4\n",
      "0.33637937903404236\n",
      "/media/naveen/nav/mat_codes/nina_DB4_codes/naveen_prep_nlw/sub_wise_process_TT/S5_tr.csv\n",
      "Number of columns in the dataframe: 13\n",
      "Number of rows in the dataframe: 2080000\n",
      "\n",
      "/media/naveen/nav/mat_codes/nina_DB4_codes/naveen_prep_nlw/sub_wise_process_TT/S5_tt.csv\n",
      "Number of columns in the dataframe: 13\n",
      "Number of rows in the dataframe: 1040000\n",
      "\n",
      "x_train shape:  (5199, 400, 12)\n",
      "5199 training samples\n",
      "y_train shape:  (5199,)\n",
      "num_time_periods 400\n",
      "num_sensors 12\n",
      "class_list [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0]\n",
      "x_train shape: (400, 12)\n",
      "input_shape: (400, 12)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "New y_train shape:  (5199, 52)\n",
      "x_test shape:  (2599, 400, 12)\n",
      "2599 testing samples\n",
      "y_test shape:  (2599,)\n",
      "x_train shape:  (5199, 400, 12)\n",
      "x_test shape:  (2599, 400, 12)\n",
      "n_outputs 52\n",
      "Model: \"wei_mscnn_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main (InputLayer)               [(None, 400, 12)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_8 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_10 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_12 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_14 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_16 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_18 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_20 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_22 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_1 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_2 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_3 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_4 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_5 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_10[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_6 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_12[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_7 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_14[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_8 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_16[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_9 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_18[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_10 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_20[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_11 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_22[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [()]                 0           tf_op_layer_Shape_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_5 (Te [()]                 0           tf_op_layer_Shape_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_7 (Te [()]                 0           tf_op_layer_Shape_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_9 (Te [()]                 0           tf_op_layer_Shape_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_11 (T [()]                 0           tf_op_layer_Shape_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_13 (T [()]                 0           tf_op_layer_Shape_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_15 (T [()]                 0           tf_op_layer_Shape_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_17 (T [()]                 0           tf_op_layer_Shape_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_19 (T [()]                 0           tf_op_layer_Shape_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_21 (T [()]                 0           tf_op_layer_Shape_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_23 (T [()]                 0           tf_op_layer_Shape_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape/shape (Tens [(3,)]               0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1/shape (Te [(3,)]               0           tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2/shape (Te [(3,)]               0           tf_op_layer_strided_slice_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3/shape (Te [(3,)]               0           tf_op_layer_strided_slice_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4/shape (Te [(3,)]               0           tf_op_layer_strided_slice_9[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5/shape (Te [(3,)]               0           tf_op_layer_strided_slice_11[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6/shape (Te [(3,)]               0           tf_op_layer_strided_slice_13[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7/shape (Te [(3,)]               0           tf_op_layer_strided_slice_15[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8/shape (Te [(3,)]               0           tf_op_layer_strided_slice_17[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9/shape (Te [(3,)]               0           tf_op_layer_strided_slice_19[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_10/shape (T [(3,)]               0           tf_op_layer_strided_slice_21[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_11/shape (T [(3,)]               0           tf_op_layer_strided_slice_23[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 400, 1)]     0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 tf_op_layer_Reshape/shape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_2[0][0]\n",
      "                                                                 tf_op_layer_Reshape_1/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_4[0][0]\n",
      "                                                                 tf_op_layer_Reshape_2/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_6[0][0]\n",
      "                                                                 tf_op_layer_Reshape_3/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_8[0][0]\n",
      "                                                                 tf_op_layer_Reshape_4/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_10[0][0\n",
      "                                                                 tf_op_layer_Reshape_5/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_12[0][0\n",
      "                                                                 tf_op_layer_Reshape_6/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_14[0][0\n",
      "                                                                 tf_op_layer_Reshape_7/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_16[0][0\n",
      "                                                                 tf_op_layer_Reshape_8/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_18[0][0\n",
      "                                                                 tf_op_layer_Reshape_9/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_10 (TensorF [(None, 400, 1)]     0           tf_op_layer_strided_slice_20[0][0\n",
      "                                                                 tf_op_layer_Reshape_10/shape[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_11 (TensorF [(None, 400, 1)]     0           tf_op_layer_strided_slice_22[0][0\n",
      "                                                                 tf_op_layer_Reshape_11/shape[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 400, 64)      256         tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 400, 64)      256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 400, 64)      256         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 400, 64)      256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 400, 64)      256         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 400, 64)      256         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 400, 64)      256         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 400, 64)      256         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 400, 64)      256         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 400, 64)      256         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 400, 64)      256         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 400, 64)      256         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 400, 64)      256         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 400, 64)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 400, 64)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 400, 64)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 400, 64)      0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 400, 64)      0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 400, 64)      0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 400, 64)      0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 400, 64)      0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 400, 64)      0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 400, 64)      0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 400, 64)      0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 400, 64)      0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 400, 64)      12352       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 400, 64)      12352       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 400, 64)      12352       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 400, 64)      12352       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 400, 64)      12352       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 400, 64)      12352       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 400, 64)      12352       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 400, 64)      12352       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 400, 64)      12352       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 400, 64)      12352       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 400, 64)      12352       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 400, 64)      12352       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 400, 64)      256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 400, 64)      256         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 400, 64)      256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 400, 64)      256         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 400, 64)      256         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 400, 64)      256         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 400, 64)      256         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 400, 64)      256         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 400, 64)      256         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 400, 64)      256         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 400, 64)      256         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 400, 64)      256         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 400, 64)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 400, 64)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 400, 64)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 400, 64)      0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 400, 64)      0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 400, 64)      0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 400, 64)      0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 400, 64)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 400, 64)      0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 400, 64)      0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 400, 64)      0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 400, 64)      0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d (LocallyCon (None, 400, 64)      1664000     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_2 (LocallyC (None, 400, 64)      1664000     activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_4 (LocallyC (None, 400, 64)      1664000     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_6 (LocallyC (None, 400, 64)      1664000     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_8 (LocallyC (None, 400, 64)      1664000     activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_10 (Locally (None, 400, 64)      1664000     activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_12 (Locally (None, 400, 64)      1664000     activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_14 (Locally (None, 400, 64)      1664000     activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_16 (Locally (None, 400, 64)      1664000     activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_18 (Locally (None, 400, 64)      1664000     activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_20 (Locally (None, 400, 64)      1664000     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_22 (Locally (None, 400, 64)      1664000     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 400, 64)      256         locally_connected1d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 400, 64)      256         locally_connected1d_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 400, 64)      256         locally_connected1d_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 400, 64)      256         locally_connected1d_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 400, 64)      256         locally_connected1d_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 400, 64)      256         locally_connected1d_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 400, 64)      256         locally_connected1d_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 400, 64)      256         locally_connected1d_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 400, 64)      256         locally_connected1d_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 400, 64)      256         locally_connected1d_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 400, 64)      256         locally_connected1d_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 400, 64)      256         locally_connected1d_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 400, 64)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 400, 64)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 400, 64)      0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 400, 64)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 400, 64)      0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 400, 64)      0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 400, 64)      0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 400, 64)      0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 400, 64)      0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 400, 64)      0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 400, 64)      0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 400, 64)      0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_1 (LocallyC (None, 400, 64)      1664000     activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_3 (LocallyC (None, 400, 64)      1664000     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_5 (LocallyC (None, 400, 64)      1664000     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_7 (LocallyC (None, 400, 64)      1664000     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_9 (LocallyC (None, 400, 64)      1664000     activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_11 (Locally (None, 400, 64)      1664000     activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_13 (Locally (None, 400, 64)      1664000     activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_15 (Locally (None, 400, 64)      1664000     activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_17 (Locally (None, 400, 64)      1664000     activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_19 (Locally (None, 400, 64)      1664000     activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_21 (Locally (None, 400, 64)      1664000     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_23 (Locally (None, 400, 64)      1664000     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 400, 64)      256         locally_connected1d_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 400, 64)      256         locally_connected1d_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 400, 64)      256         locally_connected1d_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 400, 64)      256         locally_connected1d_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 400, 64)      256         locally_connected1d_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 400, 64)      256         locally_connected1d_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 400, 64)      256         locally_connected1d_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 400, 64)      256         locally_connected1d_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 400, 64)      256         locally_connected1d_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 400, 64)      256         locally_connected1d_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 400, 64)      256         locally_connected1d_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 400, 64)      256         locally_connected1d_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 400, 64)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 400, 64)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 400, 64)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 400, 64)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 400, 64)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 400, 64)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 400, 64)      0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 400, 64)      0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 400, 64)      0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 400, 64)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 400, 64)      0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 400, 64)      0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 400, 64)      0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 400, 64)      0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 400, 64)      0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 400, 64)      0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 400, 64)      0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 400, 64)      0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 400, 64)      0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 400, 64)      0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 400, 64)      0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 400, 64)      0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 400, 64)      0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 400, 64)      0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_stack (TensorFlowOp [(None, 400, 12, 64) 0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "                                                                 dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 307200)       0           tf_op_layer_stack[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          157286912   flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 512)          0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 512)          0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          262656      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 512)          0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 512)          0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          65664       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 128)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 128)          0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 52)           6708        activation_50[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 197,726,132\n",
      "Trainable params: 197,717,684\n",
      "Non-trainable params: 8,448\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - ETA: 0s - loss: 4.8120 - accuracy: 0.1393\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.26048, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 123s 752ms/step - loss: 4.8120 - accuracy: 0.1393 - val_loss: 3.5060 - val_accuracy: 0.2605 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.4584 - accuracy: 0.2651\n",
      "Epoch 00002: val_accuracy improved from 0.26048 to 0.30743, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 61s 376ms/step - loss: 3.4584 - accuracy: 0.2651 - val_loss: 3.1837 - val_accuracy: 0.3074 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.1882 - accuracy: 0.3226\n",
      "Epoch 00003: val_accuracy improved from 0.30743 to 0.33359, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 61s 375ms/step - loss: 3.1882 - accuracy: 0.3226 - val_loss: 3.1215 - val_accuracy: 0.3336 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.9929 - accuracy: 0.3766\n",
      "Epoch 00004: val_accuracy improved from 0.33359 to 0.35937, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 61s 375ms/step - loss: 2.9929 - accuracy: 0.3766 - val_loss: 3.1095 - val_accuracy: 0.3594 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.9303 - accuracy: 0.4137\n",
      "Epoch 00005: val_accuracy did not improve from 0.35937\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.9303 - accuracy: 0.4137 - val_loss: 3.1788 - val_accuracy: 0.3486 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.7603 - accuracy: 0.4653\n",
      "Epoch 00006: val_accuracy improved from 0.35937 to 0.35975, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 61s 377ms/step - loss: 2.7603 - accuracy: 0.4653 - val_loss: 3.1869 - val_accuracy: 0.3598 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.6940 - accuracy: 0.4924\n",
      "Epoch 00007: val_accuracy did not improve from 0.35975\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.6940 - accuracy: 0.4924 - val_loss: 3.3060 - val_accuracy: 0.3524 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.5744 - accuracy: 0.5341\n",
      "Epoch 00008: val_accuracy improved from 0.35975 to 0.37822, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 61s 374ms/step - loss: 2.5744 - accuracy: 0.5341 - val_loss: 3.3488 - val_accuracy: 0.3782 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.4838 - accuracy: 0.5641\n",
      "Epoch 00009: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 2.4838 - accuracy: 0.5641 - val_loss: 3.3979 - val_accuracy: 0.3609 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.4561 - accuracy: 0.5888\n",
      "Epoch 00010: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.4561 - accuracy: 0.5888 - val_loss: 3.4365 - val_accuracy: 0.3617 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.3133 - accuracy: 0.6244\n",
      "Epoch 00011: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 338ms/step - loss: 2.3133 - accuracy: 0.6244 - val_loss: 3.5114 - val_accuracy: 0.3563 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.2236 - accuracy: 0.6484\n",
      "Epoch 00012: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 2.2236 - accuracy: 0.6484 - val_loss: 3.5771 - val_accuracy: 0.3463 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.1856 - accuracy: 0.6707\n",
      "Epoch 00013: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.1856 - accuracy: 0.6707 - val_loss: 3.5921 - val_accuracy: 0.3574 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.1392 - accuracy: 0.6734\n",
      "Epoch 00014: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.1392 - accuracy: 0.6734 - val_loss: 3.6563 - val_accuracy: 0.3571 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.0466 - accuracy: 0.7098\n",
      "Epoch 00015: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 2.0466 - accuracy: 0.7098 - val_loss: 3.6619 - val_accuracy: 0.3567 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.9582 - accuracy: 0.7307\n",
      "Epoch 00016: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 1.9582 - accuracy: 0.7307 - val_loss: 3.7118 - val_accuracy: 0.3482 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8866 - accuracy: 0.7538\n",
      "Epoch 00017: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 1.8866 - accuracy: 0.7538 - val_loss: 3.8365 - val_accuracy: 0.3301 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8434 - accuracy: 0.7626\n",
      "Epoch 00018: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 1.8434 - accuracy: 0.7626 - val_loss: 3.8262 - val_accuracy: 0.3421 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8064 - accuracy: 0.7734\n",
      "Epoch 00019: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.8064 - accuracy: 0.7734 - val_loss: 3.8477 - val_accuracy: 0.3436 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7160 - accuracy: 0.7950\n",
      "Epoch 00020: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 1.7160 - accuracy: 0.7950 - val_loss: 3.8886 - val_accuracy: 0.3517 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7020 - accuracy: 0.8009\n",
      "Epoch 00021: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.7020 - accuracy: 0.8009 - val_loss: 3.9170 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 22/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6669 - accuracy: 0.8053\n",
      "Epoch 00022: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 1.6669 - accuracy: 0.8053 - val_loss: 4.1349 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 23/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6431 - accuracy: 0.8155\n",
      "Epoch 00023: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 1.6431 - accuracy: 0.8155 - val_loss: 3.9691 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 24/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5954 - accuracy: 0.8192\n",
      "Epoch 00024: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 1.5954 - accuracy: 0.8192 - val_loss: 4.0308 - val_accuracy: 0.3451 - lr: 0.0010\n",
      "Epoch 25/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5917 - accuracy: 0.8217\n",
      "Epoch 00025: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.5917 - accuracy: 0.8217 - val_loss: 4.1617 - val_accuracy: 0.3382 - lr: 0.0010\n",
      "Epoch 26/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5324 - accuracy: 0.8361\n",
      "Epoch 00026: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 1.5324 - accuracy: 0.8361 - val_loss: 4.1342 - val_accuracy: 0.3355 - lr: 0.0010\n",
      "Epoch 27/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5577 - accuracy: 0.8304\n",
      "Epoch 00027: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 1.5577 - accuracy: 0.8304 - val_loss: 4.1516 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 28/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5367 - accuracy: 0.8425\n",
      "Epoch 00028: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 1.5367 - accuracy: 0.8425 - val_loss: 4.2059 - val_accuracy: 0.3344 - lr: 0.0010\n",
      "Epoch 29/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4798 - accuracy: 0.8604\n",
      "Epoch 00029: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 1.4798 - accuracy: 0.8604 - val_loss: 4.2108 - val_accuracy: 0.3301 - lr: 0.0010\n",
      "Epoch 30/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4316 - accuracy: 0.8552\n",
      "Epoch 00030: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.4316 - accuracy: 0.8552 - val_loss: 4.2328 - val_accuracy: 0.3367 - lr: 0.0010\n",
      "Epoch 31/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4133 - accuracy: 0.8634\n",
      "Epoch 00031: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.4133 - accuracy: 0.8634 - val_loss: 4.1972 - val_accuracy: 0.3390 - lr: 0.0010\n",
      "Epoch 32/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3547 - accuracy: 0.8794\n",
      "Epoch 00032: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.3547 - accuracy: 0.8794 - val_loss: 4.1979 - val_accuracy: 0.3324 - lr: 0.0010\n",
      "Epoch 33/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3183 - accuracy: 0.8790\n",
      "Epoch 00033: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.3183 - accuracy: 0.8790 - val_loss: 4.2780 - val_accuracy: 0.3201 - lr: 0.0010\n",
      "Epoch 34/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3624 - accuracy: 0.8667\n",
      "Epoch 00034: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 1.3624 - accuracy: 0.8667 - val_loss: 4.3182 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 35/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3879 - accuracy: 0.8744\n",
      "Epoch 00035: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 1.3879 - accuracy: 0.8744 - val_loss: 4.3509 - val_accuracy: 0.3371 - lr: 0.0010\n",
      "Epoch 36/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3703 - accuracy: 0.8765\n",
      "Epoch 00036: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.3703 - accuracy: 0.8765 - val_loss: 4.4187 - val_accuracy: 0.3190 - lr: 0.0010\n",
      "Epoch 37/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3345 - accuracy: 0.8831\n",
      "Epoch 00037: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 1.3345 - accuracy: 0.8831 - val_loss: 4.3277 - val_accuracy: 0.3259 - lr: 0.0010\n",
      "Epoch 38/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3057 - accuracy: 0.8852\n",
      "Epoch 00038: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.3057 - accuracy: 0.8852 - val_loss: 4.2978 - val_accuracy: 0.3355 - lr: 0.0010\n",
      "Epoch 39/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.2553 - accuracy: 0.8946\n",
      "Epoch 00039: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.2553 - accuracy: 0.8946 - val_loss: 4.3914 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 40/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.1588 - accuracy: 0.9134\n",
      "Epoch 00040: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 1.1588 - accuracy: 0.9134 - val_loss: 4.2442 - val_accuracy: 0.3297 - lr: 1.0000e-04\n",
      "Epoch 41/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0705 - accuracy: 0.9234\n",
      "Epoch 00041: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.0705 - accuracy: 0.9234 - val_loss: 4.1744 - val_accuracy: 0.3401 - lr: 1.0000e-04\n",
      "Epoch 42/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0166 - accuracy: 0.9346\n",
      "Epoch 00042: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 1.0166 - accuracy: 0.9346 - val_loss: 4.1325 - val_accuracy: 0.3321 - lr: 1.0000e-04\n",
      "Epoch 43/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9756 - accuracy: 0.9388\n",
      "Epoch 00043: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.9756 - accuracy: 0.9388 - val_loss: 4.0991 - val_accuracy: 0.3363 - lr: 1.0000e-04\n",
      "Epoch 44/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9368 - accuracy: 0.9421\n",
      "Epoch 00044: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.9368 - accuracy: 0.9421 - val_loss: 4.0712 - val_accuracy: 0.3390 - lr: 1.0000e-04\n",
      "Epoch 45/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8829 - accuracy: 0.9531\n",
      "Epoch 00045: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.8829 - accuracy: 0.9531 - val_loss: 4.0771 - val_accuracy: 0.3447 - lr: 1.0000e-04\n",
      "Epoch 46/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8688 - accuracy: 0.9481\n",
      "Epoch 00046: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.8688 - accuracy: 0.9481 - val_loss: 4.0267 - val_accuracy: 0.3367 - lr: 1.0000e-04\n",
      "Epoch 47/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8386 - accuracy: 0.9556\n",
      "Epoch 00047: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.8386 - accuracy: 0.9556 - val_loss: 4.0331 - val_accuracy: 0.3394 - lr: 1.0000e-04\n",
      "Epoch 48/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7963 - accuracy: 0.9617\n",
      "Epoch 00048: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.7963 - accuracy: 0.9617 - val_loss: 4.0504 - val_accuracy: 0.3394 - lr: 1.0000e-04\n",
      "Epoch 49/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7784 - accuracy: 0.9592\n",
      "Epoch 00049: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.7784 - accuracy: 0.9592 - val_loss: 4.0886 - val_accuracy: 0.3386 - lr: 1.0000e-04\n",
      "Epoch 50/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7769 - accuracy: 0.9519\n",
      "Epoch 00050: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.7769 - accuracy: 0.9519 - val_loss: 4.0124 - val_accuracy: 0.3436 - lr: 1.0000e-04\n",
      "Epoch 51/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7439 - accuracy: 0.9619\n",
      "Epoch 00051: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.7439 - accuracy: 0.9619 - val_loss: 3.9951 - val_accuracy: 0.3397 - lr: 1.0000e-04\n",
      "Epoch 52/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7147 - accuracy: 0.9625\n",
      "Epoch 00052: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.7147 - accuracy: 0.9625 - val_loss: 4.0473 - val_accuracy: 0.3378 - lr: 1.0000e-04\n",
      "Epoch 53/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - ETA: 0s - loss: 0.6847 - accuracy: 0.9694\n",
      "Epoch 00053: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 0.6847 - accuracy: 0.9694 - val_loss: 4.0118 - val_accuracy: 0.3359 - lr: 1.0000e-04\n",
      "Epoch 54/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6801 - accuracy: 0.9652\n",
      "Epoch 00054: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.6801 - accuracy: 0.9652 - val_loss: 4.0813 - val_accuracy: 0.3290 - lr: 1.0000e-04\n",
      "Epoch 55/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6506 - accuracy: 0.9711\n",
      "Epoch 00055: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.6506 - accuracy: 0.9711 - val_loss: 4.0162 - val_accuracy: 0.3363 - lr: 1.0000e-04\n",
      "Epoch 56/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6472 - accuracy: 0.9658\n",
      "Epoch 00056: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 0.6472 - accuracy: 0.9658 - val_loss: 3.9863 - val_accuracy: 0.3328 - lr: 1.0000e-04\n",
      "Epoch 57/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6276 - accuracy: 0.9677\n",
      "Epoch 00057: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.6276 - accuracy: 0.9677 - val_loss: 3.9581 - val_accuracy: 0.3340 - lr: 1.0000e-04\n",
      "Epoch 58/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6061 - accuracy: 0.9706\n",
      "Epoch 00058: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.6061 - accuracy: 0.9706 - val_loss: 3.9729 - val_accuracy: 0.3355 - lr: 1.0000e-04\n",
      "Epoch 59/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6093 - accuracy: 0.9658\n",
      "Epoch 00059: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.6093 - accuracy: 0.9658 - val_loss: 4.0076 - val_accuracy: 0.3324 - lr: 1.0000e-04\n",
      "Epoch 60/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5876 - accuracy: 0.9685\n",
      "Epoch 00060: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.5876 - accuracy: 0.9685 - val_loss: 3.9643 - val_accuracy: 0.3428 - lr: 1.0000e-04\n",
      "Epoch 61/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5623 - accuracy: 0.9735\n",
      "Epoch 00061: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.5623 - accuracy: 0.9735 - val_loss: 3.9742 - val_accuracy: 0.3482 - lr: 1.0000e-04\n",
      "Epoch 62/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5523 - accuracy: 0.9727\n",
      "Epoch 00062: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.5523 - accuracy: 0.9727 - val_loss: 3.9552 - val_accuracy: 0.3340 - lr: 1.0000e-04\n",
      "Epoch 63/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5412 - accuracy: 0.9725\n",
      "Epoch 00063: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.5412 - accuracy: 0.9725 - val_loss: 3.9479 - val_accuracy: 0.3394 - lr: 1.0000e-04\n",
      "Epoch 64/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5348 - accuracy: 0.9736\n",
      "Epoch 00064: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.5348 - accuracy: 0.9736 - val_loss: 3.9545 - val_accuracy: 0.3347 - lr: 1.0000e-04\n",
      "Epoch 65/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5188 - accuracy: 0.9733\n",
      "Epoch 00065: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.5188 - accuracy: 0.9733 - val_loss: 3.9250 - val_accuracy: 0.3455 - lr: 1.0000e-04\n",
      "Epoch 66/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5078 - accuracy: 0.9754\n",
      "Epoch 00066: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.5078 - accuracy: 0.9754 - val_loss: 3.9651 - val_accuracy: 0.3282 - lr: 1.0000e-04\n",
      "Epoch 67/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4946 - accuracy: 0.9748\n",
      "Epoch 00067: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4946 - accuracy: 0.9748 - val_loss: 3.9501 - val_accuracy: 0.3328 - lr: 1.0000e-04\n",
      "Epoch 68/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4930 - accuracy: 0.9711\n",
      "Epoch 00068: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.4930 - accuracy: 0.9711 - val_loss: 3.9717 - val_accuracy: 0.3351 - lr: 1.0000e-04\n",
      "Epoch 69/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4832 - accuracy: 0.9765\n",
      "Epoch 00069: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4832 - accuracy: 0.9765 - val_loss: 3.8996 - val_accuracy: 0.3409 - lr: 1.0000e-04\n",
      "Epoch 70/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4682 - accuracy: 0.9761\n",
      "Epoch 00070: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.4682 - accuracy: 0.9761 - val_loss: 3.9331 - val_accuracy: 0.3397 - lr: 1.0000e-04\n",
      "Epoch 71/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4540 - accuracy: 0.9796\n",
      "Epoch 00071: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4540 - accuracy: 0.9796 - val_loss: 3.9496 - val_accuracy: 0.3401 - lr: 1.0000e-04\n",
      "Epoch 72/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4545 - accuracy: 0.9765\n",
      "Epoch 00072: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4545 - accuracy: 0.9765 - val_loss: 3.9278 - val_accuracy: 0.3394 - lr: 1.0000e-04\n",
      "Epoch 73/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4548 - accuracy: 0.9731\n",
      "Epoch 00073: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.4548 - accuracy: 0.9731 - val_loss: 3.9666 - val_accuracy: 0.3386 - lr: 1.0000e-04\n",
      "Epoch 74/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4377 - accuracy: 0.9781\n",
      "Epoch 00074: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.4377 - accuracy: 0.9781 - val_loss: 3.9476 - val_accuracy: 0.3413 - lr: 1.0000e-04\n",
      "Epoch 75/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4256 - accuracy: 0.9790\n",
      "Epoch 00075: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 0.4256 - accuracy: 0.9790 - val_loss: 3.9623 - val_accuracy: 0.3401 - lr: 1.0000e-04\n",
      "Epoch 76/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4266 - accuracy: 0.9771\n",
      "Epoch 00076: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.4266 - accuracy: 0.9771 - val_loss: 3.9763 - val_accuracy: 0.3405 - lr: 1.0000e-04\n",
      "Epoch 77/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4170 - accuracy: 0.9763\n",
      "Epoch 00077: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.4170 - accuracy: 0.9763 - val_loss: 3.9139 - val_accuracy: 0.3390 - lr: 1.0000e-04\n",
      "Epoch 78/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4049 - accuracy: 0.9802\n",
      "Epoch 00078: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.4049 - accuracy: 0.9802 - val_loss: 3.8923 - val_accuracy: 0.3386 - lr: 1.0000e-04\n",
      "Epoch 79/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3971 - accuracy: 0.9806\n",
      "Epoch 00079: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.3971 - accuracy: 0.9806 - val_loss: 3.9315 - val_accuracy: 0.3374 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3912 - accuracy: 0.9800\n",
      "Epoch 00080: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 0.3912 - accuracy: 0.9800 - val_loss: 3.9725 - val_accuracy: 0.3363 - lr: 1.0000e-05\n",
      "Epoch 81/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3949 - accuracy: 0.9788\n",
      "Epoch 00081: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3949 - accuracy: 0.9788 - val_loss: 3.9883 - val_accuracy: 0.3401 - lr: 1.0000e-05\n",
      "Epoch 82/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3879 - accuracy: 0.9819\n",
      "Epoch 00082: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3879 - accuracy: 0.9819 - val_loss: 3.9686 - val_accuracy: 0.3344 - lr: 1.0000e-05\n",
      "Epoch 83/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3893 - accuracy: 0.9810\n",
      "Epoch 00083: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 338ms/step - loss: 0.3893 - accuracy: 0.9810 - val_loss: 3.9905 - val_accuracy: 0.3374 - lr: 1.0000e-05\n",
      "Epoch 84/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3936 - accuracy: 0.9786\n",
      "Epoch 00084: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.3936 - accuracy: 0.9786 - val_loss: 3.9267 - val_accuracy: 0.3436 - lr: 1.0000e-05\n",
      "Epoch 85/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3923 - accuracy: 0.9771\n",
      "Epoch 00085: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3923 - accuracy: 0.9771 - val_loss: 3.9270 - val_accuracy: 0.3405 - lr: 1.0000e-05\n",
      "Epoch 86/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3763 - accuracy: 0.9858\n",
      "Epoch 00086: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 338ms/step - loss: 0.3763 - accuracy: 0.9858 - val_loss: 3.9648 - val_accuracy: 0.3386 - lr: 1.0000e-05\n",
      "Epoch 87/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3823 - accuracy: 0.9833\n",
      "Epoch 00087: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3823 - accuracy: 0.9833 - val_loss: 3.9635 - val_accuracy: 0.3363 - lr: 1.0000e-05\n",
      "Epoch 88/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3767 - accuracy: 0.9856\n",
      "Epoch 00088: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3767 - accuracy: 0.9856 - val_loss: 3.9535 - val_accuracy: 0.3436 - lr: 1.0000e-05\n",
      "Epoch 89/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3766 - accuracy: 0.9852\n",
      "Epoch 00089: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.3766 - accuracy: 0.9852 - val_loss: 3.9133 - val_accuracy: 0.3347 - lr: 1.0000e-05\n",
      "Epoch 90/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3798 - accuracy: 0.9804\n",
      "Epoch 00090: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.3798 - accuracy: 0.9804 - val_loss: 3.9718 - val_accuracy: 0.3428 - lr: 1.0000e-05\n",
      "Epoch 91/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3832 - accuracy: 0.9808\n",
      "Epoch 00091: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.3832 - accuracy: 0.9808 - val_loss: 3.9418 - val_accuracy: 0.3447 - lr: 1.0000e-05\n",
      "Epoch 92/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3875 - accuracy: 0.9785\n",
      "Epoch 00092: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3875 - accuracy: 0.9785 - val_loss: 3.9654 - val_accuracy: 0.3344 - lr: 1.0000e-05\n",
      "Epoch 93/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.9798\n",
      "Epoch 00093: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.3792 - accuracy: 0.9798 - val_loss: 3.9528 - val_accuracy: 0.3382 - lr: 1.0000e-05\n",
      "Epoch 94/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3798 - accuracy: 0.9808\n",
      "Epoch 00094: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.3798 - accuracy: 0.9808 - val_loss: 3.9614 - val_accuracy: 0.3355 - lr: 1.0000e-05\n",
      "Epoch 95/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.9779\n",
      "Epoch 00095: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 0.3837 - accuracy: 0.9779 - val_loss: 3.9599 - val_accuracy: 0.3359 - lr: 1.0000e-05\n",
      "Epoch 96/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3718 - accuracy: 0.9850\n",
      "Epoch 00096: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.3718 - accuracy: 0.9850 - val_loss: 3.9495 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 97/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3754 - accuracy: 0.9808\n",
      "Epoch 00097: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3754 - accuracy: 0.9808 - val_loss: 3.9806 - val_accuracy: 0.3355 - lr: 1.0000e-05\n",
      "Epoch 98/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3757 - accuracy: 0.9813\n",
      "Epoch 00098: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3757 - accuracy: 0.9813 - val_loss: 3.9580 - val_accuracy: 0.3374 - lr: 1.0000e-05\n",
      "Epoch 99/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3808 - accuracy: 0.9781\n",
      "Epoch 00099: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3808 - accuracy: 0.9781 - val_loss: 3.9510 - val_accuracy: 0.3374 - lr: 1.0000e-05\n",
      "Epoch 100/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3765 - accuracy: 0.9806\n",
      "Epoch 00100: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3765 - accuracy: 0.9806 - val_loss: 3.9585 - val_accuracy: 0.3386 - lr: 1.0000e-05\n",
      "Epoch 101/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3687 - accuracy: 0.9838\n",
      "Epoch 00101: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3687 - accuracy: 0.9838 - val_loss: 3.9330 - val_accuracy: 0.3371 - lr: 1.0000e-05\n",
      "Epoch 102/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3683 - accuracy: 0.9819\n",
      "Epoch 00102: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 0.3683 - accuracy: 0.9819 - val_loss: 3.9314 - val_accuracy: 0.3347 - lr: 1.0000e-05\n",
      "Epoch 103/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3689 - accuracy: 0.9815\n",
      "Epoch 00103: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 0.3689 - accuracy: 0.9815 - val_loss: 3.9914 - val_accuracy: 0.3413 - lr: 1.0000e-05\n",
      "Epoch 104/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3668 - accuracy: 0.9833\n",
      "Epoch 00104: val_accuracy did not improve from 0.37822\n",
      "163/163 [==============================] - 55s 338ms/step - loss: 0.3668 - accuracy: 0.9833 - val_loss: 3.9009 - val_accuracy: 0.3371 - lr: 1.0000e-05\n",
      "epoch_number 8\n",
      "train accuracy and validation accuracy 0.5341411828994751 0.37822240591049194\n",
      "82/82 [==============================] - 6s 73ms/step - loss: 3.3488 - accuracy: 0.3782\n",
      "test_accuracy 0.37822240591049194\n",
      "[0.3470565676689148, 0.3162754774093628, 0.3166602551937103, 0.3655252158641815, 0.37822240591049194]\n",
      "test_mean for %d subjects: 5\n",
      "0.3447479844093323\n",
      "/media/naveen/nav/mat_codes/nina_DB4_codes/naveen_prep_nlw/sub_wise_process_TT/S6_tr.csv\n",
      "Number of columns in the dataframe: 13\n",
      "Number of rows in the dataframe: 2080000\n",
      "\n",
      "/media/naveen/nav/mat_codes/nina_DB4_codes/naveen_prep_nlw/sub_wise_process_TT/S6_tt.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in the dataframe: 13\n",
      "Number of rows in the dataframe: 1040000\n",
      "\n",
      "x_train shape:  (5199, 400, 12)\n",
      "5199 training samples\n",
      "y_train shape:  (5199,)\n",
      "num_time_periods 400\n",
      "num_sensors 12\n",
      "class_list [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0]\n",
      "x_train shape: (400, 12)\n",
      "input_shape: (400, 12)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "New y_train shape:  (5199, 52)\n",
      "x_test shape:  (2599, 400, 12)\n",
      "2599 testing samples\n",
      "y_test shape:  (2599,)\n",
      "x_train shape:  (5199, 400, 12)\n",
      "x_test shape:  (2599, 400, 12)\n",
      "n_outputs 52\n",
      "Model: \"wei_mscnn_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main (InputLayer)               [(None, 400, 12)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_8 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_10 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_12 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_14 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_16 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_18 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_20 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_22 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_1 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_2 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_3 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_4 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_5 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_10[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_6 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_12[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_7 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_14[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_8 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_16[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_9 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_18[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_10 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_20[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_11 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_22[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [()]                 0           tf_op_layer_Shape_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_5 (Te [()]                 0           tf_op_layer_Shape_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_7 (Te [()]                 0           tf_op_layer_Shape_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_9 (Te [()]                 0           tf_op_layer_Shape_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_11 (T [()]                 0           tf_op_layer_Shape_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_13 (T [()]                 0           tf_op_layer_Shape_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_15 (T [()]                 0           tf_op_layer_Shape_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_17 (T [()]                 0           tf_op_layer_Shape_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_19 (T [()]                 0           tf_op_layer_Shape_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_21 (T [()]                 0           tf_op_layer_Shape_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_23 (T [()]                 0           tf_op_layer_Shape_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape/shape (Tens [(3,)]               0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1/shape (Te [(3,)]               0           tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2/shape (Te [(3,)]               0           tf_op_layer_strided_slice_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3/shape (Te [(3,)]               0           tf_op_layer_strided_slice_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4/shape (Te [(3,)]               0           tf_op_layer_strided_slice_9[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5/shape (Te [(3,)]               0           tf_op_layer_strided_slice_11[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6/shape (Te [(3,)]               0           tf_op_layer_strided_slice_13[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7/shape (Te [(3,)]               0           tf_op_layer_strided_slice_15[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8/shape (Te [(3,)]               0           tf_op_layer_strided_slice_17[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9/shape (Te [(3,)]               0           tf_op_layer_strided_slice_19[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_10/shape (T [(3,)]               0           tf_op_layer_strided_slice_21[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_11/shape (T [(3,)]               0           tf_op_layer_strided_slice_23[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 400, 1)]     0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 tf_op_layer_Reshape/shape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_2[0][0]\n",
      "                                                                 tf_op_layer_Reshape_1/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_4[0][0]\n",
      "                                                                 tf_op_layer_Reshape_2/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_6[0][0]\n",
      "                                                                 tf_op_layer_Reshape_3/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_8[0][0]\n",
      "                                                                 tf_op_layer_Reshape_4/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_10[0][0\n",
      "                                                                 tf_op_layer_Reshape_5/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_12[0][0\n",
      "                                                                 tf_op_layer_Reshape_6/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_14[0][0\n",
      "                                                                 tf_op_layer_Reshape_7/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_16[0][0\n",
      "                                                                 tf_op_layer_Reshape_8/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_18[0][0\n",
      "                                                                 tf_op_layer_Reshape_9/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_10 (TensorF [(None, 400, 1)]     0           tf_op_layer_strided_slice_20[0][0\n",
      "                                                                 tf_op_layer_Reshape_10/shape[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_11 (TensorF [(None, 400, 1)]     0           tf_op_layer_strided_slice_22[0][0\n",
      "                                                                 tf_op_layer_Reshape_11/shape[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 400, 64)      256         tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 400, 64)      256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 400, 64)      256         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 400, 64)      256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 400, 64)      256         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 400, 64)      256         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 400, 64)      256         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 400, 64)      256         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 400, 64)      256         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 400, 64)      256         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 400, 64)      256         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 400, 64)      256         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 400, 64)      256         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 400, 64)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 400, 64)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 400, 64)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 400, 64)      0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 400, 64)      0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 400, 64)      0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 400, 64)      0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 400, 64)      0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 400, 64)      0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 400, 64)      0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 400, 64)      0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 400, 64)      0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 400, 64)      12352       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 400, 64)      12352       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 400, 64)      12352       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 400, 64)      12352       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 400, 64)      12352       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 400, 64)      12352       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 400, 64)      12352       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 400, 64)      12352       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 400, 64)      12352       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 400, 64)      12352       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 400, 64)      12352       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 400, 64)      12352       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 400, 64)      256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 400, 64)      256         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 400, 64)      256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 400, 64)      256         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 400, 64)      256         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 400, 64)      256         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 400, 64)      256         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 400, 64)      256         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 400, 64)      256         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 400, 64)      256         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 400, 64)      256         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 400, 64)      256         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 400, 64)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 400, 64)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 400, 64)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 400, 64)      0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 400, 64)      0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 400, 64)      0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 400, 64)      0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 400, 64)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 400, 64)      0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 400, 64)      0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 400, 64)      0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 400, 64)      0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d (LocallyCon (None, 400, 64)      1664000     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_2 (LocallyC (None, 400, 64)      1664000     activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_4 (LocallyC (None, 400, 64)      1664000     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_6 (LocallyC (None, 400, 64)      1664000     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_8 (LocallyC (None, 400, 64)      1664000     activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_10 (Locally (None, 400, 64)      1664000     activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_12 (Locally (None, 400, 64)      1664000     activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_14 (Locally (None, 400, 64)      1664000     activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_16 (Locally (None, 400, 64)      1664000     activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_18 (Locally (None, 400, 64)      1664000     activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_20 (Locally (None, 400, 64)      1664000     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_22 (Locally (None, 400, 64)      1664000     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 400, 64)      256         locally_connected1d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 400, 64)      256         locally_connected1d_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 400, 64)      256         locally_connected1d_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 400, 64)      256         locally_connected1d_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 400, 64)      256         locally_connected1d_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 400, 64)      256         locally_connected1d_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 400, 64)      256         locally_connected1d_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 400, 64)      256         locally_connected1d_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 400, 64)      256         locally_connected1d_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 400, 64)      256         locally_connected1d_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 400, 64)      256         locally_connected1d_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 400, 64)      256         locally_connected1d_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 400, 64)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 400, 64)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 400, 64)      0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 400, 64)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 400, 64)      0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 400, 64)      0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 400, 64)      0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 400, 64)      0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 400, 64)      0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 400, 64)      0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 400, 64)      0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 400, 64)      0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_1 (LocallyC (None, 400, 64)      1664000     activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_3 (LocallyC (None, 400, 64)      1664000     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_5 (LocallyC (None, 400, 64)      1664000     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_7 (LocallyC (None, 400, 64)      1664000     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_9 (LocallyC (None, 400, 64)      1664000     activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_11 (Locally (None, 400, 64)      1664000     activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_13 (Locally (None, 400, 64)      1664000     activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_15 (Locally (None, 400, 64)      1664000     activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_17 (Locally (None, 400, 64)      1664000     activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_19 (Locally (None, 400, 64)      1664000     activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_21 (Locally (None, 400, 64)      1664000     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_23 (Locally (None, 400, 64)      1664000     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 400, 64)      256         locally_connected1d_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 400, 64)      256         locally_connected1d_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 400, 64)      256         locally_connected1d_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 400, 64)      256         locally_connected1d_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 400, 64)      256         locally_connected1d_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 400, 64)      256         locally_connected1d_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 400, 64)      256         locally_connected1d_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 400, 64)      256         locally_connected1d_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 400, 64)      256         locally_connected1d_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 400, 64)      256         locally_connected1d_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 400, 64)      256         locally_connected1d_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 400, 64)      256         locally_connected1d_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 400, 64)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 400, 64)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 400, 64)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 400, 64)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 400, 64)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 400, 64)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 400, 64)      0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 400, 64)      0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 400, 64)      0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 400, 64)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 400, 64)      0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 400, 64)      0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 400, 64)      0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 400, 64)      0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 400, 64)      0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 400, 64)      0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 400, 64)      0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 400, 64)      0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 400, 64)      0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 400, 64)      0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 400, 64)      0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 400, 64)      0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 400, 64)      0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 400, 64)      0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_stack (TensorFlowOp [(None, 400, 12, 64) 0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "                                                                 dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 307200)       0           tf_op_layer_stack[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          157286912   flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 512)          0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 512)          0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          262656      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 512)          0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 512)          0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          65664       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 128)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 128)          0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 52)           6708        activation_50[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 197,726,132\n",
      "Trainable params: 197,717,684\n",
      "Non-trainable params: 8,448\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 4.6067 - accuracy: 0.1402\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.26510, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 132s 807ms/step - loss: 4.6067 - accuracy: 0.1402 - val_loss: 3.4383 - val_accuracy: 0.2651 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.3854 - accuracy: 0.2581\n",
      "Epoch 00002: val_accuracy improved from 0.26510 to 0.32628, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 61s 376ms/step - loss: 3.3854 - accuracy: 0.2581 - val_loss: 3.1069 - val_accuracy: 0.3263 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.0660 - accuracy: 0.3372\n",
      "Epoch 00003: val_accuracy did not improve from 0.32628\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 3.0660 - accuracy: 0.3372 - val_loss: 3.1017 - val_accuracy: 0.3247 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.9440 - accuracy: 0.3883\n",
      "Epoch 00004: val_accuracy improved from 0.32628 to 0.37245, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 61s 377ms/step - loss: 2.9440 - accuracy: 0.3883 - val_loss: 3.0511 - val_accuracy: 0.3725 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.8276 - accuracy: 0.4299\n",
      "Epoch 00005: val_accuracy did not improve from 0.37245\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.8276 - accuracy: 0.4299 - val_loss: 3.1602 - val_accuracy: 0.3659 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.7334 - accuracy: 0.4662\n",
      "Epoch 00006: val_accuracy improved from 0.37245 to 0.37591, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 60s 371ms/step - loss: 2.7334 - accuracy: 0.4662 - val_loss: 3.1987 - val_accuracy: 0.3759 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.6325 - accuracy: 0.5043\n",
      "Epoch 00007: val_accuracy did not improve from 0.37591\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 2.6325 - accuracy: 0.5043 - val_loss: 3.2008 - val_accuracy: 0.3728 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.5398 - accuracy: 0.5468\n",
      "Epoch 00008: val_accuracy improved from 0.37591 to 0.39169, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 60s 370ms/step - loss: 2.5398 - accuracy: 0.5468 - val_loss: 3.2014 - val_accuracy: 0.3917 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.4269 - accuracy: 0.5724\n",
      "Epoch 00009: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 2.4269 - accuracy: 0.5724 - val_loss: 3.3497 - val_accuracy: 0.3836 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.3209 - accuracy: 0.6084\n",
      "Epoch 00010: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 2.3209 - accuracy: 0.6084 - val_loss: 3.3338 - val_accuracy: 0.3767 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.2618 - accuracy: 0.6297\n",
      "Epoch 00011: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.2618 - accuracy: 0.6297 - val_loss: 3.4202 - val_accuracy: 0.3690 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.2357 - accuracy: 0.6472\n",
      "Epoch 00012: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.2357 - accuracy: 0.6472 - val_loss: 3.4527 - val_accuracy: 0.3717 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.1432 - accuracy: 0.6805\n",
      "Epoch 00013: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.1432 - accuracy: 0.6805 - val_loss: 3.5319 - val_accuracy: 0.3567 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.0683 - accuracy: 0.6957\n",
      "Epoch 00014: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.0683 - accuracy: 0.6957 - val_loss: 3.5789 - val_accuracy: 0.3682 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.0604 - accuracy: 0.6996\n",
      "Epoch 00015: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.0604 - accuracy: 0.6996 - val_loss: 3.6116 - val_accuracy: 0.3832 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.9613 - accuracy: 0.7301\n",
      "Epoch 00016: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.9613 - accuracy: 0.7301 - val_loss: 3.6060 - val_accuracy: 0.3721 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.9375 - accuracy: 0.7394\n",
      "Epoch 00017: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.9375 - accuracy: 0.7394 - val_loss: 3.6237 - val_accuracy: 0.3825 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8315 - accuracy: 0.7690\n",
      "Epoch 00018: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.8315 - accuracy: 0.7690 - val_loss: 3.6414 - val_accuracy: 0.3601 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7797 - accuracy: 0.7798\n",
      "Epoch 00019: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.7797 - accuracy: 0.7798 - val_loss: 3.7515 - val_accuracy: 0.3628 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7603 - accuracy: 0.7828\n",
      "Epoch 00020: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.7603 - accuracy: 0.7828 - val_loss: 3.7891 - val_accuracy: 0.3640 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7055 - accuracy: 0.7977\n",
      "Epoch 00021: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.7055 - accuracy: 0.7977 - val_loss: 3.7799 - val_accuracy: 0.3690 - lr: 0.0010\n",
      "Epoch 22/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6192 - accuracy: 0.8217\n",
      "Epoch 00022: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 1.6192 - accuracy: 0.8217 - val_loss: 3.7788 - val_accuracy: 0.3671 - lr: 0.0010\n",
      "Epoch 23/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6517 - accuracy: 0.8059\n",
      "Epoch 00023: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.6517 - accuracy: 0.8059 - val_loss: 3.8331 - val_accuracy: 0.3574 - lr: 0.0010\n",
      "Epoch 24/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6457 - accuracy: 0.8190\n",
      "Epoch 00024: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 1.6457 - accuracy: 0.8190 - val_loss: 3.8893 - val_accuracy: 0.3605 - lr: 0.0010\n",
      "Epoch 25/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6369 - accuracy: 0.8292\n",
      "Epoch 00025: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.6369 - accuracy: 0.8292 - val_loss: 4.0128 - val_accuracy: 0.3594 - lr: 0.0010\n",
      "Epoch 26/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5589 - accuracy: 0.8388\n",
      "Epoch 00026: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.5589 - accuracy: 0.8388 - val_loss: 3.9339 - val_accuracy: 0.3628 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4750 - accuracy: 0.8432\n",
      "Epoch 00027: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.4750 - accuracy: 0.8432 - val_loss: 3.9142 - val_accuracy: 0.3617 - lr: 0.0010\n",
      "Epoch 28/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4557 - accuracy: 0.8536\n",
      "Epoch 00028: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.4557 - accuracy: 0.8536 - val_loss: 4.0007 - val_accuracy: 0.3590 - lr: 0.0010\n",
      "Epoch 29/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5155 - accuracy: 0.8427\n",
      "Epoch 00029: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.5155 - accuracy: 0.8427 - val_loss: 4.0440 - val_accuracy: 0.3528 - lr: 0.0010\n",
      "Epoch 30/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5046 - accuracy: 0.8517\n",
      "Epoch 00030: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 1.5046 - accuracy: 0.8517 - val_loss: 3.9851 - val_accuracy: 0.3655 - lr: 0.0010\n",
      "Epoch 31/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4189 - accuracy: 0.8700\n",
      "Epoch 00031: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.4189 - accuracy: 0.8700 - val_loss: 4.0265 - val_accuracy: 0.3594 - lr: 0.0010\n",
      "Epoch 32/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4130 - accuracy: 0.8561\n",
      "Epoch 00032: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 1.4130 - accuracy: 0.8561 - val_loss: 4.0709 - val_accuracy: 0.3555 - lr: 0.0010\n",
      "Epoch 33/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3907 - accuracy: 0.8761\n",
      "Epoch 00033: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.3907 - accuracy: 0.8761 - val_loss: 4.1235 - val_accuracy: 0.3524 - lr: 0.0010\n",
      "Epoch 34/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3438 - accuracy: 0.8777\n",
      "Epoch 00034: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.3438 - accuracy: 0.8777 - val_loss: 4.0944 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 35/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3212 - accuracy: 0.8796\n",
      "Epoch 00035: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.3212 - accuracy: 0.8796 - val_loss: 4.1237 - val_accuracy: 0.3582 - lr: 0.0010\n",
      "Epoch 36/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3463 - accuracy: 0.8811\n",
      "Epoch 00036: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.3463 - accuracy: 0.8811 - val_loss: 4.1620 - val_accuracy: 0.3517 - lr: 0.0010\n",
      "Epoch 37/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3123 - accuracy: 0.8811\n",
      "Epoch 00037: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.3123 - accuracy: 0.8811 - val_loss: 4.2637 - val_accuracy: 0.3436 - lr: 0.0010\n",
      "Epoch 38/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3145 - accuracy: 0.8881\n",
      "Epoch 00038: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.3145 - accuracy: 0.8881 - val_loss: 4.1643 - val_accuracy: 0.3521 - lr: 0.0010\n",
      "Epoch 39/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.2438 - accuracy: 0.8931\n",
      "Epoch 00039: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.2438 - accuracy: 0.8931 - val_loss: 4.2227 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 40/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.1555 - accuracy: 0.9175\n",
      "Epoch 00040: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.1555 - accuracy: 0.9175 - val_loss: 4.0086 - val_accuracy: 0.3513 - lr: 1.0000e-04\n",
      "Epoch 41/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0819 - accuracy: 0.9321\n",
      "Epoch 00041: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.0819 - accuracy: 0.9321 - val_loss: 3.9947 - val_accuracy: 0.3528 - lr: 1.0000e-04\n",
      "Epoch 42/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0294 - accuracy: 0.9369\n",
      "Epoch 00042: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.0294 - accuracy: 0.9369 - val_loss: 3.9257 - val_accuracy: 0.3567 - lr: 1.0000e-04\n",
      "Epoch 43/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9847 - accuracy: 0.9438\n",
      "Epoch 00043: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.9847 - accuracy: 0.9438 - val_loss: 3.8972 - val_accuracy: 0.3563 - lr: 1.0000e-04\n",
      "Epoch 44/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9530 - accuracy: 0.9436\n",
      "Epoch 00044: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.9530 - accuracy: 0.9436 - val_loss: 3.9023 - val_accuracy: 0.3501 - lr: 1.0000e-04\n",
      "Epoch 45/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9209 - accuracy: 0.9460\n",
      "Epoch 00045: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.9209 - accuracy: 0.9460 - val_loss: 3.8812 - val_accuracy: 0.3598 - lr: 1.0000e-04\n",
      "Epoch 46/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8868 - accuracy: 0.9508\n",
      "Epoch 00046: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.8868 - accuracy: 0.9508 - val_loss: 3.8839 - val_accuracy: 0.3571 - lr: 1.0000e-04\n",
      "Epoch 47/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8610 - accuracy: 0.9517\n",
      "Epoch 00047: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.8610 - accuracy: 0.9517 - val_loss: 3.8702 - val_accuracy: 0.3574 - lr: 1.0000e-04\n",
      "Epoch 48/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8266 - accuracy: 0.9598\n",
      "Epoch 00048: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.8266 - accuracy: 0.9598 - val_loss: 3.8526 - val_accuracy: 0.3605 - lr: 1.0000e-04\n",
      "Epoch 49/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8185 - accuracy: 0.9531\n",
      "Epoch 00049: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.8185 - accuracy: 0.9531 - val_loss: 3.8415 - val_accuracy: 0.3517 - lr: 1.0000e-04\n",
      "Epoch 50/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7886 - accuracy: 0.9585\n",
      "Epoch 00050: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.7886 - accuracy: 0.9585 - val_loss: 3.8079 - val_accuracy: 0.3582 - lr: 1.0000e-04\n",
      "Epoch 51/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7487 - accuracy: 0.9671\n",
      "Epoch 00051: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.7487 - accuracy: 0.9671 - val_loss: 3.7894 - val_accuracy: 0.3574 - lr: 1.0000e-04\n",
      "Epoch 52/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7354 - accuracy: 0.9644\n",
      "Epoch 00052: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.7354 - accuracy: 0.9644 - val_loss: 3.7940 - val_accuracy: 0.3590 - lr: 1.0000e-04\n",
      "Epoch 53/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7052 - accuracy: 0.9690\n",
      "Epoch 00053: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 0.7052 - accuracy: 0.9690 - val_loss: 3.8463 - val_accuracy: 0.3501 - lr: 1.0000e-04\n",
      "Epoch 54/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6959 - accuracy: 0.9690\n",
      "Epoch 00054: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.6959 - accuracy: 0.9690 - val_loss: 3.8182 - val_accuracy: 0.3521 - lr: 1.0000e-04\n",
      "Epoch 55/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6737 - accuracy: 0.9683\n",
      "Epoch 00055: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.6737 - accuracy: 0.9683 - val_loss: 3.8622 - val_accuracy: 0.3497 - lr: 1.0000e-04\n",
      "Epoch 56/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6590 - accuracy: 0.9715\n",
      "Epoch 00056: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.6590 - accuracy: 0.9715 - val_loss: 3.8026 - val_accuracy: 0.3567 - lr: 1.0000e-04\n",
      "Epoch 57/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6401 - accuracy: 0.9706\n",
      "Epoch 00057: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.6401 - accuracy: 0.9706 - val_loss: 3.7827 - val_accuracy: 0.3578 - lr: 1.0000e-04\n",
      "Epoch 58/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6281 - accuracy: 0.9686\n",
      "Epoch 00058: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.6281 - accuracy: 0.9686 - val_loss: 3.7761 - val_accuracy: 0.3578 - lr: 1.0000e-04\n",
      "Epoch 59/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6159 - accuracy: 0.9683\n",
      "Epoch 00059: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.6159 - accuracy: 0.9683 - val_loss: 3.7593 - val_accuracy: 0.3559 - lr: 1.0000e-04\n",
      "Epoch 60/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5961 - accuracy: 0.9738\n",
      "Epoch 00060: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.5961 - accuracy: 0.9738 - val_loss: 3.6955 - val_accuracy: 0.3540 - lr: 1.0000e-04\n",
      "Epoch 61/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5749 - accuracy: 0.9777\n",
      "Epoch 00061: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.5749 - accuracy: 0.9777 - val_loss: 3.7355 - val_accuracy: 0.3563 - lr: 1.0000e-04\n",
      "Epoch 62/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5767 - accuracy: 0.9723\n",
      "Epoch 00062: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.5767 - accuracy: 0.9723 - val_loss: 3.7433 - val_accuracy: 0.3544 - lr: 1.0000e-04\n",
      "Epoch 63/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5536 - accuracy: 0.9777\n",
      "Epoch 00063: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.5536 - accuracy: 0.9777 - val_loss: 3.7414 - val_accuracy: 0.3517 - lr: 1.0000e-04\n",
      "Epoch 64/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5432 - accuracy: 0.9735\n",
      "Epoch 00064: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.5432 - accuracy: 0.9735 - val_loss: 3.7848 - val_accuracy: 0.3551 - lr: 1.0000e-04\n",
      "Epoch 65/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5272 - accuracy: 0.9771\n",
      "Epoch 00065: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.5272 - accuracy: 0.9771 - val_loss: 3.7325 - val_accuracy: 0.3559 - lr: 1.0000e-04\n",
      "Epoch 66/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5223 - accuracy: 0.9769\n",
      "Epoch 00066: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.5223 - accuracy: 0.9769 - val_loss: 3.7757 - val_accuracy: 0.3524 - lr: 1.0000e-04\n",
      "Epoch 67/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5062 - accuracy: 0.9792\n",
      "Epoch 00067: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.5062 - accuracy: 0.9792 - val_loss: 3.7358 - val_accuracy: 0.3571 - lr: 1.0000e-04\n",
      "Epoch 68/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5000 - accuracy: 0.9767\n",
      "Epoch 00068: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.5000 - accuracy: 0.9767 - val_loss: 3.7401 - val_accuracy: 0.3517 - lr: 1.0000e-04\n",
      "Epoch 69/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4922 - accuracy: 0.9756\n",
      "Epoch 00069: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4922 - accuracy: 0.9756 - val_loss: 3.6966 - val_accuracy: 0.3524 - lr: 1.0000e-04\n",
      "Epoch 70/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4851 - accuracy: 0.9752\n",
      "Epoch 00070: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4851 - accuracy: 0.9752 - val_loss: 3.7623 - val_accuracy: 0.3559 - lr: 1.0000e-04\n",
      "Epoch 71/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4709 - accuracy: 0.9777\n",
      "Epoch 00071: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4709 - accuracy: 0.9777 - val_loss: 3.7502 - val_accuracy: 0.3563 - lr: 1.0000e-04\n",
      "Epoch 72/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4682 - accuracy: 0.9760\n",
      "Epoch 00072: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.4682 - accuracy: 0.9760 - val_loss: 3.7629 - val_accuracy: 0.3555 - lr: 1.0000e-04\n",
      "Epoch 73/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4569 - accuracy: 0.9800\n",
      "Epoch 00073: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4569 - accuracy: 0.9800 - val_loss: 3.7492 - val_accuracy: 0.3574 - lr: 1.0000e-04\n",
      "Epoch 74/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4526 - accuracy: 0.9765\n",
      "Epoch 00074: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4526 - accuracy: 0.9765 - val_loss: 3.7787 - val_accuracy: 0.3555 - lr: 1.0000e-04\n",
      "Epoch 75/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4368 - accuracy: 0.9804\n",
      "Epoch 00075: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4368 - accuracy: 0.9804 - val_loss: 3.7486 - val_accuracy: 0.3532 - lr: 1.0000e-04\n",
      "Epoch 76/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4252 - accuracy: 0.9825\n",
      "Epoch 00076: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4252 - accuracy: 0.9825 - val_loss: 3.7827 - val_accuracy: 0.3551 - lr: 1.0000e-04\n",
      "Epoch 77/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4133 - accuracy: 0.9827\n",
      "Epoch 00077: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4133 - accuracy: 0.9827 - val_loss: 3.7530 - val_accuracy: 0.3497 - lr: 1.0000e-04\n",
      "Epoch 78/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4158 - accuracy: 0.9808\n",
      "Epoch 00078: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4158 - accuracy: 0.9808 - val_loss: 3.7512 - val_accuracy: 0.3474 - lr: 1.0000e-04\n",
      "Epoch 79/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4101 - accuracy: 0.9792\n",
      "Epoch 00079: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4101 - accuracy: 0.9792 - val_loss: 3.8061 - val_accuracy: 0.3482 - lr: 1.0000e-04\n",
      "Epoch 80/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3957 - accuracy: 0.9833\n",
      "Epoch 00080: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 0.3957 - accuracy: 0.9833 - val_loss: 3.7783 - val_accuracy: 0.3555 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3986 - accuracy: 0.9840\n",
      "Epoch 00081: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.3986 - accuracy: 0.9840 - val_loss: 3.7893 - val_accuracy: 0.3574 - lr: 1.0000e-05\n",
      "Epoch 82/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3939 - accuracy: 0.9831\n",
      "Epoch 00082: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.3939 - accuracy: 0.9831 - val_loss: 3.7467 - val_accuracy: 0.3513 - lr: 1.0000e-05\n",
      "Epoch 83/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4021 - accuracy: 0.9798\n",
      "Epoch 00083: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.4021 - accuracy: 0.9798 - val_loss: 3.7811 - val_accuracy: 0.3486 - lr: 1.0000e-05\n",
      "Epoch 84/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3951 - accuracy: 0.9835\n",
      "Epoch 00084: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.3951 - accuracy: 0.9835 - val_loss: 3.7826 - val_accuracy: 0.3551 - lr: 1.0000e-05\n",
      "Epoch 85/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3925 - accuracy: 0.9833\n",
      "Epoch 00085: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3925 - accuracy: 0.9833 - val_loss: 3.7413 - val_accuracy: 0.3548 - lr: 1.0000e-05\n",
      "Epoch 86/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3908 - accuracy: 0.9838\n",
      "Epoch 00086: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.3908 - accuracy: 0.9838 - val_loss: 3.7903 - val_accuracy: 0.3528 - lr: 1.0000e-05\n",
      "Epoch 87/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3867 - accuracy: 0.9856\n",
      "Epoch 00087: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.3867 - accuracy: 0.9856 - val_loss: 3.7714 - val_accuracy: 0.3517 - lr: 1.0000e-05\n",
      "Epoch 88/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3966 - accuracy: 0.9810\n",
      "Epoch 00088: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3966 - accuracy: 0.9810 - val_loss: 3.7921 - val_accuracy: 0.3521 - lr: 1.0000e-05\n",
      "Epoch 89/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3914 - accuracy: 0.9806\n",
      "Epoch 00089: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.3914 - accuracy: 0.9806 - val_loss: 3.8074 - val_accuracy: 0.3574 - lr: 1.0000e-05\n",
      "Epoch 90/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.9842\n",
      "Epoch 00090: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.3853 - accuracy: 0.9842 - val_loss: 3.7365 - val_accuracy: 0.3571 - lr: 1.0000e-05\n",
      "Epoch 91/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.9827\n",
      "Epoch 00091: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.3853 - accuracy: 0.9827 - val_loss: 3.7703 - val_accuracy: 0.3528 - lr: 1.0000e-05\n",
      "Epoch 92/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3860 - accuracy: 0.9825\n",
      "Epoch 00092: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.3860 - accuracy: 0.9825 - val_loss: 3.7501 - val_accuracy: 0.3563 - lr: 1.0000e-05\n",
      "Epoch 93/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3924 - accuracy: 0.9800\n",
      "Epoch 00093: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.3924 - accuracy: 0.9800 - val_loss: 3.8027 - val_accuracy: 0.3490 - lr: 1.0000e-05\n",
      "Epoch 94/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3881 - accuracy: 0.9835\n",
      "Epoch 00094: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.3881 - accuracy: 0.9835 - val_loss: 3.7383 - val_accuracy: 0.3567 - lr: 1.0000e-05\n",
      "Epoch 95/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3907 - accuracy: 0.9800\n",
      "Epoch 00095: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3907 - accuracy: 0.9800 - val_loss: 3.7776 - val_accuracy: 0.3567 - lr: 1.0000e-05\n",
      "Epoch 96/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3917 - accuracy: 0.9806\n",
      "Epoch 00096: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.3917 - accuracy: 0.9806 - val_loss: 3.7845 - val_accuracy: 0.3521 - lr: 1.0000e-05\n",
      "Epoch 97/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3918 - accuracy: 0.9792\n",
      "Epoch 00097: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3918 - accuracy: 0.9792 - val_loss: 3.7607 - val_accuracy: 0.3644 - lr: 1.0000e-05\n",
      "Epoch 98/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3798 - accuracy: 0.9829\n",
      "Epoch 00098: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3798 - accuracy: 0.9829 - val_loss: 3.7654 - val_accuracy: 0.3563 - lr: 1.0000e-05\n",
      "Epoch 99/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3777 - accuracy: 0.9858\n",
      "Epoch 00099: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.3777 - accuracy: 0.9858 - val_loss: 3.8133 - val_accuracy: 0.3517 - lr: 1.0000e-05\n",
      "Epoch 100/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3883 - accuracy: 0.9800\n",
      "Epoch 00100: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.3883 - accuracy: 0.9800 - val_loss: 3.7256 - val_accuracy: 0.3574 - lr: 1.0000e-05\n",
      "Epoch 101/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.9812\n",
      "Epoch 00101: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.3838 - accuracy: 0.9812 - val_loss: 3.7247 - val_accuracy: 0.3559 - lr: 1.0000e-05\n",
      "Epoch 102/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3812 - accuracy: 0.9815\n",
      "Epoch 00102: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.3812 - accuracy: 0.9815 - val_loss: 3.7534 - val_accuracy: 0.3571 - lr: 1.0000e-05\n",
      "Epoch 103/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3782 - accuracy: 0.9835\n",
      "Epoch 00103: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.3782 - accuracy: 0.9835 - val_loss: 3.7194 - val_accuracy: 0.3578 - lr: 1.0000e-05\n",
      "Epoch 104/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3765 - accuracy: 0.9842\n",
      "Epoch 00104: val_accuracy did not improve from 0.39169\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 0.3765 - accuracy: 0.9842 - val_loss: 3.7402 - val_accuracy: 0.3548 - lr: 1.0000e-05\n",
      "epoch_number 8\n",
      "train accuracy and validation accuracy 0.5468359589576721 0.39168912172317505\n",
      "82/82 [==============================] - 6s 74ms/step - loss: 3.2014 - accuracy: 0.3917\n",
      "test_accuracy 0.39168912172317505\n",
      "[0.3470565676689148, 0.3162754774093628, 0.3166602551937103, 0.3655252158641815, 0.37822240591049194, 0.39168912172317505]\n",
      "test_mean for %d subjects: 6\n",
      "0.3525715072949727\n",
      "/media/naveen/nav/mat_codes/nina_DB4_codes/naveen_prep_nlw/sub_wise_process_TT/S7_tr.csv\n",
      "Number of columns in the dataframe: 13\n",
      "Number of rows in the dataframe: 2080000\n",
      "\n",
      "/media/naveen/nav/mat_codes/nina_DB4_codes/naveen_prep_nlw/sub_wise_process_TT/S7_tt.csv\n",
      "Number of columns in the dataframe: 13\n",
      "Number of rows in the dataframe: 1040000\n",
      "\n",
      "x_train shape:  (5199, 400, 12)\n",
      "5199 training samples\n",
      "y_train shape:  (5199,)\n",
      "num_time_periods 400\n",
      "num_sensors 12\n",
      "class_list [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0]\n",
      "x_train shape: (400, 12)\n",
      "input_shape: (400, 12)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "New y_train shape:  (5199, 52)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test shape:  (2599, 400, 12)\n",
      "2599 testing samples\n",
      "y_test shape:  (2599,)\n",
      "x_train shape:  (5199, 400, 12)\n",
      "x_test shape:  (2599, 400, 12)\n",
      "n_outputs 52\n",
      "Model: \"wei_mscnn_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main (InputLayer)               [(None, 400, 12)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_8 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_10 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_12 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_14 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_16 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_18 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_20 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_22 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_1 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_2 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_3 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_4 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_5 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_10[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_6 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_12[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_7 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_14[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_8 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_16[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_9 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_18[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_10 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_20[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_11 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_22[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [()]                 0           tf_op_layer_Shape_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_5 (Te [()]                 0           tf_op_layer_Shape_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_7 (Te [()]                 0           tf_op_layer_Shape_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_9 (Te [()]                 0           tf_op_layer_Shape_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_11 (T [()]                 0           tf_op_layer_Shape_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_13 (T [()]                 0           tf_op_layer_Shape_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_15 (T [()]                 0           tf_op_layer_Shape_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_17 (T [()]                 0           tf_op_layer_Shape_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_19 (T [()]                 0           tf_op_layer_Shape_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_21 (T [()]                 0           tf_op_layer_Shape_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_23 (T [()]                 0           tf_op_layer_Shape_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape/shape (Tens [(3,)]               0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1/shape (Te [(3,)]               0           tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2/shape (Te [(3,)]               0           tf_op_layer_strided_slice_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3/shape (Te [(3,)]               0           tf_op_layer_strided_slice_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4/shape (Te [(3,)]               0           tf_op_layer_strided_slice_9[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5/shape (Te [(3,)]               0           tf_op_layer_strided_slice_11[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6/shape (Te [(3,)]               0           tf_op_layer_strided_slice_13[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7/shape (Te [(3,)]               0           tf_op_layer_strided_slice_15[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8/shape (Te [(3,)]               0           tf_op_layer_strided_slice_17[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9/shape (Te [(3,)]               0           tf_op_layer_strided_slice_19[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_10/shape (T [(3,)]               0           tf_op_layer_strided_slice_21[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_11/shape (T [(3,)]               0           tf_op_layer_strided_slice_23[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 400, 1)]     0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 tf_op_layer_Reshape/shape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_2[0][0]\n",
      "                                                                 tf_op_layer_Reshape_1/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_4[0][0]\n",
      "                                                                 tf_op_layer_Reshape_2/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_6[0][0]\n",
      "                                                                 tf_op_layer_Reshape_3/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_8[0][0]\n",
      "                                                                 tf_op_layer_Reshape_4/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_10[0][0\n",
      "                                                                 tf_op_layer_Reshape_5/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_12[0][0\n",
      "                                                                 tf_op_layer_Reshape_6/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_14[0][0\n",
      "                                                                 tf_op_layer_Reshape_7/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_16[0][0\n",
      "                                                                 tf_op_layer_Reshape_8/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_18[0][0\n",
      "                                                                 tf_op_layer_Reshape_9/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_10 (TensorF [(None, 400, 1)]     0           tf_op_layer_strided_slice_20[0][0\n",
      "                                                                 tf_op_layer_Reshape_10/shape[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_11 (TensorF [(None, 400, 1)]     0           tf_op_layer_strided_slice_22[0][0\n",
      "                                                                 tf_op_layer_Reshape_11/shape[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 400, 64)      256         tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 400, 64)      256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 400, 64)      256         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 400, 64)      256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 400, 64)      256         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 400, 64)      256         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 400, 64)      256         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 400, 64)      256         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 400, 64)      256         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 400, 64)      256         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 400, 64)      256         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 400, 64)      256         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 400, 64)      256         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 400, 64)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 400, 64)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 400, 64)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 400, 64)      0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 400, 64)      0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 400, 64)      0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 400, 64)      0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 400, 64)      0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 400, 64)      0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 400, 64)      0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 400, 64)      0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 400, 64)      0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 400, 64)      12352       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 400, 64)      12352       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 400, 64)      12352       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 400, 64)      12352       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 400, 64)      12352       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 400, 64)      12352       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 400, 64)      12352       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 400, 64)      12352       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 400, 64)      12352       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 400, 64)      12352       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 400, 64)      12352       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 400, 64)      12352       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 400, 64)      256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 400, 64)      256         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 400, 64)      256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 400, 64)      256         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 400, 64)      256         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 400, 64)      256         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 400, 64)      256         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 400, 64)      256         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 400, 64)      256         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 400, 64)      256         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 400, 64)      256         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 400, 64)      256         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 400, 64)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 400, 64)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 400, 64)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 400, 64)      0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 400, 64)      0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 400, 64)      0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 400, 64)      0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 400, 64)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 400, 64)      0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 400, 64)      0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 400, 64)      0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 400, 64)      0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d (LocallyCon (None, 400, 64)      1664000     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_2 (LocallyC (None, 400, 64)      1664000     activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_4 (LocallyC (None, 400, 64)      1664000     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_6 (LocallyC (None, 400, 64)      1664000     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_8 (LocallyC (None, 400, 64)      1664000     activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_10 (Locally (None, 400, 64)      1664000     activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_12 (Locally (None, 400, 64)      1664000     activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_14 (Locally (None, 400, 64)      1664000     activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_16 (Locally (None, 400, 64)      1664000     activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_18 (Locally (None, 400, 64)      1664000     activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_20 (Locally (None, 400, 64)      1664000     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_22 (Locally (None, 400, 64)      1664000     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 400, 64)      256         locally_connected1d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 400, 64)      256         locally_connected1d_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 400, 64)      256         locally_connected1d_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 400, 64)      256         locally_connected1d_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 400, 64)      256         locally_connected1d_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 400, 64)      256         locally_connected1d_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 400, 64)      256         locally_connected1d_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 400, 64)      256         locally_connected1d_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 400, 64)      256         locally_connected1d_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 400, 64)      256         locally_connected1d_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 400, 64)      256         locally_connected1d_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 400, 64)      256         locally_connected1d_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 400, 64)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 400, 64)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 400, 64)      0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 400, 64)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 400, 64)      0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 400, 64)      0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 400, 64)      0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 400, 64)      0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 400, 64)      0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 400, 64)      0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 400, 64)      0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 400, 64)      0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_1 (LocallyC (None, 400, 64)      1664000     activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_3 (LocallyC (None, 400, 64)      1664000     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_5 (LocallyC (None, 400, 64)      1664000     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_7 (LocallyC (None, 400, 64)      1664000     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_9 (LocallyC (None, 400, 64)      1664000     activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_11 (Locally (None, 400, 64)      1664000     activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_13 (Locally (None, 400, 64)      1664000     activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_15 (Locally (None, 400, 64)      1664000     activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_17 (Locally (None, 400, 64)      1664000     activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_19 (Locally (None, 400, 64)      1664000     activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_21 (Locally (None, 400, 64)      1664000     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_23 (Locally (None, 400, 64)      1664000     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 400, 64)      256         locally_connected1d_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 400, 64)      256         locally_connected1d_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 400, 64)      256         locally_connected1d_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 400, 64)      256         locally_connected1d_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 400, 64)      256         locally_connected1d_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 400, 64)      256         locally_connected1d_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 400, 64)      256         locally_connected1d_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 400, 64)      256         locally_connected1d_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 400, 64)      256         locally_connected1d_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 400, 64)      256         locally_connected1d_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 400, 64)      256         locally_connected1d_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 400, 64)      256         locally_connected1d_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 400, 64)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 400, 64)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 400, 64)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 400, 64)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 400, 64)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 400, 64)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 400, 64)      0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 400, 64)      0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 400, 64)      0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 400, 64)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 400, 64)      0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 400, 64)      0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 400, 64)      0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 400, 64)      0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 400, 64)      0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 400, 64)      0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 400, 64)      0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 400, 64)      0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 400, 64)      0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 400, 64)      0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 400, 64)      0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 400, 64)      0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 400, 64)      0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 400, 64)      0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_stack (TensorFlowOp [(None, 400, 12, 64) 0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "                                                                 dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 307200)       0           tf_op_layer_stack[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          157286912   flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 512)          0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 512)          0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          262656      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 512)          0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 512)          0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          65664       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 128)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 128)          0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 52)           6708        activation_50[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 197,726,132\n",
      "Trainable params: 197,717,684\n",
      "Non-trainable params: 8,448\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - ETA: 0s - loss: 4.5955 - accuracy: 0.1154\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.20700, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 123s 757ms/step - loss: 4.5955 - accuracy: 0.1154 - val_loss: 3.6509 - val_accuracy: 0.2070 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.5396 - accuracy: 0.2206\n",
      "Epoch 00002: val_accuracy improved from 0.20700 to 0.24471, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 62s 378ms/step - loss: 3.5396 - accuracy: 0.2206 - val_loss: 3.3707 - val_accuracy: 0.2447 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.3431 - accuracy: 0.2766\n",
      "Epoch 00003: val_accuracy improved from 0.24471 to 0.26395, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 60s 369ms/step - loss: 3.3431 - accuracy: 0.2766 - val_loss: 3.4238 - val_accuracy: 0.2639 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.1987 - accuracy: 0.3418\n",
      "Epoch 00004: val_accuracy improved from 0.26395 to 0.28934, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 61s 372ms/step - loss: 3.1987 - accuracy: 0.3418 - val_loss: 3.4687 - val_accuracy: 0.2893 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.1539 - accuracy: 0.3687\n",
      "Epoch 00005: val_accuracy improved from 0.28934 to 0.30012, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 60s 370ms/step - loss: 3.1539 - accuracy: 0.3687 - val_loss: 3.4806 - val_accuracy: 0.3001 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.0608 - accuracy: 0.4045\n",
      "Epoch 00006: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 3.0608 - accuracy: 0.4045 - val_loss: 3.6271 - val_accuracy: 0.2924 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.9725 - accuracy: 0.4441\n",
      "Epoch 00007: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 2.9725 - accuracy: 0.4441 - val_loss: 3.6375 - val_accuracy: 0.2855 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.8712 - accuracy: 0.4830\n",
      "Epoch 00008: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 2.8712 - accuracy: 0.4830 - val_loss: 3.6771 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.7557 - accuracy: 0.5097\n",
      "Epoch 00009: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.7557 - accuracy: 0.5097 - val_loss: 3.7548 - val_accuracy: 0.2816 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.6857 - accuracy: 0.5359\n",
      "Epoch 00010: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.6857 - accuracy: 0.5359 - val_loss: 3.7741 - val_accuracy: 0.2928 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.5369 - accuracy: 0.5843\n",
      "Epoch 00011: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 2.5369 - accuracy: 0.5843 - val_loss: 3.8561 - val_accuracy: 0.2928 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.5471 - accuracy: 0.5932\n",
      "Epoch 00012: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 2.5471 - accuracy: 0.5932 - val_loss: 3.9393 - val_accuracy: 0.2893 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.4857 - accuracy: 0.6097\n",
      "Epoch 00013: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.4857 - accuracy: 0.6097 - val_loss: 4.0500 - val_accuracy: 0.2763 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.3938 - accuracy: 0.6392\n",
      "Epoch 00014: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 2.3938 - accuracy: 0.6392 - val_loss: 4.1311 - val_accuracy: 0.2755 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.3375 - accuracy: 0.6626\n",
      "Epoch 00015: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.3375 - accuracy: 0.6626 - val_loss: 4.1823 - val_accuracy: 0.2766 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.2465 - accuracy: 0.6726\n",
      "Epoch 00016: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 2.2465 - accuracy: 0.6726 - val_loss: 4.1784 - val_accuracy: 0.2778 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.2017 - accuracy: 0.6951\n",
      "Epoch 00017: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.2017 - accuracy: 0.6951 - val_loss: 4.3300 - val_accuracy: 0.2513 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.1168 - accuracy: 0.7078\n",
      "Epoch 00018: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 2.1168 - accuracy: 0.7078 - val_loss: 4.2808 - val_accuracy: 0.2663 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.1395 - accuracy: 0.7076\n",
      "Epoch 00019: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 2.1395 - accuracy: 0.7076 - val_loss: 4.3486 - val_accuracy: 0.2770 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.0915 - accuracy: 0.7267\n",
      "Epoch 00020: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 2.0915 - accuracy: 0.7267 - val_loss: 4.3587 - val_accuracy: 0.2632 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.0024 - accuracy: 0.7396\n",
      "Epoch 00021: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.0024 - accuracy: 0.7396 - val_loss: 4.4214 - val_accuracy: 0.2709 - lr: 0.0010\n",
      "Epoch 22/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8992 - accuracy: 0.7700\n",
      "Epoch 00022: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 1.8992 - accuracy: 0.7700 - val_loss: 4.3243 - val_accuracy: 0.2759 - lr: 0.0010\n",
      "Epoch 23/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.9231 - accuracy: 0.7553\n",
      "Epoch 00023: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.9231 - accuracy: 0.7553 - val_loss: 4.3726 - val_accuracy: 0.2828 - lr: 0.0010\n",
      "Epoch 24/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.9255 - accuracy: 0.7688\n",
      "Epoch 00024: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.9255 - accuracy: 0.7688 - val_loss: 4.5018 - val_accuracy: 0.2678 - lr: 0.0010\n",
      "Epoch 25/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8763 - accuracy: 0.7736\n",
      "Epoch 00025: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.8763 - accuracy: 0.7736 - val_loss: 4.6498 - val_accuracy: 0.2520 - lr: 0.0010\n",
      "Epoch 26/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8456 - accuracy: 0.7798\n",
      "Epoch 00026: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.8456 - accuracy: 0.7798 - val_loss: 4.6492 - val_accuracy: 0.2732 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7848 - accuracy: 0.7932\n",
      "Epoch 00027: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 1.7848 - accuracy: 0.7932 - val_loss: 4.6134 - val_accuracy: 0.2724 - lr: 0.0010\n",
      "Epoch 28/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7581 - accuracy: 0.7988\n",
      "Epoch 00028: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.7581 - accuracy: 0.7988 - val_loss: 4.6971 - val_accuracy: 0.2705 - lr: 0.0010\n",
      "Epoch 29/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7573 - accuracy: 0.7928\n",
      "Epoch 00029: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.7573 - accuracy: 0.7928 - val_loss: 4.8100 - val_accuracy: 0.2597 - lr: 0.0010\n",
      "Epoch 30/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6986 - accuracy: 0.8221\n",
      "Epoch 00030: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 1.6986 - accuracy: 0.8221 - val_loss: 4.7621 - val_accuracy: 0.2609 - lr: 0.0010\n",
      "Epoch 31/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7003 - accuracy: 0.8169\n",
      "Epoch 00031: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 1.7003 - accuracy: 0.8169 - val_loss: 4.8176 - val_accuracy: 0.2666 - lr: 0.0010\n",
      "Epoch 32/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6910 - accuracy: 0.8204\n",
      "Epoch 00032: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.6910 - accuracy: 0.8204 - val_loss: 4.9040 - val_accuracy: 0.2536 - lr: 0.0010\n",
      "Epoch 33/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6200 - accuracy: 0.8334\n",
      "Epoch 00033: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.6200 - accuracy: 0.8334 - val_loss: 4.8407 - val_accuracy: 0.2551 - lr: 0.0010\n",
      "Epoch 34/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5448 - accuracy: 0.8473\n",
      "Epoch 00034: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.5448 - accuracy: 0.8473 - val_loss: 4.8817 - val_accuracy: 0.2536 - lr: 0.0010\n",
      "Epoch 35/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5765 - accuracy: 0.8430\n",
      "Epoch 00035: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.5765 - accuracy: 0.8430 - val_loss: 4.9129 - val_accuracy: 0.2578 - lr: 0.0010\n",
      "Epoch 36/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5758 - accuracy: 0.8442\n",
      "Epoch 00036: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.5758 - accuracy: 0.8442 - val_loss: 5.0711 - val_accuracy: 0.2593 - lr: 0.0010\n",
      "Epoch 37/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5681 - accuracy: 0.8432\n",
      "Epoch 00037: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.5681 - accuracy: 0.8432 - val_loss: 5.0284 - val_accuracy: 0.2559 - lr: 0.0010\n",
      "Epoch 38/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5445 - accuracy: 0.8540\n",
      "Epoch 00038: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 1.5445 - accuracy: 0.8540 - val_loss: 5.0431 - val_accuracy: 0.2566 - lr: 0.0010\n",
      "Epoch 39/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5344 - accuracy: 0.8527\n",
      "Epoch 00039: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.5344 - accuracy: 0.8527 - val_loss: 5.0154 - val_accuracy: 0.2574 - lr: 0.0010\n",
      "Epoch 40/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3761 - accuracy: 0.8946\n",
      "Epoch 00040: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.3761 - accuracy: 0.8946 - val_loss: 4.7793 - val_accuracy: 0.2655 - lr: 1.0000e-04\n",
      "Epoch 41/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3007 - accuracy: 0.9036\n",
      "Epoch 00041: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.3007 - accuracy: 0.9036 - val_loss: 4.8215 - val_accuracy: 0.2670 - lr: 1.0000e-04\n",
      "Epoch 42/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.2317 - accuracy: 0.9169\n",
      "Epoch 00042: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.2317 - accuracy: 0.9169 - val_loss: 4.7860 - val_accuracy: 0.2686 - lr: 1.0000e-04\n",
      "Epoch 43/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.1842 - accuracy: 0.9213\n",
      "Epoch 00043: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.1842 - accuracy: 0.9213 - val_loss: 4.7341 - val_accuracy: 0.2686 - lr: 1.0000e-04\n",
      "Epoch 44/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.1347 - accuracy: 0.9290\n",
      "Epoch 00044: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.1347 - accuracy: 0.9290 - val_loss: 4.7786 - val_accuracy: 0.2643 - lr: 1.0000e-04\n",
      "Epoch 45/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.1106 - accuracy: 0.9302\n",
      "Epoch 00045: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.1106 - accuracy: 0.9302 - val_loss: 4.7315 - val_accuracy: 0.2666 - lr: 1.0000e-04\n",
      "Epoch 46/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0600 - accuracy: 0.9344\n",
      "Epoch 00046: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.0600 - accuracy: 0.9344 - val_loss: 4.6949 - val_accuracy: 0.2693 - lr: 1.0000e-04\n",
      "Epoch 47/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0231 - accuracy: 0.9415\n",
      "Epoch 00047: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.0231 - accuracy: 0.9415 - val_loss: 4.7685 - val_accuracy: 0.2663 - lr: 1.0000e-04\n",
      "Epoch 48/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0075 - accuracy: 0.9438\n",
      "Epoch 00048: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.0075 - accuracy: 0.9438 - val_loss: 4.7089 - val_accuracy: 0.2647 - lr: 1.0000e-04\n",
      "Epoch 49/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9718 - accuracy: 0.9463\n",
      "Epoch 00049: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.9718 - accuracy: 0.9463 - val_loss: 4.7269 - val_accuracy: 0.2636 - lr: 1.0000e-04\n",
      "Epoch 50/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9466 - accuracy: 0.9444\n",
      "Epoch 00050: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.9466 - accuracy: 0.9444 - val_loss: 4.6830 - val_accuracy: 0.2663 - lr: 1.0000e-04\n",
      "Epoch 51/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9161 - accuracy: 0.9500\n",
      "Epoch 00051: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.9161 - accuracy: 0.9500 - val_loss: 4.7010 - val_accuracy: 0.2609 - lr: 1.0000e-04\n",
      "Epoch 52/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9049 - accuracy: 0.9479\n",
      "Epoch 00052: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.9049 - accuracy: 0.9479 - val_loss: 4.7910 - val_accuracy: 0.2632 - lr: 1.0000e-04\n",
      "Epoch 53/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8771 - accuracy: 0.9517\n",
      "Epoch 00053: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.8771 - accuracy: 0.9517 - val_loss: 4.6627 - val_accuracy: 0.2655 - lr: 1.0000e-04\n",
      "Epoch 54/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8545 - accuracy: 0.9540\n",
      "Epoch 00054: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.8545 - accuracy: 0.9540 - val_loss: 4.6147 - val_accuracy: 0.2616 - lr: 1.0000e-04\n",
      "Epoch 55/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8411 - accuracy: 0.9517\n",
      "Epoch 00055: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.8411 - accuracy: 0.9517 - val_loss: 4.6313 - val_accuracy: 0.2689 - lr: 1.0000e-04\n",
      "Epoch 56/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8136 - accuracy: 0.9544\n",
      "Epoch 00056: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.8136 - accuracy: 0.9544 - val_loss: 4.6359 - val_accuracy: 0.2663 - lr: 1.0000e-04\n",
      "Epoch 57/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7670 - accuracy: 0.9646\n",
      "Epoch 00057: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.7670 - accuracy: 0.9646 - val_loss: 4.7115 - val_accuracy: 0.2563 - lr: 1.0000e-04\n",
      "Epoch 58/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7758 - accuracy: 0.9579\n",
      "Epoch 00058: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.7758 - accuracy: 0.9579 - val_loss: 4.6663 - val_accuracy: 0.2670 - lr: 1.0000e-04\n",
      "Epoch 59/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7441 - accuracy: 0.9631\n",
      "Epoch 00059: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.7441 - accuracy: 0.9631 - val_loss: 4.7104 - val_accuracy: 0.2563 - lr: 1.0000e-04\n",
      "Epoch 60/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7247 - accuracy: 0.9656\n",
      "Epoch 00060: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.7247 - accuracy: 0.9656 - val_loss: 4.7217 - val_accuracy: 0.2578 - lr: 1.0000e-04\n",
      "Epoch 61/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7206 - accuracy: 0.9613\n",
      "Epoch 00061: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.7206 - accuracy: 0.9613 - val_loss: 4.6997 - val_accuracy: 0.2520 - lr: 1.0000e-04\n",
      "Epoch 62/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7157 - accuracy: 0.9556\n",
      "Epoch 00062: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.7157 - accuracy: 0.9556 - val_loss: 4.7390 - val_accuracy: 0.2582 - lr: 1.0000e-04\n",
      "Epoch 63/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6944 - accuracy: 0.9608\n",
      "Epoch 00063: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.6944 - accuracy: 0.9608 - val_loss: 4.6459 - val_accuracy: 0.2589 - lr: 1.0000e-04\n",
      "Epoch 64/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6726 - accuracy: 0.9644\n",
      "Epoch 00064: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.6726 - accuracy: 0.9644 - val_loss: 4.7189 - val_accuracy: 0.2578 - lr: 1.0000e-04\n",
      "Epoch 65/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6595 - accuracy: 0.9658\n",
      "Epoch 00065: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 0.6595 - accuracy: 0.9658 - val_loss: 4.7267 - val_accuracy: 0.2528 - lr: 1.0000e-04\n",
      "Epoch 66/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6437 - accuracy: 0.9690\n",
      "Epoch 00066: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.6437 - accuracy: 0.9690 - val_loss: 4.7443 - val_accuracy: 0.2589 - lr: 1.0000e-04\n",
      "Epoch 67/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6384 - accuracy: 0.9648\n",
      "Epoch 00067: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.6384 - accuracy: 0.9648 - val_loss: 4.7052 - val_accuracy: 0.2593 - lr: 1.0000e-04\n",
      "Epoch 68/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6144 - accuracy: 0.9706\n",
      "Epoch 00068: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 58s 353ms/step - loss: 0.6144 - accuracy: 0.9706 - val_loss: 4.7399 - val_accuracy: 0.2505 - lr: 1.0000e-04\n",
      "Epoch 69/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6137 - accuracy: 0.9685\n",
      "Epoch 00069: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 60s 367ms/step - loss: 0.6137 - accuracy: 0.9685 - val_loss: 4.7379 - val_accuracy: 0.2570 - lr: 1.0000e-04\n",
      "Epoch 70/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6012 - accuracy: 0.9698\n",
      "Epoch 00070: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 58s 356ms/step - loss: 0.6012 - accuracy: 0.9698 - val_loss: 4.7497 - val_accuracy: 0.2574 - lr: 1.0000e-04\n",
      "Epoch 71/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5905 - accuracy: 0.9673\n",
      "Epoch 00071: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 58s 353ms/step - loss: 0.5905 - accuracy: 0.9673 - val_loss: 4.7150 - val_accuracy: 0.2620 - lr: 1.0000e-04\n",
      "Epoch 72/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5698 - accuracy: 0.9733\n",
      "Epoch 00072: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 57s 352ms/step - loss: 0.5698 - accuracy: 0.9733 - val_loss: 4.7607 - val_accuracy: 0.2559 - lr: 1.0000e-04\n",
      "Epoch 73/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5617 - accuracy: 0.9713\n",
      "Epoch 00073: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 57s 351ms/step - loss: 0.5617 - accuracy: 0.9713 - val_loss: 4.6968 - val_accuracy: 0.2559 - lr: 1.0000e-04\n",
      "Epoch 74/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5502 - accuracy: 0.9731\n",
      "Epoch 00074: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 57s 351ms/step - loss: 0.5502 - accuracy: 0.9731 - val_loss: 4.6714 - val_accuracy: 0.2566 - lr: 1.0000e-04\n",
      "Epoch 75/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5457 - accuracy: 0.9717\n",
      "Epoch 00075: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 57s 350ms/step - loss: 0.5457 - accuracy: 0.9717 - val_loss: 4.7574 - val_accuracy: 0.2497 - lr: 1.0000e-04\n",
      "Epoch 76/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5334 - accuracy: 0.9744\n",
      "Epoch 00076: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 57s 350ms/step - loss: 0.5334 - accuracy: 0.9744 - val_loss: 4.7607 - val_accuracy: 0.2505 - lr: 1.0000e-04\n",
      "Epoch 77/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5258 - accuracy: 0.9758\n",
      "Epoch 00077: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 59s 364ms/step - loss: 0.5258 - accuracy: 0.9758 - val_loss: 4.7271 - val_accuracy: 0.2589 - lr: 1.0000e-04\n",
      "Epoch 78/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5234 - accuracy: 0.9725\n",
      "Epoch 00078: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 59s 364ms/step - loss: 0.5234 - accuracy: 0.9725 - val_loss: 4.6795 - val_accuracy: 0.2620 - lr: 1.0000e-04\n",
      "Epoch 79/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5199 - accuracy: 0.9715\n",
      "Epoch 00079: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 60s 367ms/step - loss: 0.5199 - accuracy: 0.9715 - val_loss: 4.7756 - val_accuracy: 0.2609 - lr: 1.0000e-04\n",
      "Epoch 80/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5076 - accuracy: 0.9752\n",
      "Epoch 00080: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 62s 380ms/step - loss: 0.5076 - accuracy: 0.9752 - val_loss: 4.7930 - val_accuracy: 0.2528 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5045 - accuracy: 0.9738\n",
      "Epoch 00081: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 57s 350ms/step - loss: 0.5045 - accuracy: 0.9738 - val_loss: 4.6943 - val_accuracy: 0.2555 - lr: 1.0000e-05\n",
      "Epoch 82/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4996 - accuracy: 0.9761\n",
      "Epoch 00082: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 56s 345ms/step - loss: 0.4996 - accuracy: 0.9761 - val_loss: 4.7478 - val_accuracy: 0.2551 - lr: 1.0000e-05\n",
      "Epoch 83/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4983 - accuracy: 0.9760\n",
      "Epoch 00083: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 57s 347ms/step - loss: 0.4983 - accuracy: 0.9760 - val_loss: 4.7066 - val_accuracy: 0.2613 - lr: 1.0000e-05\n",
      "Epoch 84/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4990 - accuracy: 0.9744\n",
      "Epoch 00084: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 56s 346ms/step - loss: 0.4990 - accuracy: 0.9744 - val_loss: 4.7481 - val_accuracy: 0.2524 - lr: 1.0000e-05\n",
      "Epoch 85/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5003 - accuracy: 0.9765\n",
      "Epoch 00085: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 56s 346ms/step - loss: 0.5003 - accuracy: 0.9765 - val_loss: 4.7474 - val_accuracy: 0.2555 - lr: 1.0000e-05\n",
      "Epoch 86/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4918 - accuracy: 0.9786\n",
      "Epoch 00086: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 56s 346ms/step - loss: 0.4918 - accuracy: 0.9786 - val_loss: 4.7154 - val_accuracy: 0.2593 - lr: 1.0000e-05\n",
      "Epoch 87/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4942 - accuracy: 0.9754\n",
      "Epoch 00087: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 57s 348ms/step - loss: 0.4942 - accuracy: 0.9754 - val_loss: 4.7612 - val_accuracy: 0.2543 - lr: 1.0000e-05\n",
      "Epoch 88/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4922 - accuracy: 0.9779\n",
      "Epoch 00088: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 57s 350ms/step - loss: 0.4922 - accuracy: 0.9779 - val_loss: 4.7288 - val_accuracy: 0.2616 - lr: 1.0000e-05\n",
      "Epoch 89/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4975 - accuracy: 0.9750\n",
      "Epoch 00089: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 57s 348ms/step - loss: 0.4975 - accuracy: 0.9750 - val_loss: 4.7334 - val_accuracy: 0.2605 - lr: 1.0000e-05\n",
      "Epoch 90/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4926 - accuracy: 0.9761\n",
      "Epoch 00090: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 56s 344ms/step - loss: 0.4926 - accuracy: 0.9761 - val_loss: 4.7242 - val_accuracy: 0.2563 - lr: 1.0000e-05\n",
      "Epoch 91/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4909 - accuracy: 0.9761\n",
      "Epoch 00091: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 57s 347ms/step - loss: 0.4909 - accuracy: 0.9761 - val_loss: 4.7446 - val_accuracy: 0.2578 - lr: 1.0000e-05\n",
      "Epoch 92/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4897 - accuracy: 0.9763\n",
      "Epoch 00092: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 57s 349ms/step - loss: 0.4897 - accuracy: 0.9763 - val_loss: 4.7387 - val_accuracy: 0.2536 - lr: 1.0000e-05\n",
      "Epoch 93/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4943 - accuracy: 0.9746\n",
      "Epoch 00093: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 56s 347ms/step - loss: 0.4943 - accuracy: 0.9746 - val_loss: 4.7593 - val_accuracy: 0.2555 - lr: 1.0000e-05\n",
      "Epoch 94/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4857 - accuracy: 0.9746\n",
      "Epoch 00094: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 56s 346ms/step - loss: 0.4857 - accuracy: 0.9746 - val_loss: 4.7937 - val_accuracy: 0.2593 - lr: 1.0000e-05\n",
      "Epoch 95/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4827 - accuracy: 0.9785\n",
      "Epoch 00095: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 56s 346ms/step - loss: 0.4827 - accuracy: 0.9785 - val_loss: 4.7554 - val_accuracy: 0.2524 - lr: 1.0000e-05\n",
      "Epoch 96/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4825 - accuracy: 0.9773\n",
      "Epoch 00096: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 57s 348ms/step - loss: 0.4825 - accuracy: 0.9773 - val_loss: 4.7524 - val_accuracy: 0.2613 - lr: 1.0000e-05\n",
      "Epoch 97/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4811 - accuracy: 0.9785\n",
      "Epoch 00097: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 56s 346ms/step - loss: 0.4811 - accuracy: 0.9785 - val_loss: 4.7846 - val_accuracy: 0.2528 - lr: 1.0000e-05\n",
      "Epoch 98/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4861 - accuracy: 0.9748\n",
      "Epoch 00098: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 56s 345ms/step - loss: 0.4861 - accuracy: 0.9748 - val_loss: 4.7915 - val_accuracy: 0.2501 - lr: 1.0000e-05\n",
      "Epoch 99/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4775 - accuracy: 0.9792\n",
      "Epoch 00099: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 57s 347ms/step - loss: 0.4775 - accuracy: 0.9792 - val_loss: 4.7441 - val_accuracy: 0.2636 - lr: 1.0000e-05\n",
      "Epoch 100/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4805 - accuracy: 0.9767\n",
      "Epoch 00100: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 57s 350ms/step - loss: 0.4805 - accuracy: 0.9767 - val_loss: 4.7546 - val_accuracy: 0.2574 - lr: 1.0000e-05\n",
      "Epoch 101/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4839 - accuracy: 0.9761\n",
      "Epoch 00101: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 57s 348ms/step - loss: 0.4839 - accuracy: 0.9761 - val_loss: 4.7272 - val_accuracy: 0.2597 - lr: 1.0000e-05\n",
      "Epoch 102/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4867 - accuracy: 0.9740\n",
      "Epoch 00102: val_accuracy did not improve from 0.30012\n",
      "163/163 [==============================] - 57s 349ms/step - loss: 0.4867 - accuracy: 0.9740 - val_loss: 4.7426 - val_accuracy: 0.2574 - lr: 1.0000e-05\n",
      "epoch_number 5\n",
      "train accuracy and validation accuracy 0.3687247633934021 0.3001154363155365\n",
      "82/82 [==============================] - 7s 81ms/step - loss: 3.4806 - accuracy: 0.3001\n",
      "test_accuracy 0.3001154363155365\n",
      "[0.3470565676689148, 0.3162754774093628, 0.3166602551937103, 0.3655252158641815, 0.37822240591049194, 0.39168912172317505, 0.3001154363155365]\n",
      "test_mean for %d subjects: 7\n",
      "0.345077782869339\n",
      "/media/naveen/nav/mat_codes/nina_DB4_codes/naveen_prep_nlw/sub_wise_process_TT/S8_tr.csv\n",
      "Number of columns in the dataframe: 13\n",
      "Number of rows in the dataframe: 2080000\n",
      "\n",
      "/media/naveen/nav/mat_codes/nina_DB4_codes/naveen_prep_nlw/sub_wise_process_TT/S8_tt.csv\n",
      "Number of columns in the dataframe: 13\n",
      "Number of rows in the dataframe: 1040000\n",
      "\n",
      "x_train shape:  (5199, 400, 12)\n",
      "5199 training samples\n",
      "y_train shape:  (5199,)\n",
      "num_time_periods 400\n",
      "num_sensors 12\n",
      "class_list [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0]\n",
      "x_train shape: (400, 12)\n",
      "input_shape: (400, 12)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "New y_train shape:  (5199, 52)\n",
      "x_test shape:  (2599, 400, 12)\n",
      "2599 testing samples\n",
      "y_test shape:  (2599,)\n",
      "x_train shape:  (5199, 400, 12)\n",
      "x_test shape:  (2599, 400, 12)\n",
      "n_outputs 52\n",
      "Model: \"wei_mscnn_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main (InputLayer)               [(None, 400, 12)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_8 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_10 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_12 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_14 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_16 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_18 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_20 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_22 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_1 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_2 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_3 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_4 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_5 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_10[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_6 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_12[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_7 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_14[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_8 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_16[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_9 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_18[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_10 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_20[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_11 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_22[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [()]                 0           tf_op_layer_Shape_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_5 (Te [()]                 0           tf_op_layer_Shape_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_7 (Te [()]                 0           tf_op_layer_Shape_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_9 (Te [()]                 0           tf_op_layer_Shape_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_11 (T [()]                 0           tf_op_layer_Shape_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_13 (T [()]                 0           tf_op_layer_Shape_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_15 (T [()]                 0           tf_op_layer_Shape_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_17 (T [()]                 0           tf_op_layer_Shape_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_19 (T [()]                 0           tf_op_layer_Shape_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_21 (T [()]                 0           tf_op_layer_Shape_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_23 (T [()]                 0           tf_op_layer_Shape_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape/shape (Tens [(3,)]               0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1/shape (Te [(3,)]               0           tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2/shape (Te [(3,)]               0           tf_op_layer_strided_slice_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3/shape (Te [(3,)]               0           tf_op_layer_strided_slice_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4/shape (Te [(3,)]               0           tf_op_layer_strided_slice_9[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5/shape (Te [(3,)]               0           tf_op_layer_strided_slice_11[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6/shape (Te [(3,)]               0           tf_op_layer_strided_slice_13[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7/shape (Te [(3,)]               0           tf_op_layer_strided_slice_15[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8/shape (Te [(3,)]               0           tf_op_layer_strided_slice_17[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9/shape (Te [(3,)]               0           tf_op_layer_strided_slice_19[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_10/shape (T [(3,)]               0           tf_op_layer_strided_slice_21[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_11/shape (T [(3,)]               0           tf_op_layer_strided_slice_23[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 400, 1)]     0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 tf_op_layer_Reshape/shape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_2[0][0]\n",
      "                                                                 tf_op_layer_Reshape_1/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_4[0][0]\n",
      "                                                                 tf_op_layer_Reshape_2/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_6[0][0]\n",
      "                                                                 tf_op_layer_Reshape_3/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_8[0][0]\n",
      "                                                                 tf_op_layer_Reshape_4/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_10[0][0\n",
      "                                                                 tf_op_layer_Reshape_5/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_12[0][0\n",
      "                                                                 tf_op_layer_Reshape_6/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_14[0][0\n",
      "                                                                 tf_op_layer_Reshape_7/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_16[0][0\n",
      "                                                                 tf_op_layer_Reshape_8/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_18[0][0\n",
      "                                                                 tf_op_layer_Reshape_9/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_10 (TensorF [(None, 400, 1)]     0           tf_op_layer_strided_slice_20[0][0\n",
      "                                                                 tf_op_layer_Reshape_10/shape[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_11 (TensorF [(None, 400, 1)]     0           tf_op_layer_strided_slice_22[0][0\n",
      "                                                                 tf_op_layer_Reshape_11/shape[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 400, 64)      256         tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 400, 64)      256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 400, 64)      256         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 400, 64)      256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 400, 64)      256         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 400, 64)      256         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 400, 64)      256         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 400, 64)      256         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 400, 64)      256         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 400, 64)      256         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 400, 64)      256         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 400, 64)      256         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 400, 64)      256         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 400, 64)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 400, 64)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 400, 64)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 400, 64)      0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 400, 64)      0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 400, 64)      0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 400, 64)      0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 400, 64)      0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 400, 64)      0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 400, 64)      0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 400, 64)      0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 400, 64)      0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 400, 64)      12352       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 400, 64)      12352       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 400, 64)      12352       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 400, 64)      12352       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 400, 64)      12352       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 400, 64)      12352       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 400, 64)      12352       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 400, 64)      12352       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 400, 64)      12352       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 400, 64)      12352       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 400, 64)      12352       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 400, 64)      12352       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 400, 64)      256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 400, 64)      256         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 400, 64)      256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 400, 64)      256         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 400, 64)      256         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 400, 64)      256         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 400, 64)      256         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 400, 64)      256         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 400, 64)      256         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 400, 64)      256         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 400, 64)      256         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 400, 64)      256         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 400, 64)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 400, 64)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 400, 64)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 400, 64)      0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 400, 64)      0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 400, 64)      0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 400, 64)      0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 400, 64)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 400, 64)      0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 400, 64)      0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 400, 64)      0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 400, 64)      0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d (LocallyCon (None, 400, 64)      1664000     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_2 (LocallyC (None, 400, 64)      1664000     activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_4 (LocallyC (None, 400, 64)      1664000     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_6 (LocallyC (None, 400, 64)      1664000     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_8 (LocallyC (None, 400, 64)      1664000     activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_10 (Locally (None, 400, 64)      1664000     activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_12 (Locally (None, 400, 64)      1664000     activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_14 (Locally (None, 400, 64)      1664000     activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_16 (Locally (None, 400, 64)      1664000     activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_18 (Locally (None, 400, 64)      1664000     activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_20 (Locally (None, 400, 64)      1664000     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_22 (Locally (None, 400, 64)      1664000     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 400, 64)      256         locally_connected1d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 400, 64)      256         locally_connected1d_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 400, 64)      256         locally_connected1d_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 400, 64)      256         locally_connected1d_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 400, 64)      256         locally_connected1d_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 400, 64)      256         locally_connected1d_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 400, 64)      256         locally_connected1d_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 400, 64)      256         locally_connected1d_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 400, 64)      256         locally_connected1d_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 400, 64)      256         locally_connected1d_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 400, 64)      256         locally_connected1d_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 400, 64)      256         locally_connected1d_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 400, 64)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 400, 64)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 400, 64)      0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 400, 64)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 400, 64)      0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 400, 64)      0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 400, 64)      0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 400, 64)      0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 400, 64)      0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 400, 64)      0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 400, 64)      0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 400, 64)      0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_1 (LocallyC (None, 400, 64)      1664000     activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_3 (LocallyC (None, 400, 64)      1664000     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_5 (LocallyC (None, 400, 64)      1664000     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_7 (LocallyC (None, 400, 64)      1664000     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_9 (LocallyC (None, 400, 64)      1664000     activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_11 (Locally (None, 400, 64)      1664000     activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_13 (Locally (None, 400, 64)      1664000     activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_15 (Locally (None, 400, 64)      1664000     activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_17 (Locally (None, 400, 64)      1664000     activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_19 (Locally (None, 400, 64)      1664000     activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_21 (Locally (None, 400, 64)      1664000     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_23 (Locally (None, 400, 64)      1664000     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 400, 64)      256         locally_connected1d_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 400, 64)      256         locally_connected1d_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 400, 64)      256         locally_connected1d_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 400, 64)      256         locally_connected1d_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 400, 64)      256         locally_connected1d_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 400, 64)      256         locally_connected1d_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 400, 64)      256         locally_connected1d_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 400, 64)      256         locally_connected1d_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 400, 64)      256         locally_connected1d_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 400, 64)      256         locally_connected1d_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 400, 64)      256         locally_connected1d_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 400, 64)      256         locally_connected1d_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 400, 64)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 400, 64)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 400, 64)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 400, 64)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 400, 64)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 400, 64)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 400, 64)      0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 400, 64)      0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 400, 64)      0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 400, 64)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 400, 64)      0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 400, 64)      0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 400, 64)      0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 400, 64)      0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 400, 64)      0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 400, 64)      0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 400, 64)      0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 400, 64)      0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 400, 64)      0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 400, 64)      0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 400, 64)      0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 400, 64)      0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 400, 64)      0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 400, 64)      0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_stack (TensorFlowOp [(None, 400, 12, 64) 0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "                                                                 dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 307200)       0           tf_op_layer_stack[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          157286912   flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 512)          0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 512)          0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          262656      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 512)          0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 512)          0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          65664       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 128)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 128)          0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 52)           6708        activation_50[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 197,726,132\n",
      "Trainable params: 197,717,684\n",
      "Non-trainable params: 8,448\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.9485 - accuracy: 0.1602\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.28626, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 126s 774ms/step - loss: 3.9485 - accuracy: 0.1602 - val_loss: 3.2204 - val_accuracy: 0.2863 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.1716 - accuracy: 0.2835\n",
      "Epoch 00002: val_accuracy improved from 0.28626 to 0.31012, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 63s 389ms/step - loss: 3.1716 - accuracy: 0.2835 - val_loss: 3.0738 - val_accuracy: 0.3101 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.0055 - accuracy: 0.3393\n",
      "Epoch 00003: val_accuracy improved from 0.31012 to 0.34436, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 63s 387ms/step - loss: 3.0055 - accuracy: 0.3393 - val_loss: 3.0485 - val_accuracy: 0.3444 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.8691 - accuracy: 0.3924\n",
      "Epoch 00004: val_accuracy improved from 0.34436 to 0.36860, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 62s 383ms/step - loss: 2.8691 - accuracy: 0.3924 - val_loss: 3.0494 - val_accuracy: 0.3686 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.8102 - accuracy: 0.4310\n",
      "Epoch 00005: val_accuracy did not improve from 0.36860\n",
      "163/163 [==============================] - 57s 349ms/step - loss: 2.8102 - accuracy: 0.4310 - val_loss: 3.1739 - val_accuracy: 0.3528 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.6911 - accuracy: 0.4693\n",
      "Epoch 00006: val_accuracy did not improve from 0.36860\n",
      "163/163 [==============================] - 56s 346ms/step - loss: 2.6911 - accuracy: 0.4693 - val_loss: 3.1800 - val_accuracy: 0.3478 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.5577 - accuracy: 0.5049\n",
      "Epoch 00007: val_accuracy did not improve from 0.36860\n",
      "163/163 [==============================] - 57s 347ms/step - loss: 2.5577 - accuracy: 0.5049 - val_loss: 3.2800 - val_accuracy: 0.3605 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.5258 - accuracy: 0.5230\n",
      "Epoch 00008: val_accuracy improved from 0.36860 to 0.37630, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 63s 387ms/step - loss: 2.5258 - accuracy: 0.5230 - val_loss: 3.2292 - val_accuracy: 0.3763 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.4598 - accuracy: 0.5582\n",
      "Epoch 00009: val_accuracy improved from 0.37630 to 0.37861, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 63s 386ms/step - loss: 2.4598 - accuracy: 0.5582 - val_loss: 3.3293 - val_accuracy: 0.3786 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.4046 - accuracy: 0.5876\n",
      "Epoch 00010: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 56s 345ms/step - loss: 2.4046 - accuracy: 0.5876 - val_loss: 3.4975 - val_accuracy: 0.3578 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.2963 - accuracy: 0.6151\n",
      "Epoch 00011: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 56s 347ms/step - loss: 2.2963 - accuracy: 0.6151 - val_loss: 3.4304 - val_accuracy: 0.3682 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.2372 - accuracy: 0.6409\n",
      "Epoch 00012: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 57s 347ms/step - loss: 2.2372 - accuracy: 0.6409 - val_loss: 3.5560 - val_accuracy: 0.3524 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.1286 - accuracy: 0.6715\n",
      "Epoch 00013: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 56s 346ms/step - loss: 2.1286 - accuracy: 0.6715 - val_loss: 3.5225 - val_accuracy: 0.3705 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.0501 - accuracy: 0.6882\n",
      "Epoch 00014: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 56s 344ms/step - loss: 2.0501 - accuracy: 0.6882 - val_loss: 3.5861 - val_accuracy: 0.3605 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.9980 - accuracy: 0.7096\n",
      "Epoch 00015: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 57s 350ms/step - loss: 1.9980 - accuracy: 0.7096 - val_loss: 3.6810 - val_accuracy: 0.3605 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.9547 - accuracy: 0.7255\n",
      "Epoch 00016: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 57s 350ms/step - loss: 1.9547 - accuracy: 0.7255 - val_loss: 3.6939 - val_accuracy: 0.3544 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.9090 - accuracy: 0.7415\n",
      "Epoch 00017: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 59s 360ms/step - loss: 1.9090 - accuracy: 0.7415 - val_loss: 3.7704 - val_accuracy: 0.3532 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8613 - accuracy: 0.7496\n",
      "Epoch 00018: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 57s 349ms/step - loss: 1.8613 - accuracy: 0.7496 - val_loss: 3.7748 - val_accuracy: 0.3690 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8262 - accuracy: 0.7757\n",
      "Epoch 00019: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 57s 351ms/step - loss: 1.8262 - accuracy: 0.7757 - val_loss: 3.8145 - val_accuracy: 0.3447 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7654 - accuracy: 0.7800\n",
      "Epoch 00020: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 57s 350ms/step - loss: 1.7654 - accuracy: 0.7800 - val_loss: 3.9941 - val_accuracy: 0.3471 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7414 - accuracy: 0.7853\n",
      "Epoch 00021: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 57s 351ms/step - loss: 1.7414 - accuracy: 0.7853 - val_loss: 4.0367 - val_accuracy: 0.3355 - lr: 0.0010\n",
      "Epoch 22/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7208 - accuracy: 0.7927\n",
      "Epoch 00022: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 57s 350ms/step - loss: 1.7208 - accuracy: 0.7927 - val_loss: 4.0033 - val_accuracy: 0.3440 - lr: 0.0010\n",
      "Epoch 23/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6309 - accuracy: 0.8182\n",
      "Epoch 00023: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 57s 350ms/step - loss: 1.6309 - accuracy: 0.8182 - val_loss: 4.1006 - val_accuracy: 0.3321 - lr: 0.0010\n",
      "Epoch 24/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6807 - accuracy: 0.8028\n",
      "Epoch 00024: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 57s 351ms/step - loss: 1.6807 - accuracy: 0.8028 - val_loss: 4.0694 - val_accuracy: 0.3324 - lr: 0.0010\n",
      "Epoch 25/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6054 - accuracy: 0.8207\n",
      "Epoch 00025: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 57s 351ms/step - loss: 1.6054 - accuracy: 0.8207 - val_loss: 4.1512 - val_accuracy: 0.3497 - lr: 0.0010\n",
      "Epoch 26/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5315 - accuracy: 0.8402\n",
      "Epoch 00026: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 57s 348ms/step - loss: 1.5315 - accuracy: 0.8402 - val_loss: 4.1861 - val_accuracy: 0.3467 - lr: 0.0010\n",
      "Epoch 27/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5035 - accuracy: 0.8417\n",
      "Epoch 00027: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 57s 350ms/step - loss: 1.5035 - accuracy: 0.8417 - val_loss: 4.2553 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 28/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5332 - accuracy: 0.8390\n",
      "Epoch 00028: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 57s 349ms/step - loss: 1.5332 - accuracy: 0.8390 - val_loss: 4.2571 - val_accuracy: 0.3313 - lr: 0.0010\n",
      "Epoch 29/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4546 - accuracy: 0.8554\n",
      "Epoch 00029: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 56s 345ms/step - loss: 1.4546 - accuracy: 0.8554 - val_loss: 4.2788 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 30/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4553 - accuracy: 0.8555\n",
      "Epoch 00030: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 56s 346ms/step - loss: 1.4553 - accuracy: 0.8555 - val_loss: 4.3592 - val_accuracy: 0.3294 - lr: 0.0010\n",
      "Epoch 31/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4387 - accuracy: 0.8613\n",
      "Epoch 00031: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 57s 350ms/step - loss: 1.4387 - accuracy: 0.8613 - val_loss: 4.4708 - val_accuracy: 0.3147 - lr: 0.0010\n",
      "Epoch 32/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3757 - accuracy: 0.8792\n",
      "Epoch 00032: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 57s 348ms/step - loss: 1.3757 - accuracy: 0.8792 - val_loss: 4.3356 - val_accuracy: 0.3374 - lr: 0.0010\n",
      "Epoch 33/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3828 - accuracy: 0.8709\n",
      "Epoch 00033: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 57s 349ms/step - loss: 1.3828 - accuracy: 0.8709 - val_loss: 4.4086 - val_accuracy: 0.3136 - lr: 0.0010\n",
      "Epoch 34/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3585 - accuracy: 0.8779\n",
      "Epoch 00034: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 57s 348ms/step - loss: 1.3585 - accuracy: 0.8779 - val_loss: 4.5226 - val_accuracy: 0.3159 - lr: 0.0010\n",
      "Epoch 35/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3741 - accuracy: 0.8711\n",
      "Epoch 00035: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 57s 348ms/step - loss: 1.3741 - accuracy: 0.8711 - val_loss: 4.4906 - val_accuracy: 0.3113 - lr: 0.0010\n",
      "Epoch 36/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3395 - accuracy: 0.8831\n",
      "Epoch 00036: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 57s 349ms/step - loss: 1.3395 - accuracy: 0.8831 - val_loss: 4.3860 - val_accuracy: 0.3294 - lr: 0.0010\n",
      "Epoch 37/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3223 - accuracy: 0.8811\n",
      "Epoch 00037: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 56s 346ms/step - loss: 1.3223 - accuracy: 0.8811 - val_loss: 4.4409 - val_accuracy: 0.3305 - lr: 0.0010\n",
      "Epoch 38/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3269 - accuracy: 0.8775\n",
      "Epoch 00038: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 57s 347ms/step - loss: 1.3269 - accuracy: 0.8775 - val_loss: 4.4832 - val_accuracy: 0.3132 - lr: 0.0010\n",
      "Epoch 39/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.2942 - accuracy: 0.8863\n",
      "Epoch 00039: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 57s 349ms/step - loss: 1.2942 - accuracy: 0.8863 - val_loss: 4.6278 - val_accuracy: 0.3209 - lr: 0.0010\n",
      "Epoch 40/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.2131 - accuracy: 0.9094\n",
      "Epoch 00040: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.2131 - accuracy: 0.9094 - val_loss: 4.3700 - val_accuracy: 0.3220 - lr: 1.0000e-04\n",
      "Epoch 41/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.1205 - accuracy: 0.9265\n",
      "Epoch 00041: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 1.1205 - accuracy: 0.9265 - val_loss: 4.2822 - val_accuracy: 0.3213 - lr: 1.0000e-04\n",
      "Epoch 42/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0820 - accuracy: 0.9329\n",
      "Epoch 00042: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.0820 - accuracy: 0.9329 - val_loss: 4.2516 - val_accuracy: 0.3270 - lr: 1.0000e-04\n",
      "Epoch 43/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0329 - accuracy: 0.9400\n",
      "Epoch 00043: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.0329 - accuracy: 0.9400 - val_loss: 4.2676 - val_accuracy: 0.3278 - lr: 1.0000e-04\n",
      "Epoch 44/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9931 - accuracy: 0.9452\n",
      "Epoch 00044: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.9931 - accuracy: 0.9452 - val_loss: 4.2687 - val_accuracy: 0.3174 - lr: 1.0000e-04\n",
      "Epoch 45/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9698 - accuracy: 0.9417\n",
      "Epoch 00045: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.9698 - accuracy: 0.9417 - val_loss: 4.2145 - val_accuracy: 0.3197 - lr: 1.0000e-04\n",
      "Epoch 46/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9275 - accuracy: 0.9523\n",
      "Epoch 00046: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.9275 - accuracy: 0.9523 - val_loss: 4.2290 - val_accuracy: 0.3228 - lr: 1.0000e-04\n",
      "Epoch 47/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8905 - accuracy: 0.9540\n",
      "Epoch 00047: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.8905 - accuracy: 0.9540 - val_loss: 4.1552 - val_accuracy: 0.3251 - lr: 1.0000e-04\n",
      "Epoch 48/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8718 - accuracy: 0.9590\n",
      "Epoch 00048: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.8718 - accuracy: 0.9590 - val_loss: 4.1633 - val_accuracy: 0.3270 - lr: 1.0000e-04\n",
      "Epoch 49/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8420 - accuracy: 0.9617\n",
      "Epoch 00049: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 0.8420 - accuracy: 0.9617 - val_loss: 4.1713 - val_accuracy: 0.3247 - lr: 1.0000e-04\n",
      "Epoch 50/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8205 - accuracy: 0.9631\n",
      "Epoch 00050: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 338ms/step - loss: 0.8205 - accuracy: 0.9631 - val_loss: 4.1715 - val_accuracy: 0.3263 - lr: 1.0000e-04\n",
      "Epoch 51/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8005 - accuracy: 0.9656\n",
      "Epoch 00051: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.8005 - accuracy: 0.9656 - val_loss: 4.1152 - val_accuracy: 0.3259 - lr: 1.0000e-04\n",
      "Epoch 52/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7855 - accuracy: 0.9642\n",
      "Epoch 00052: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.7855 - accuracy: 0.9642 - val_loss: 4.1116 - val_accuracy: 0.3294 - lr: 1.0000e-04\n",
      "Epoch 53/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - ETA: 0s - loss: 0.7625 - accuracy: 0.9617\n",
      "Epoch 00053: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.7625 - accuracy: 0.9617 - val_loss: 4.1501 - val_accuracy: 0.3217 - lr: 1.0000e-04\n",
      "Epoch 54/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7357 - accuracy: 0.9658\n",
      "Epoch 00054: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.7357 - accuracy: 0.9658 - val_loss: 4.1520 - val_accuracy: 0.3290 - lr: 1.0000e-04\n",
      "Epoch 55/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7169 - accuracy: 0.9656\n",
      "Epoch 00055: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.7169 - accuracy: 0.9656 - val_loss: 4.1676 - val_accuracy: 0.3224 - lr: 1.0000e-04\n",
      "Epoch 56/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7029 - accuracy: 0.9673\n",
      "Epoch 00056: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.7029 - accuracy: 0.9673 - val_loss: 4.1789 - val_accuracy: 0.3170 - lr: 1.0000e-04\n",
      "Epoch 57/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6813 - accuracy: 0.9715\n",
      "Epoch 00057: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.6813 - accuracy: 0.9715 - val_loss: 4.1245 - val_accuracy: 0.3147 - lr: 1.0000e-04\n",
      "Epoch 58/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6676 - accuracy: 0.9683\n",
      "Epoch 00058: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.6676 - accuracy: 0.9683 - val_loss: 4.1490 - val_accuracy: 0.3194 - lr: 1.0000e-04\n",
      "Epoch 59/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6425 - accuracy: 0.9746\n",
      "Epoch 00059: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.6425 - accuracy: 0.9746 - val_loss: 4.1554 - val_accuracy: 0.3167 - lr: 1.0000e-04\n",
      "Epoch 60/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6346 - accuracy: 0.9717\n",
      "Epoch 00060: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 0.6346 - accuracy: 0.9717 - val_loss: 4.1278 - val_accuracy: 0.3201 - lr: 1.0000e-04\n",
      "Epoch 61/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6261 - accuracy: 0.9681\n",
      "Epoch 00061: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.6261 - accuracy: 0.9681 - val_loss: 4.1305 - val_accuracy: 0.3186 - lr: 1.0000e-04\n",
      "Epoch 62/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6107 - accuracy: 0.9708\n",
      "Epoch 00062: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.6107 - accuracy: 0.9708 - val_loss: 4.1341 - val_accuracy: 0.3197 - lr: 1.0000e-04\n",
      "Epoch 63/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6028 - accuracy: 0.9698\n",
      "Epoch 00063: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.6028 - accuracy: 0.9698 - val_loss: 4.1278 - val_accuracy: 0.3251 - lr: 1.0000e-04\n",
      "Epoch 64/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5914 - accuracy: 0.9713\n",
      "Epoch 00064: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 338ms/step - loss: 0.5914 - accuracy: 0.9713 - val_loss: 4.1507 - val_accuracy: 0.3217 - lr: 1.0000e-04\n",
      "Epoch 65/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5651 - accuracy: 0.9748\n",
      "Epoch 00065: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.5651 - accuracy: 0.9748 - val_loss: 4.1699 - val_accuracy: 0.3247 - lr: 1.0000e-04\n",
      "Epoch 66/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5559 - accuracy: 0.9760\n",
      "Epoch 00066: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 0.5559 - accuracy: 0.9760 - val_loss: 4.1491 - val_accuracy: 0.3255 - lr: 1.0000e-04\n",
      "Epoch 67/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5480 - accuracy: 0.9735\n",
      "Epoch 00067: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.5480 - accuracy: 0.9735 - val_loss: 4.1451 - val_accuracy: 0.3286 - lr: 1.0000e-04\n",
      "Epoch 68/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5365 - accuracy: 0.9754\n",
      "Epoch 00068: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.5365 - accuracy: 0.9754 - val_loss: 4.1301 - val_accuracy: 0.3205 - lr: 1.0000e-04\n",
      "Epoch 69/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5281 - accuracy: 0.9729\n",
      "Epoch 00069: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 0.5281 - accuracy: 0.9729 - val_loss: 4.1231 - val_accuracy: 0.3217 - lr: 1.0000e-04\n",
      "Epoch 70/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5113 - accuracy: 0.9792\n",
      "Epoch 00070: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.5113 - accuracy: 0.9792 - val_loss: 4.1178 - val_accuracy: 0.3332 - lr: 1.0000e-04\n",
      "Epoch 71/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5046 - accuracy: 0.9783\n",
      "Epoch 00071: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.5046 - accuracy: 0.9783 - val_loss: 4.1145 - val_accuracy: 0.3297 - lr: 1.0000e-04\n",
      "Epoch 72/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4969 - accuracy: 0.9763\n",
      "Epoch 00072: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4969 - accuracy: 0.9763 - val_loss: 4.1424 - val_accuracy: 0.3236 - lr: 1.0000e-04\n",
      "Epoch 73/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4876 - accuracy: 0.9790\n",
      "Epoch 00073: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4876 - accuracy: 0.9790 - val_loss: 4.1342 - val_accuracy: 0.3236 - lr: 1.0000e-04\n",
      "Epoch 74/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4788 - accuracy: 0.9761\n",
      "Epoch 00074: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 0.4788 - accuracy: 0.9761 - val_loss: 4.1277 - val_accuracy: 0.3251 - lr: 1.0000e-04\n",
      "Epoch 75/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4615 - accuracy: 0.9802\n",
      "Epoch 00075: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.4615 - accuracy: 0.9802 - val_loss: 4.1601 - val_accuracy: 0.3274 - lr: 1.0000e-04\n",
      "Epoch 76/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4580 - accuracy: 0.9800\n",
      "Epoch 00076: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4580 - accuracy: 0.9800 - val_loss: 4.1442 - val_accuracy: 0.3263 - lr: 1.0000e-04\n",
      "Epoch 77/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4542 - accuracy: 0.9767\n",
      "Epoch 00077: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 0.4542 - accuracy: 0.9767 - val_loss: 4.1871 - val_accuracy: 0.3228 - lr: 1.0000e-04\n",
      "Epoch 78/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4410 - accuracy: 0.9810\n",
      "Epoch 00078: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4410 - accuracy: 0.9810 - val_loss: 4.1733 - val_accuracy: 0.3236 - lr: 1.0000e-04\n",
      "Epoch 79/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4372 - accuracy: 0.9794\n",
      "Epoch 00079: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.4372 - accuracy: 0.9794 - val_loss: 4.1125 - val_accuracy: 0.3282 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4335 - accuracy: 0.9802\n",
      "Epoch 00080: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4335 - accuracy: 0.9802 - val_loss: 4.1408 - val_accuracy: 0.3259 - lr: 1.0000e-05\n",
      "Epoch 81/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4322 - accuracy: 0.9808\n",
      "Epoch 00081: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.4322 - accuracy: 0.9808 - val_loss: 4.1229 - val_accuracy: 0.3263 - lr: 1.0000e-05\n",
      "Epoch 82/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4285 - accuracy: 0.9804\n",
      "Epoch 00082: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4285 - accuracy: 0.9804 - val_loss: 4.1108 - val_accuracy: 0.3267 - lr: 1.0000e-05\n",
      "Epoch 83/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4334 - accuracy: 0.9792\n",
      "Epoch 00083: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4334 - accuracy: 0.9792 - val_loss: 4.1153 - val_accuracy: 0.3240 - lr: 1.0000e-05\n",
      "Epoch 84/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4253 - accuracy: 0.9815\n",
      "Epoch 00084: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4253 - accuracy: 0.9815 - val_loss: 4.1182 - val_accuracy: 0.3278 - lr: 1.0000e-05\n",
      "Epoch 85/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4234 - accuracy: 0.9827\n",
      "Epoch 00085: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 0.4234 - accuracy: 0.9827 - val_loss: 4.1232 - val_accuracy: 0.3278 - lr: 1.0000e-05\n",
      "Epoch 86/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4226 - accuracy: 0.9821\n",
      "Epoch 00086: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.4226 - accuracy: 0.9821 - val_loss: 4.1198 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 87/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4241 - accuracy: 0.9813\n",
      "Epoch 00087: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.4241 - accuracy: 0.9813 - val_loss: 4.1190 - val_accuracy: 0.3290 - lr: 1.0000e-05\n",
      "Epoch 88/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4333 - accuracy: 0.9777\n",
      "Epoch 00088: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4333 - accuracy: 0.9777 - val_loss: 4.0999 - val_accuracy: 0.3259 - lr: 1.0000e-05\n",
      "Epoch 89/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4314 - accuracy: 0.9806\n",
      "Epoch 00089: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 0.4314 - accuracy: 0.9806 - val_loss: 4.1778 - val_accuracy: 0.3309 - lr: 1.0000e-05\n",
      "Epoch 90/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4208 - accuracy: 0.9823\n",
      "Epoch 00090: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 0.4208 - accuracy: 0.9823 - val_loss: 4.1255 - val_accuracy: 0.3294 - lr: 1.0000e-05\n",
      "Epoch 91/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4164 - accuracy: 0.9838\n",
      "Epoch 00091: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4164 - accuracy: 0.9838 - val_loss: 4.0779 - val_accuracy: 0.3317 - lr: 1.0000e-05\n",
      "Epoch 92/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4140 - accuracy: 0.9825\n",
      "Epoch 00092: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4140 - accuracy: 0.9825 - val_loss: 4.1209 - val_accuracy: 0.3286 - lr: 1.0000e-05\n",
      "Epoch 93/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4147 - accuracy: 0.9831\n",
      "Epoch 00093: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4147 - accuracy: 0.9831 - val_loss: 4.1737 - val_accuracy: 0.3305 - lr: 1.0000e-05\n",
      "Epoch 94/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4193 - accuracy: 0.9810\n",
      "Epoch 00094: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.4193 - accuracy: 0.9810 - val_loss: 4.1445 - val_accuracy: 0.3294 - lr: 1.0000e-05\n",
      "Epoch 95/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4097 - accuracy: 0.9833\n",
      "Epoch 00095: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.4097 - accuracy: 0.9833 - val_loss: 4.1022 - val_accuracy: 0.3332 - lr: 1.0000e-05\n",
      "Epoch 96/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4188 - accuracy: 0.9823\n",
      "Epoch 00096: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.4188 - accuracy: 0.9823 - val_loss: 4.1228 - val_accuracy: 0.3336 - lr: 1.0000e-05\n",
      "Epoch 97/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4133 - accuracy: 0.9823\n",
      "Epoch 00097: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.4133 - accuracy: 0.9823 - val_loss: 4.1219 - val_accuracy: 0.3309 - lr: 1.0000e-05\n",
      "Epoch 98/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4117 - accuracy: 0.9815\n",
      "Epoch 00098: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4117 - accuracy: 0.9815 - val_loss: 4.1220 - val_accuracy: 0.3267 - lr: 1.0000e-05\n",
      "Epoch 99/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4140 - accuracy: 0.9815\n",
      "Epoch 00099: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4140 - accuracy: 0.9815 - val_loss: 4.1883 - val_accuracy: 0.3267 - lr: 1.0000e-05\n",
      "Epoch 100/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4041 - accuracy: 0.9850\n",
      "Epoch 00100: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.4041 - accuracy: 0.9850 - val_loss: 4.1734 - val_accuracy: 0.3255 - lr: 1.0000e-05\n",
      "Epoch 101/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4079 - accuracy: 0.9827\n",
      "Epoch 00101: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4079 - accuracy: 0.9827 - val_loss: 4.1216 - val_accuracy: 0.3351 - lr: 1.0000e-05\n",
      "Epoch 102/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4124 - accuracy: 0.9804\n",
      "Epoch 00102: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.4124 - accuracy: 0.9804 - val_loss: 4.1322 - val_accuracy: 0.3297 - lr: 1.0000e-05\n",
      "Epoch 103/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4124 - accuracy: 0.9808\n",
      "Epoch 00103: val_accuracy did not improve from 0.37861\n",
      "163/163 [==============================] - 55s 340ms/step - loss: 0.4124 - accuracy: 0.9808 - val_loss: 4.1393 - val_accuracy: 0.3274 - lr: 1.0000e-05\n",
      "epoch_number 9\n",
      "train accuracy and validation accuracy 0.5581842660903931 0.3786071538925171\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 3.3293 - accuracy: 0.3786\n",
      "test_accuracy 0.3786071538925171\n",
      "[0.3470565676689148, 0.3162754774093628, 0.3166602551937103, 0.3655252158641815, 0.37822240591049194, 0.39168912172317505, 0.3001154363155365, 0.3786071538925171]\n",
      "test_mean for %d subjects: 8\n",
      "0.34926895424723625\n",
      "/media/naveen/nav/mat_codes/nina_DB4_codes/naveen_prep_nlw/sub_wise_process_TT/S9_tr.csv\n",
      "Number of columns in the dataframe: 13\n",
      "Number of rows in the dataframe: 2080000\n",
      "\n",
      "/media/naveen/nav/mat_codes/nina_DB4_codes/naveen_prep_nlw/sub_wise_process_TT/S9_tt.csv\n",
      "Number of columns in the dataframe: 13\n",
      "Number of rows in the dataframe: 1040000\n",
      "\n",
      "x_train shape:  (5199, 400, 12)\n",
      "5199 training samples\n",
      "y_train shape:  (5199,)\n",
      "num_time_periods 400\n",
      "num_sensors 12\n",
      "class_list [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0]\n",
      "x_train shape: (400, 12)\n",
      "input_shape: (400, 12)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "New y_train shape:  (5199, 52)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test shape:  (2599, 400, 12)\n",
      "2599 testing samples\n",
      "y_test shape:  (2599,)\n",
      "x_train shape:  (5199, 400, 12)\n",
      "x_test shape:  (2599, 400, 12)\n",
      "n_outputs 52\n",
      "Model: \"wei_mscnn_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main (InputLayer)               [(None, 400, 12)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_8 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_10 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_12 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_14 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_16 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_18 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_20 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_22 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_1 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_2 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_3 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_4 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_5 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_10[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_6 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_12[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_7 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_14[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_8 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_16[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_9 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_18[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_10 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_20[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_11 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_22[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [()]                 0           tf_op_layer_Shape_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_5 (Te [()]                 0           tf_op_layer_Shape_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_7 (Te [()]                 0           tf_op_layer_Shape_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_9 (Te [()]                 0           tf_op_layer_Shape_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_11 (T [()]                 0           tf_op_layer_Shape_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_13 (T [()]                 0           tf_op_layer_Shape_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_15 (T [()]                 0           tf_op_layer_Shape_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_17 (T [()]                 0           tf_op_layer_Shape_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_19 (T [()]                 0           tf_op_layer_Shape_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_21 (T [()]                 0           tf_op_layer_Shape_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_23 (T [()]                 0           tf_op_layer_Shape_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape/shape (Tens [(3,)]               0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1/shape (Te [(3,)]               0           tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2/shape (Te [(3,)]               0           tf_op_layer_strided_slice_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3/shape (Te [(3,)]               0           tf_op_layer_strided_slice_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4/shape (Te [(3,)]               0           tf_op_layer_strided_slice_9[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5/shape (Te [(3,)]               0           tf_op_layer_strided_slice_11[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6/shape (Te [(3,)]               0           tf_op_layer_strided_slice_13[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7/shape (Te [(3,)]               0           tf_op_layer_strided_slice_15[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8/shape (Te [(3,)]               0           tf_op_layer_strided_slice_17[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9/shape (Te [(3,)]               0           tf_op_layer_strided_slice_19[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_10/shape (T [(3,)]               0           tf_op_layer_strided_slice_21[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_11/shape (T [(3,)]               0           tf_op_layer_strided_slice_23[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 400, 1)]     0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 tf_op_layer_Reshape/shape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_2[0][0]\n",
      "                                                                 tf_op_layer_Reshape_1/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_4[0][0]\n",
      "                                                                 tf_op_layer_Reshape_2/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_6[0][0]\n",
      "                                                                 tf_op_layer_Reshape_3/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_8[0][0]\n",
      "                                                                 tf_op_layer_Reshape_4/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_10[0][0\n",
      "                                                                 tf_op_layer_Reshape_5/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_12[0][0\n",
      "                                                                 tf_op_layer_Reshape_6/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_14[0][0\n",
      "                                                                 tf_op_layer_Reshape_7/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_16[0][0\n",
      "                                                                 tf_op_layer_Reshape_8/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_18[0][0\n",
      "                                                                 tf_op_layer_Reshape_9/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_10 (TensorF [(None, 400, 1)]     0           tf_op_layer_strided_slice_20[0][0\n",
      "                                                                 tf_op_layer_Reshape_10/shape[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_11 (TensorF [(None, 400, 1)]     0           tf_op_layer_strided_slice_22[0][0\n",
      "                                                                 tf_op_layer_Reshape_11/shape[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 400, 64)      256         tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 400, 64)      256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 400, 64)      256         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 400, 64)      256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 400, 64)      256         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 400, 64)      256         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 400, 64)      256         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 400, 64)      256         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 400, 64)      256         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 400, 64)      256         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 400, 64)      256         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 400, 64)      256         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 400, 64)      256         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 400, 64)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 400, 64)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 400, 64)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 400, 64)      0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 400, 64)      0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 400, 64)      0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 400, 64)      0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 400, 64)      0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 400, 64)      0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 400, 64)      0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 400, 64)      0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 400, 64)      0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 400, 64)      12352       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 400, 64)      12352       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 400, 64)      12352       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 400, 64)      12352       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 400, 64)      12352       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 400, 64)      12352       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 400, 64)      12352       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 400, 64)      12352       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 400, 64)      12352       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 400, 64)      12352       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 400, 64)      12352       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 400, 64)      12352       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 400, 64)      256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 400, 64)      256         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 400, 64)      256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 400, 64)      256         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 400, 64)      256         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 400, 64)      256         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 400, 64)      256         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 400, 64)      256         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 400, 64)      256         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 400, 64)      256         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 400, 64)      256         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 400, 64)      256         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 400, 64)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 400, 64)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 400, 64)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 400, 64)      0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 400, 64)      0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 400, 64)      0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 400, 64)      0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 400, 64)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 400, 64)      0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 400, 64)      0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 400, 64)      0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 400, 64)      0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d (LocallyCon (None, 400, 64)      1664000     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_2 (LocallyC (None, 400, 64)      1664000     activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_4 (LocallyC (None, 400, 64)      1664000     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_6 (LocallyC (None, 400, 64)      1664000     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_8 (LocallyC (None, 400, 64)      1664000     activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_10 (Locally (None, 400, 64)      1664000     activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_12 (Locally (None, 400, 64)      1664000     activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_14 (Locally (None, 400, 64)      1664000     activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_16 (Locally (None, 400, 64)      1664000     activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_18 (Locally (None, 400, 64)      1664000     activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_20 (Locally (None, 400, 64)      1664000     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_22 (Locally (None, 400, 64)      1664000     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 400, 64)      256         locally_connected1d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 400, 64)      256         locally_connected1d_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 400, 64)      256         locally_connected1d_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 400, 64)      256         locally_connected1d_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 400, 64)      256         locally_connected1d_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 400, 64)      256         locally_connected1d_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 400, 64)      256         locally_connected1d_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 400, 64)      256         locally_connected1d_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 400, 64)      256         locally_connected1d_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 400, 64)      256         locally_connected1d_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 400, 64)      256         locally_connected1d_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 400, 64)      256         locally_connected1d_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 400, 64)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 400, 64)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 400, 64)      0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 400, 64)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 400, 64)      0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 400, 64)      0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 400, 64)      0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 400, 64)      0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 400, 64)      0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 400, 64)      0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 400, 64)      0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 400, 64)      0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_1 (LocallyC (None, 400, 64)      1664000     activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_3 (LocallyC (None, 400, 64)      1664000     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_5 (LocallyC (None, 400, 64)      1664000     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_7 (LocallyC (None, 400, 64)      1664000     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_9 (LocallyC (None, 400, 64)      1664000     activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_11 (Locally (None, 400, 64)      1664000     activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_13 (Locally (None, 400, 64)      1664000     activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_15 (Locally (None, 400, 64)      1664000     activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_17 (Locally (None, 400, 64)      1664000     activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_19 (Locally (None, 400, 64)      1664000     activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_21 (Locally (None, 400, 64)      1664000     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_23 (Locally (None, 400, 64)      1664000     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 400, 64)      256         locally_connected1d_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 400, 64)      256         locally_connected1d_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 400, 64)      256         locally_connected1d_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 400, 64)      256         locally_connected1d_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 400, 64)      256         locally_connected1d_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 400, 64)      256         locally_connected1d_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 400, 64)      256         locally_connected1d_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 400, 64)      256         locally_connected1d_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 400, 64)      256         locally_connected1d_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 400, 64)      256         locally_connected1d_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 400, 64)      256         locally_connected1d_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 400, 64)      256         locally_connected1d_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 400, 64)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 400, 64)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 400, 64)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 400, 64)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 400, 64)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 400, 64)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 400, 64)      0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 400, 64)      0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 400, 64)      0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 400, 64)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 400, 64)      0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 400, 64)      0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 400, 64)      0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 400, 64)      0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 400, 64)      0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 400, 64)      0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 400, 64)      0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 400, 64)      0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 400, 64)      0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 400, 64)      0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 400, 64)      0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 400, 64)      0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 400, 64)      0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 400, 64)      0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_stack (TensorFlowOp [(None, 400, 12, 64) 0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "                                                                 dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 307200)       0           tf_op_layer_stack[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          157286912   flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 512)          0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 512)          0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          262656      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 512)          0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 512)          0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          65664       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 128)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 128)          0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 52)           6708        activation_50[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 197,726,132\n",
      "Trainable params: 197,717,684\n",
      "Non-trainable params: 8,448\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 4.3575 - accuracy: 0.1377\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.24279, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 122s 747ms/step - loss: 4.3575 - accuracy: 0.1377 - val_loss: 3.4640 - val_accuracy: 0.2428 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.3582 - accuracy: 0.2527\n",
      "Epoch 00002: val_accuracy improved from 0.24279 to 0.29742, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 61s 373ms/step - loss: 3.3582 - accuracy: 0.2527 - val_loss: 3.1800 - val_accuracy: 0.2974 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.0820 - accuracy: 0.3187\n",
      "Epoch 00003: val_accuracy improved from 0.29742 to 0.32051, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 59s 365ms/step - loss: 3.0820 - accuracy: 0.3187 - val_loss: 3.1840 - val_accuracy: 0.3205 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.9668 - accuracy: 0.3822\n",
      "Epoch 00004: val_accuracy improved from 0.32051 to 0.32513, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 60s 369ms/step - loss: 2.9668 - accuracy: 0.3822 - val_loss: 3.2512 - val_accuracy: 0.3251 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.8472 - accuracy: 0.4251\n",
      "Epoch 00005: val_accuracy improved from 0.32513 to 0.33551, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 60s 368ms/step - loss: 2.8472 - accuracy: 0.4251 - val_loss: 3.2550 - val_accuracy: 0.3355 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.7635 - accuracy: 0.4468\n",
      "Epoch 00006: val_accuracy did not improve from 0.33551\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.7635 - accuracy: 0.4468 - val_loss: 3.3705 - val_accuracy: 0.3236 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.6203 - accuracy: 0.5109\n",
      "Epoch 00007: val_accuracy did not improve from 0.33551\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 2.6203 - accuracy: 0.5109 - val_loss: 3.3842 - val_accuracy: 0.3255 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.5515 - accuracy: 0.5368\n",
      "Epoch 00008: val_accuracy did not improve from 0.33551\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 2.5515 - accuracy: 0.5368 - val_loss: 3.4920 - val_accuracy: 0.3321 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.4420 - accuracy: 0.5743\n",
      "Epoch 00009: val_accuracy did not improve from 0.33551\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.4420 - accuracy: 0.5743 - val_loss: 3.5156 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.3203 - accuracy: 0.6253\n",
      "Epoch 00010: val_accuracy improved from 0.33551 to 0.34436, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 60s 368ms/step - loss: 2.3203 - accuracy: 0.6253 - val_loss: 3.5770 - val_accuracy: 0.3444 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.2679 - accuracy: 0.6290\n",
      "Epoch 00011: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 2.2679 - accuracy: 0.6290 - val_loss: 3.6058 - val_accuracy: 0.3382 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.2503 - accuracy: 0.6367\n",
      "Epoch 00012: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 2.2503 - accuracy: 0.6367 - val_loss: 3.7872 - val_accuracy: 0.3321 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.1575 - accuracy: 0.6747\n",
      "Epoch 00013: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.1575 - accuracy: 0.6747 - val_loss: 3.7211 - val_accuracy: 0.3109 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.0502 - accuracy: 0.7040\n",
      "Epoch 00014: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.0502 - accuracy: 0.7040 - val_loss: 3.8159 - val_accuracy: 0.3305 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.0241 - accuracy: 0.7148\n",
      "Epoch 00015: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.0241 - accuracy: 0.7148 - val_loss: 3.8513 - val_accuracy: 0.3263 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.9670 - accuracy: 0.7344\n",
      "Epoch 00016: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.9670 - accuracy: 0.7344 - val_loss: 3.8975 - val_accuracy: 0.3274 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.9449 - accuracy: 0.7373\n",
      "Epoch 00017: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.9449 - accuracy: 0.7373 - val_loss: 3.9266 - val_accuracy: 0.3082 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8836 - accuracy: 0.7550\n",
      "Epoch 00018: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 1.8836 - accuracy: 0.7550 - val_loss: 3.9509 - val_accuracy: 0.3136 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7753 - accuracy: 0.7715\n",
      "Epoch 00019: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 1.7753 - accuracy: 0.7715 - val_loss: 4.0096 - val_accuracy: 0.3209 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7428 - accuracy: 0.7861\n",
      "Epoch 00020: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.7428 - accuracy: 0.7861 - val_loss: 4.2176 - val_accuracy: 0.3043 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7732 - accuracy: 0.7815\n",
      "Epoch 00021: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.7732 - accuracy: 0.7815 - val_loss: 4.1860 - val_accuracy: 0.3093 - lr: 0.0010\n",
      "Epoch 22/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7124 - accuracy: 0.8017\n",
      "Epoch 00022: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.7124 - accuracy: 0.8017 - val_loss: 4.1510 - val_accuracy: 0.3067 - lr: 0.0010\n",
      "Epoch 23/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6448 - accuracy: 0.8142\n",
      "Epoch 00023: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 1.6448 - accuracy: 0.8142 - val_loss: 4.2045 - val_accuracy: 0.3113 - lr: 0.0010\n",
      "Epoch 24/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6353 - accuracy: 0.8157\n",
      "Epoch 00024: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.6353 - accuracy: 0.8157 - val_loss: 4.2405 - val_accuracy: 0.3093 - lr: 0.0010\n",
      "Epoch 25/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5803 - accuracy: 0.8255\n",
      "Epoch 00025: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 1.5803 - accuracy: 0.8255 - val_loss: 4.2905 - val_accuracy: 0.3043 - lr: 0.0010\n",
      "Epoch 26/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5474 - accuracy: 0.8336\n",
      "Epoch 00026: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 1.5474 - accuracy: 0.8336 - val_loss: 4.3447 - val_accuracy: 0.3009 - lr: 0.0010\n",
      "Epoch 27/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5198 - accuracy: 0.8357\n",
      "Epoch 00027: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 331ms/step - loss: 1.5198 - accuracy: 0.8357 - val_loss: 4.4002 - val_accuracy: 0.2886 - lr: 0.0010\n",
      "Epoch 28/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5232 - accuracy: 0.8377\n",
      "Epoch 00028: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 331ms/step - loss: 1.5232 - accuracy: 0.8377 - val_loss: 4.3567 - val_accuracy: 0.3055 - lr: 0.0010\n",
      "Epoch 29/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5337 - accuracy: 0.8342\n",
      "Epoch 00029: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 1.5337 - accuracy: 0.8342 - val_loss: 4.3731 - val_accuracy: 0.3013 - lr: 0.0010\n",
      "Epoch 30/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4901 - accuracy: 0.8490\n",
      "Epoch 00030: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 1.4901 - accuracy: 0.8490 - val_loss: 4.3025 - val_accuracy: 0.2982 - lr: 0.0010\n",
      "Epoch 31/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4460 - accuracy: 0.8513\n",
      "Epoch 00031: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.4460 - accuracy: 0.8513 - val_loss: 4.4838 - val_accuracy: 0.2997 - lr: 0.0010\n",
      "Epoch 32/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4486 - accuracy: 0.8611\n",
      "Epoch 00032: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 1.4486 - accuracy: 0.8611 - val_loss: 4.5106 - val_accuracy: 0.2947 - lr: 0.0010\n",
      "Epoch 33/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4296 - accuracy: 0.8613\n",
      "Epoch 00033: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 1.4296 - accuracy: 0.8613 - val_loss: 4.4046 - val_accuracy: 0.3101 - lr: 0.0010\n",
      "Epoch 34/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3988 - accuracy: 0.8646\n",
      "Epoch 00034: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 1.3988 - accuracy: 0.8646 - val_loss: 4.5856 - val_accuracy: 0.2886 - lr: 0.0010\n",
      "Epoch 35/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4021 - accuracy: 0.8682\n",
      "Epoch 00035: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 1.4021 - accuracy: 0.8682 - val_loss: 4.4438 - val_accuracy: 0.3005 - lr: 0.0010\n",
      "Epoch 36/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3627 - accuracy: 0.8740\n",
      "Epoch 00036: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 1.3627 - accuracy: 0.8740 - val_loss: 4.4905 - val_accuracy: 0.3028 - lr: 0.0010\n",
      "Epoch 37/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3127 - accuracy: 0.8806\n",
      "Epoch 00037: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.3127 - accuracy: 0.8806 - val_loss: 4.6050 - val_accuracy: 0.2990 - lr: 0.0010\n",
      "Epoch 38/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3143 - accuracy: 0.8819\n",
      "Epoch 00038: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 331ms/step - loss: 1.3143 - accuracy: 0.8819 - val_loss: 4.6201 - val_accuracy: 0.3067 - lr: 0.0010\n",
      "Epoch 39/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3317 - accuracy: 0.8792\n",
      "Epoch 00039: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.3317 - accuracy: 0.8792 - val_loss: 4.6033 - val_accuracy: 0.3090 - lr: 0.0010\n",
      "Epoch 40/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.2360 - accuracy: 0.9038\n",
      "Epoch 00040: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.2360 - accuracy: 0.9038 - val_loss: 4.3729 - val_accuracy: 0.3078 - lr: 1.0000e-04\n",
      "Epoch 41/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.1470 - accuracy: 0.9219\n",
      "Epoch 00041: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.1470 - accuracy: 0.9219 - val_loss: 4.4562 - val_accuracy: 0.3086 - lr: 1.0000e-04\n",
      "Epoch 42/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0953 - accuracy: 0.9300\n",
      "Epoch 00042: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 1.0953 - accuracy: 0.9300 - val_loss: 4.4236 - val_accuracy: 0.3059 - lr: 1.0000e-04\n",
      "Epoch 43/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0515 - accuracy: 0.9381\n",
      "Epoch 00043: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.0515 - accuracy: 0.9381 - val_loss: 4.3971 - val_accuracy: 0.3136 - lr: 1.0000e-04\n",
      "Epoch 44/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0377 - accuracy: 0.9304\n",
      "Epoch 00044: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 1.0377 - accuracy: 0.9304 - val_loss: 4.3106 - val_accuracy: 0.3113 - lr: 1.0000e-04\n",
      "Epoch 45/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9783 - accuracy: 0.9427\n",
      "Epoch 00045: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.9783 - accuracy: 0.9427 - val_loss: 4.3484 - val_accuracy: 0.3117 - lr: 1.0000e-04\n",
      "Epoch 46/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9605 - accuracy: 0.9479\n",
      "Epoch 00046: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.9605 - accuracy: 0.9479 - val_loss: 4.3822 - val_accuracy: 0.3067 - lr: 1.0000e-04\n",
      "Epoch 47/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9308 - accuracy: 0.9461\n",
      "Epoch 00047: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.9308 - accuracy: 0.9461 - val_loss: 4.3117 - val_accuracy: 0.3113 - lr: 1.0000e-04\n",
      "Epoch 48/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9093 - accuracy: 0.9492\n",
      "Epoch 00048: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.9093 - accuracy: 0.9492 - val_loss: 4.3419 - val_accuracy: 0.3036 - lr: 1.0000e-04\n",
      "Epoch 49/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8793 - accuracy: 0.9515\n",
      "Epoch 00049: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.8793 - accuracy: 0.9515 - val_loss: 4.3188 - val_accuracy: 0.3086 - lr: 1.0000e-04\n",
      "Epoch 50/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8517 - accuracy: 0.9558\n",
      "Epoch 00050: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.8517 - accuracy: 0.9558 - val_loss: 4.3425 - val_accuracy: 0.3109 - lr: 1.0000e-04\n",
      "Epoch 51/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8172 - accuracy: 0.9596\n",
      "Epoch 00051: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.8172 - accuracy: 0.9596 - val_loss: 4.2802 - val_accuracy: 0.3067 - lr: 1.0000e-04\n",
      "Epoch 52/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8090 - accuracy: 0.9567\n",
      "Epoch 00052: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.8090 - accuracy: 0.9567 - val_loss: 4.3158 - val_accuracy: 0.3009 - lr: 1.0000e-04\n",
      "Epoch 53/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - ETA: 0s - loss: 0.7744 - accuracy: 0.9644\n",
      "Epoch 00053: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.7744 - accuracy: 0.9644 - val_loss: 4.2675 - val_accuracy: 0.3055 - lr: 1.0000e-04\n",
      "Epoch 54/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7640 - accuracy: 0.9615\n",
      "Epoch 00054: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.7640 - accuracy: 0.9615 - val_loss: 4.2701 - val_accuracy: 0.3028 - lr: 1.0000e-04\n",
      "Epoch 55/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7452 - accuracy: 0.9663\n",
      "Epoch 00055: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.7452 - accuracy: 0.9663 - val_loss: 4.2487 - val_accuracy: 0.3070 - lr: 1.0000e-04\n",
      "Epoch 56/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7288 - accuracy: 0.9660\n",
      "Epoch 00056: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.7288 - accuracy: 0.9660 - val_loss: 4.2543 - val_accuracy: 0.3043 - lr: 1.0000e-04\n",
      "Epoch 57/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7108 - accuracy: 0.9696\n",
      "Epoch 00057: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.7108 - accuracy: 0.9696 - val_loss: 4.2770 - val_accuracy: 0.3147 - lr: 1.0000e-04\n",
      "Epoch 58/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6903 - accuracy: 0.9673\n",
      "Epoch 00058: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.6903 - accuracy: 0.9673 - val_loss: 4.2794 - val_accuracy: 0.3059 - lr: 1.0000e-04\n",
      "Epoch 59/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6661 - accuracy: 0.9706\n",
      "Epoch 00059: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.6661 - accuracy: 0.9706 - val_loss: 4.3152 - val_accuracy: 0.3063 - lr: 1.0000e-04\n",
      "Epoch 60/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6620 - accuracy: 0.9669\n",
      "Epoch 00060: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.6620 - accuracy: 0.9669 - val_loss: 4.2612 - val_accuracy: 0.3074 - lr: 1.0000e-04\n",
      "Epoch 61/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6432 - accuracy: 0.9713\n",
      "Epoch 00061: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.6432 - accuracy: 0.9713 - val_loss: 4.3239 - val_accuracy: 0.3074 - lr: 1.0000e-04\n",
      "Epoch 62/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6400 - accuracy: 0.9679\n",
      "Epoch 00062: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.6400 - accuracy: 0.9679 - val_loss: 4.2548 - val_accuracy: 0.3113 - lr: 1.0000e-04\n",
      "Epoch 63/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6279 - accuracy: 0.9685\n",
      "Epoch 00063: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.6279 - accuracy: 0.9685 - val_loss: 4.2112 - val_accuracy: 0.3090 - lr: 1.0000e-04\n",
      "Epoch 64/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6051 - accuracy: 0.9736\n",
      "Epoch 00064: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.6051 - accuracy: 0.9736 - val_loss: 4.3041 - val_accuracy: 0.3051 - lr: 1.0000e-04\n",
      "Epoch 65/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5888 - accuracy: 0.9729\n",
      "Epoch 00065: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.5888 - accuracy: 0.9729 - val_loss: 4.2530 - val_accuracy: 0.3109 - lr: 1.0000e-04\n",
      "Epoch 66/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5718 - accuracy: 0.9775\n",
      "Epoch 00066: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.5718 - accuracy: 0.9775 - val_loss: 4.2650 - val_accuracy: 0.3074 - lr: 1.0000e-04\n",
      "Epoch 67/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5742 - accuracy: 0.9715\n",
      "Epoch 00067: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.5742 - accuracy: 0.9715 - val_loss: 4.3123 - val_accuracy: 0.3078 - lr: 1.0000e-04\n",
      "Epoch 68/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5656 - accuracy: 0.9711\n",
      "Epoch 00068: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 55s 334ms/step - loss: 0.5656 - accuracy: 0.9711 - val_loss: 4.2820 - val_accuracy: 0.3067 - lr: 1.0000e-04\n",
      "Epoch 69/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5492 - accuracy: 0.9725\n",
      "Epoch 00069: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.5492 - accuracy: 0.9725 - val_loss: 4.3148 - val_accuracy: 0.3001 - lr: 1.0000e-04\n",
      "Epoch 70/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5334 - accuracy: 0.9750\n",
      "Epoch 00070: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.5334 - accuracy: 0.9750 - val_loss: 4.2971 - val_accuracy: 0.3036 - lr: 1.0000e-04\n",
      "Epoch 71/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5259 - accuracy: 0.9765\n",
      "Epoch 00071: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.5259 - accuracy: 0.9765 - val_loss: 4.3018 - val_accuracy: 0.3059 - lr: 1.0000e-04\n",
      "Epoch 72/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5137 - accuracy: 0.9783\n",
      "Epoch 00072: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.5137 - accuracy: 0.9783 - val_loss: 4.2918 - val_accuracy: 0.2970 - lr: 1.0000e-04\n",
      "Epoch 73/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5096 - accuracy: 0.9744\n",
      "Epoch 00073: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.5096 - accuracy: 0.9744 - val_loss: 4.2710 - val_accuracy: 0.3024 - lr: 1.0000e-04\n",
      "Epoch 74/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5027 - accuracy: 0.9740\n",
      "Epoch 00074: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.5027 - accuracy: 0.9740 - val_loss: 4.2604 - val_accuracy: 0.3017 - lr: 1.0000e-04\n",
      "Epoch 75/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4883 - accuracy: 0.9783\n",
      "Epoch 00075: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4883 - accuracy: 0.9783 - val_loss: 4.2771 - val_accuracy: 0.3028 - lr: 1.0000e-04\n",
      "Epoch 76/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4823 - accuracy: 0.9775\n",
      "Epoch 00076: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4823 - accuracy: 0.9775 - val_loss: 4.2915 - val_accuracy: 0.3055 - lr: 1.0000e-04\n",
      "Epoch 77/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4756 - accuracy: 0.9794\n",
      "Epoch 00077: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4756 - accuracy: 0.9794 - val_loss: 4.3352 - val_accuracy: 0.3043 - lr: 1.0000e-04\n",
      "Epoch 78/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4694 - accuracy: 0.9760\n",
      "Epoch 00078: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.4694 - accuracy: 0.9760 - val_loss: 4.2272 - val_accuracy: 0.3036 - lr: 1.0000e-04\n",
      "Epoch 79/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4576 - accuracy: 0.9798\n",
      "Epoch 00079: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4576 - accuracy: 0.9798 - val_loss: 4.3324 - val_accuracy: 0.2974 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4536 - accuracy: 0.9786\n",
      "Epoch 00080: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.4536 - accuracy: 0.9786 - val_loss: 4.3429 - val_accuracy: 0.2943 - lr: 1.0000e-05\n",
      "Epoch 81/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4601 - accuracy: 0.9765\n",
      "Epoch 00081: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 331ms/step - loss: 0.4601 - accuracy: 0.9765 - val_loss: 4.3580 - val_accuracy: 0.3005 - lr: 1.0000e-05\n",
      "Epoch 82/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4497 - accuracy: 0.9806\n",
      "Epoch 00082: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 331ms/step - loss: 0.4497 - accuracy: 0.9806 - val_loss: 4.2872 - val_accuracy: 0.3017 - lr: 1.0000e-05\n",
      "Epoch 83/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4524 - accuracy: 0.9786\n",
      "Epoch 00083: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4524 - accuracy: 0.9786 - val_loss: 4.3297 - val_accuracy: 0.3028 - lr: 1.0000e-05\n",
      "Epoch 84/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4513 - accuracy: 0.9783\n",
      "Epoch 00084: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 331ms/step - loss: 0.4513 - accuracy: 0.9783 - val_loss: 4.2040 - val_accuracy: 0.3024 - lr: 1.0000e-05\n",
      "Epoch 85/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4496 - accuracy: 0.9777\n",
      "Epoch 00085: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.4496 - accuracy: 0.9777 - val_loss: 4.2946 - val_accuracy: 0.2936 - lr: 1.0000e-05\n",
      "Epoch 86/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4497 - accuracy: 0.9796\n",
      "Epoch 00086: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4497 - accuracy: 0.9796 - val_loss: 4.3184 - val_accuracy: 0.2993 - lr: 1.0000e-05\n",
      "Epoch 87/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4500 - accuracy: 0.9786\n",
      "Epoch 00087: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4500 - accuracy: 0.9786 - val_loss: 4.2985 - val_accuracy: 0.3047 - lr: 1.0000e-05\n",
      "Epoch 88/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4365 - accuracy: 0.9827\n",
      "Epoch 00088: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4365 - accuracy: 0.9827 - val_loss: 4.3008 - val_accuracy: 0.2974 - lr: 1.0000e-05\n",
      "Epoch 89/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4437 - accuracy: 0.9812\n",
      "Epoch 00089: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 331ms/step - loss: 0.4437 - accuracy: 0.9812 - val_loss: 4.3324 - val_accuracy: 0.3047 - lr: 1.0000e-05\n",
      "Epoch 90/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4383 - accuracy: 0.9806\n",
      "Epoch 00090: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.4383 - accuracy: 0.9806 - val_loss: 4.2850 - val_accuracy: 0.3047 - lr: 1.0000e-05\n",
      "Epoch 91/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4345 - accuracy: 0.9796\n",
      "Epoch 00091: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4345 - accuracy: 0.9796 - val_loss: 4.3006 - val_accuracy: 0.3028 - lr: 1.0000e-05\n",
      "Epoch 92/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4401 - accuracy: 0.9788\n",
      "Epoch 00092: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.4401 - accuracy: 0.9788 - val_loss: 4.3281 - val_accuracy: 0.3028 - lr: 1.0000e-05\n",
      "Epoch 93/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4362 - accuracy: 0.9812\n",
      "Epoch 00093: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.4362 - accuracy: 0.9812 - val_loss: 4.2768 - val_accuracy: 0.3009 - lr: 1.0000e-05\n",
      "Epoch 94/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4349 - accuracy: 0.9812\n",
      "Epoch 00094: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.4349 - accuracy: 0.9812 - val_loss: 4.2379 - val_accuracy: 0.3009 - lr: 1.0000e-05\n",
      "Epoch 95/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4463 - accuracy: 0.9781\n",
      "Epoch 00095: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4463 - accuracy: 0.9781 - val_loss: 4.3009 - val_accuracy: 0.2982 - lr: 1.0000e-05\n",
      "Epoch 96/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4349 - accuracy: 0.9817\n",
      "Epoch 00096: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.4349 - accuracy: 0.9817 - val_loss: 4.3275 - val_accuracy: 0.3078 - lr: 1.0000e-05\n",
      "Epoch 97/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4389 - accuracy: 0.9796\n",
      "Epoch 00097: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4389 - accuracy: 0.9796 - val_loss: 4.2966 - val_accuracy: 0.3047 - lr: 1.0000e-05\n",
      "Epoch 98/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4324 - accuracy: 0.9835\n",
      "Epoch 00098: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4324 - accuracy: 0.9835 - val_loss: 4.2731 - val_accuracy: 0.3040 - lr: 1.0000e-05\n",
      "Epoch 99/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4361 - accuracy: 0.9794\n",
      "Epoch 00099: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4361 - accuracy: 0.9794 - val_loss: 4.2895 - val_accuracy: 0.3028 - lr: 1.0000e-05\n",
      "Epoch 100/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4294 - accuracy: 0.9819\n",
      "Epoch 00100: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 0.4294 - accuracy: 0.9819 - val_loss: 4.2716 - val_accuracy: 0.3059 - lr: 1.0000e-05\n",
      "Epoch 101/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4371 - accuracy: 0.9798\n",
      "Epoch 00101: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.4371 - accuracy: 0.9798 - val_loss: 4.3051 - val_accuracy: 0.3020 - lr: 1.0000e-05\n",
      "Epoch 102/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.4259 - accuracy: 0.9821\n",
      "Epoch 00102: val_accuracy did not improve from 0.34436\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.4259 - accuracy: 0.9821 - val_loss: 4.3013 - val_accuracy: 0.3051 - lr: 1.0000e-05\n",
      "epoch_number 10\n",
      "train accuracy and validation accuracy 0.6253125667572021 0.3443632125854492\n",
      "82/82 [==============================] - 6s 73ms/step - loss: 3.5770 - accuracy: 0.3444\n",
      "test_accuracy 0.3443632125854492\n",
      "[0.3470565676689148, 0.3162754774093628, 0.3166602551937103, 0.3655252158641815, 0.37822240591049194, 0.39168912172317505, 0.3001154363155365, 0.3786071538925171, 0.3443632125854492]\n",
      "test_mean for %d subjects: 9\n",
      "0.348723871840371\n",
      "/media/naveen/nav/mat_codes/nina_DB4_codes/naveen_prep_nlw/sub_wise_process_TT/S10_tr.csv\n",
      "Number of columns in the dataframe: 13\n",
      "Number of rows in the dataframe: 2080000\n",
      "\n",
      "/media/naveen/nav/mat_codes/nina_DB4_codes/naveen_prep_nlw/sub_wise_process_TT/S10_tt.csv\n",
      "Number of columns in the dataframe: 13\n",
      "Number of rows in the dataframe: 1040000\n",
      "\n",
      "x_train shape:  (5199, 400, 12)\n",
      "5199 training samples\n",
      "y_train shape:  (5199,)\n",
      "num_time_periods 400\n",
      "num_sensors 12\n",
      "class_list [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0]\n",
      "x_train shape: (400, 12)\n",
      "input_shape: (400, 12)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "New y_train shape:  (5199, 52)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test shape:  (2599, 400, 12)\n",
      "2599 testing samples\n",
      "y_test shape:  (2599,)\n",
      "x_train shape:  (5199, 400, 12)\n",
      "x_test shape:  (2599, 400, 12)\n",
      "n_outputs 52\n",
      "Model: \"wei_mscnn_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main (InputLayer)               [(None, 400, 12)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_8 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_10 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_12 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_14 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_16 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_18 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_20 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_22 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_1 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_2 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_3 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_4 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_5 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_10[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_6 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_12[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_7 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_14[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_8 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_16[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_9 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_18[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_10 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_20[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_11 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_22[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [()]                 0           tf_op_layer_Shape_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_5 (Te [()]                 0           tf_op_layer_Shape_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_7 (Te [()]                 0           tf_op_layer_Shape_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_9 (Te [()]                 0           tf_op_layer_Shape_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_11 (T [()]                 0           tf_op_layer_Shape_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_13 (T [()]                 0           tf_op_layer_Shape_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_15 (T [()]                 0           tf_op_layer_Shape_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_17 (T [()]                 0           tf_op_layer_Shape_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_19 (T [()]                 0           tf_op_layer_Shape_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_21 (T [()]                 0           tf_op_layer_Shape_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_23 (T [()]                 0           tf_op_layer_Shape_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape/shape (Tens [(3,)]               0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1/shape (Te [(3,)]               0           tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2/shape (Te [(3,)]               0           tf_op_layer_strided_slice_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3/shape (Te [(3,)]               0           tf_op_layer_strided_slice_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4/shape (Te [(3,)]               0           tf_op_layer_strided_slice_9[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5/shape (Te [(3,)]               0           tf_op_layer_strided_slice_11[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6/shape (Te [(3,)]               0           tf_op_layer_strided_slice_13[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7/shape (Te [(3,)]               0           tf_op_layer_strided_slice_15[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8/shape (Te [(3,)]               0           tf_op_layer_strided_slice_17[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9/shape (Te [(3,)]               0           tf_op_layer_strided_slice_19[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_10/shape (T [(3,)]               0           tf_op_layer_strided_slice_21[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_11/shape (T [(3,)]               0           tf_op_layer_strided_slice_23[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 400, 1)]     0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 tf_op_layer_Reshape/shape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_2[0][0]\n",
      "                                                                 tf_op_layer_Reshape_1/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_4[0][0]\n",
      "                                                                 tf_op_layer_Reshape_2/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_6[0][0]\n",
      "                                                                 tf_op_layer_Reshape_3/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_8[0][0]\n",
      "                                                                 tf_op_layer_Reshape_4/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_10[0][0\n",
      "                                                                 tf_op_layer_Reshape_5/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_12[0][0\n",
      "                                                                 tf_op_layer_Reshape_6/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_14[0][0\n",
      "                                                                 tf_op_layer_Reshape_7/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_16[0][0\n",
      "                                                                 tf_op_layer_Reshape_8/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_18[0][0\n",
      "                                                                 tf_op_layer_Reshape_9/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_10 (TensorF [(None, 400, 1)]     0           tf_op_layer_strided_slice_20[0][0\n",
      "                                                                 tf_op_layer_Reshape_10/shape[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_11 (TensorF [(None, 400, 1)]     0           tf_op_layer_strided_slice_22[0][0\n",
      "                                                                 tf_op_layer_Reshape_11/shape[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 400, 64)      256         tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 400, 64)      256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 400, 64)      256         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 400, 64)      256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 400, 64)      256         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 400, 64)      256         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 400, 64)      256         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 400, 64)      256         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 400, 64)      256         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 400, 64)      256         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 400, 64)      256         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 400, 64)      256         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 400, 64)      256         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 400, 64)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 400, 64)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 400, 64)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 400, 64)      0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 400, 64)      0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 400, 64)      0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 400, 64)      0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 400, 64)      0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 400, 64)      0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 400, 64)      0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 400, 64)      0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 400, 64)      0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 400, 64)      12352       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 400, 64)      12352       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 400, 64)      12352       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 400, 64)      12352       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 400, 64)      12352       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 400, 64)      12352       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 400, 64)      12352       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 400, 64)      12352       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 400, 64)      12352       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 400, 64)      12352       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 400, 64)      12352       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 400, 64)      12352       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 400, 64)      256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 400, 64)      256         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 400, 64)      256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 400, 64)      256         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 400, 64)      256         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 400, 64)      256         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 400, 64)      256         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 400, 64)      256         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 400, 64)      256         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 400, 64)      256         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 400, 64)      256         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 400, 64)      256         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 400, 64)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 400, 64)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 400, 64)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 400, 64)      0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 400, 64)      0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 400, 64)      0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 400, 64)      0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 400, 64)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 400, 64)      0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 400, 64)      0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 400, 64)      0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 400, 64)      0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d (LocallyCon (None, 400, 64)      1664000     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_2 (LocallyC (None, 400, 64)      1664000     activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_4 (LocallyC (None, 400, 64)      1664000     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_6 (LocallyC (None, 400, 64)      1664000     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_8 (LocallyC (None, 400, 64)      1664000     activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_10 (Locally (None, 400, 64)      1664000     activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_12 (Locally (None, 400, 64)      1664000     activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_14 (Locally (None, 400, 64)      1664000     activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_16 (Locally (None, 400, 64)      1664000     activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_18 (Locally (None, 400, 64)      1664000     activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_20 (Locally (None, 400, 64)      1664000     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_22 (Locally (None, 400, 64)      1664000     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 400, 64)      256         locally_connected1d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 400, 64)      256         locally_connected1d_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 400, 64)      256         locally_connected1d_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 400, 64)      256         locally_connected1d_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 400, 64)      256         locally_connected1d_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 400, 64)      256         locally_connected1d_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 400, 64)      256         locally_connected1d_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 400, 64)      256         locally_connected1d_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 400, 64)      256         locally_connected1d_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 400, 64)      256         locally_connected1d_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 400, 64)      256         locally_connected1d_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 400, 64)      256         locally_connected1d_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 400, 64)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 400, 64)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 400, 64)      0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 400, 64)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 400, 64)      0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 400, 64)      0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 400, 64)      0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 400, 64)      0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 400, 64)      0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 400, 64)      0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 400, 64)      0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 400, 64)      0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_1 (LocallyC (None, 400, 64)      1664000     activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_3 (LocallyC (None, 400, 64)      1664000     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_5 (LocallyC (None, 400, 64)      1664000     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_7 (LocallyC (None, 400, 64)      1664000     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_9 (LocallyC (None, 400, 64)      1664000     activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_11 (Locally (None, 400, 64)      1664000     activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_13 (Locally (None, 400, 64)      1664000     activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_15 (Locally (None, 400, 64)      1664000     activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_17 (Locally (None, 400, 64)      1664000     activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_19 (Locally (None, 400, 64)      1664000     activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_21 (Locally (None, 400, 64)      1664000     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_23 (Locally (None, 400, 64)      1664000     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 400, 64)      256         locally_connected1d_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 400, 64)      256         locally_connected1d_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 400, 64)      256         locally_connected1d_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 400, 64)      256         locally_connected1d_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 400, 64)      256         locally_connected1d_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 400, 64)      256         locally_connected1d_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 400, 64)      256         locally_connected1d_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 400, 64)      256         locally_connected1d_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 400, 64)      256         locally_connected1d_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 400, 64)      256         locally_connected1d_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 400, 64)      256         locally_connected1d_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 400, 64)      256         locally_connected1d_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 400, 64)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 400, 64)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 400, 64)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 400, 64)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 400, 64)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 400, 64)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 400, 64)      0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 400, 64)      0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 400, 64)      0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 400, 64)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 400, 64)      0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 400, 64)      0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 400, 64)      0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 400, 64)      0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 400, 64)      0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 400, 64)      0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 400, 64)      0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 400, 64)      0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 400, 64)      0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 400, 64)      0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 400, 64)      0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 400, 64)      0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 400, 64)      0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 400, 64)      0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_stack (TensorFlowOp [(None, 400, 12, 64) 0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "                                                                 dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 307200)       0           tf_op_layer_stack[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          157286912   flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 512)          0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 512)          0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          262656      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 512)          0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 512)          0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          65664       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 128)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 128)          0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 52)           6708        activation_50[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 197,726,132\n",
      "Trainable params: 197,717,684\n",
      "Non-trainable params: 8,448\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 4.7360 - accuracy: 0.1118\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.21047, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 123s 755ms/step - loss: 4.7360 - accuracy: 0.1118 - val_loss: 3.7439 - val_accuracy: 0.2105 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.6712 - accuracy: 0.2114\n",
      "Epoch 00002: val_accuracy improved from 0.21047 to 0.24933, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 60s 367ms/step - loss: 3.6712 - accuracy: 0.2114 - val_loss: 3.4454 - val_accuracy: 0.2493 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.3733 - accuracy: 0.2751\n",
      "Epoch 00003: val_accuracy did not improve from 0.24933\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 3.3733 - accuracy: 0.2751 - val_loss: 3.4739 - val_accuracy: 0.2451 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.2510 - accuracy: 0.3353\n",
      "Epoch 00004: val_accuracy improved from 0.24933 to 0.26549, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 59s 364ms/step - loss: 3.2510 - accuracy: 0.3353 - val_loss: 3.5701 - val_accuracy: 0.2655 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.2194 - accuracy: 0.3683\n",
      "Epoch 00005: val_accuracy did not improve from 0.26549\n",
      "163/163 [==============================] - 54s 331ms/step - loss: 3.2194 - accuracy: 0.3683 - val_loss: 3.6845 - val_accuracy: 0.2643 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.0547 - accuracy: 0.4214\n",
      "Epoch 00006: val_accuracy improved from 0.26549 to 0.27241, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "163/163 [==============================] - 59s 360ms/step - loss: 3.0547 - accuracy: 0.4214 - val_loss: 3.7239 - val_accuracy: 0.2724 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.9205 - accuracy: 0.4718\n",
      "Epoch 00007: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.9205 - accuracy: 0.4718 - val_loss: 3.8601 - val_accuracy: 0.2659 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.8298 - accuracy: 0.5153\n",
      "Epoch 00008: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 2.8298 - accuracy: 0.5153 - val_loss: 3.9171 - val_accuracy: 0.2705 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.7851 - accuracy: 0.5370\n",
      "Epoch 00009: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 2.7851 - accuracy: 0.5370 - val_loss: 4.0723 - val_accuracy: 0.2597 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.6515 - accuracy: 0.5668\n",
      "Epoch 00010: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 2.6515 - accuracy: 0.5668 - val_loss: 4.1173 - val_accuracy: 0.2589 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.5646 - accuracy: 0.5899\n",
      "Epoch 00011: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 2.5646 - accuracy: 0.5899 - val_loss: 4.2015 - val_accuracy: 0.2655 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.4962 - accuracy: 0.6270\n",
      "Epoch 00012: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.4962 - accuracy: 0.6270 - val_loss: 4.3851 - val_accuracy: 0.2516 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.3905 - accuracy: 0.6430\n",
      "Epoch 00013: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.3905 - accuracy: 0.6430 - val_loss: 4.2738 - val_accuracy: 0.2689 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.2854 - accuracy: 0.6765\n",
      "Epoch 00014: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.2854 - accuracy: 0.6765 - val_loss: 4.3632 - val_accuracy: 0.2570 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.2853 - accuracy: 0.6753\n",
      "Epoch 00015: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 2.2853 - accuracy: 0.6753 - val_loss: 4.4960 - val_accuracy: 0.2482 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.2314 - accuracy: 0.6907\n",
      "Epoch 00016: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 2.2314 - accuracy: 0.6907 - val_loss: 4.6132 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.1240 - accuracy: 0.7261\n",
      "Epoch 00017: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.1240 - accuracy: 0.7261 - val_loss: 4.6102 - val_accuracy: 0.2382 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.1000 - accuracy: 0.7298\n",
      "Epoch 00018: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.1000 - accuracy: 0.7298 - val_loss: 4.6268 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.0772 - accuracy: 0.7453\n",
      "Epoch 00019: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.0772 - accuracy: 0.7453 - val_loss: 4.7459 - val_accuracy: 0.2416 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 2.0191 - accuracy: 0.7473\n",
      "Epoch 00020: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 2.0191 - accuracy: 0.7473 - val_loss: 4.7256 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8899 - accuracy: 0.7755\n",
      "Epoch 00021: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.8899 - accuracy: 0.7755 - val_loss: 4.8362 - val_accuracy: 0.2424 - lr: 0.0010\n",
      "Epoch 22/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8483 - accuracy: 0.7852\n",
      "Epoch 00022: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.8483 - accuracy: 0.7852 - val_loss: 4.9056 - val_accuracy: 0.2336 - lr: 0.0010\n",
      "Epoch 23/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.9218 - accuracy: 0.7780\n",
      "Epoch 00023: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.9218 - accuracy: 0.7780 - val_loss: 5.0400 - val_accuracy: 0.2282 - lr: 0.0010\n",
      "Epoch 24/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.8564 - accuracy: 0.7930\n",
      "Epoch 00024: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 54s 333ms/step - loss: 1.8564 - accuracy: 0.7930 - val_loss: 4.9824 - val_accuracy: 0.2239 - lr: 0.0010\n",
      "Epoch 25/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7992 - accuracy: 0.8113\n",
      "Epoch 00025: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.7992 - accuracy: 0.8113 - val_loss: 4.9436 - val_accuracy: 0.2205 - lr: 0.0010\n",
      "Epoch 26/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7355 - accuracy: 0.8150\n",
      "Epoch 00026: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 1.7355 - accuracy: 0.8150 - val_loss: 4.9271 - val_accuracy: 0.2339 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.7414 - accuracy: 0.8113\n",
      "Epoch 00027: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 61s 372ms/step - loss: 1.7414 - accuracy: 0.8113 - val_loss: 5.0619 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 28/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6601 - accuracy: 0.8334\n",
      "Epoch 00028: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 61s 377ms/step - loss: 1.6601 - accuracy: 0.8334 - val_loss: 5.1141 - val_accuracy: 0.2297 - lr: 0.0010\n",
      "Epoch 29/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6257 - accuracy: 0.8402\n",
      "Epoch 00029: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 58s 353ms/step - loss: 1.6257 - accuracy: 0.8402 - val_loss: 5.0519 - val_accuracy: 0.2301 - lr: 0.0010\n",
      "Epoch 30/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5974 - accuracy: 0.8430\n",
      "Epoch 00030: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 55s 338ms/step - loss: 1.5974 - accuracy: 0.8430 - val_loss: 5.2358 - val_accuracy: 0.2382 - lr: 0.0010\n",
      "Epoch 31/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.6006 - accuracy: 0.8517\n",
      "Epoch 00031: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 55s 338ms/step - loss: 1.6006 - accuracy: 0.8517 - val_loss: 5.1337 - val_accuracy: 0.2439 - lr: 0.0010\n",
      "Epoch 32/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5496 - accuracy: 0.8517\n",
      "Epoch 00032: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 56s 341ms/step - loss: 1.5496 - accuracy: 0.8517 - val_loss: 5.3138 - val_accuracy: 0.2289 - lr: 0.0010\n",
      "Epoch 33/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5693 - accuracy: 0.8505\n",
      "Epoch 00033: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 56s 341ms/step - loss: 1.5693 - accuracy: 0.8505 - val_loss: 5.1653 - val_accuracy: 0.2320 - lr: 0.0010\n",
      "Epoch 34/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5679 - accuracy: 0.8534\n",
      "Epoch 00034: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 55s 339ms/step - loss: 1.5679 - accuracy: 0.8534 - val_loss: 5.2603 - val_accuracy: 0.2370 - lr: 0.0010\n",
      "Epoch 35/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5455 - accuracy: 0.8590\n",
      "Epoch 00035: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 1.5455 - accuracy: 0.8590 - val_loss: 5.3981 - val_accuracy: 0.2289 - lr: 0.0010\n",
      "Epoch 36/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.5431 - accuracy: 0.8567\n",
      "Epoch 00036: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 55s 338ms/step - loss: 1.5431 - accuracy: 0.8567 - val_loss: 5.3979 - val_accuracy: 0.2370 - lr: 0.0010\n",
      "Epoch 37/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4948 - accuracy: 0.8686\n",
      "Epoch 00037: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 56s 342ms/step - loss: 1.4948 - accuracy: 0.8686 - val_loss: 5.2423 - val_accuracy: 0.2235 - lr: 0.0010\n",
      "Epoch 38/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4689 - accuracy: 0.8706\n",
      "Epoch 00038: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 56s 341ms/step - loss: 1.4689 - accuracy: 0.8706 - val_loss: 5.4420 - val_accuracy: 0.2116 - lr: 0.0010\n",
      "Epoch 39/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.4933 - accuracy: 0.8671\n",
      "Epoch 00039: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 1.4933 - accuracy: 0.8671 - val_loss: 5.4418 - val_accuracy: 0.2316 - lr: 0.0010\n",
      "Epoch 40/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.3951 - accuracy: 0.8892\n",
      "Epoch 00040: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 55s 340ms/step - loss: 1.3951 - accuracy: 0.8892 - val_loss: 5.2893 - val_accuracy: 0.2339 - lr: 1.0000e-04\n",
      "Epoch 41/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.2943 - accuracy: 0.9121\n",
      "Epoch 00041: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 56s 343ms/step - loss: 1.2943 - accuracy: 0.9121 - val_loss: 5.1829 - val_accuracy: 0.2320 - lr: 1.0000e-04\n",
      "Epoch 42/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.2276 - accuracy: 0.9281\n",
      "Epoch 00042: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 55s 340ms/step - loss: 1.2276 - accuracy: 0.9281 - val_loss: 5.1817 - val_accuracy: 0.2339 - lr: 1.0000e-04\n",
      "Epoch 43/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.1816 - accuracy: 0.9338\n",
      "Epoch 00043: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 56s 344ms/step - loss: 1.1816 - accuracy: 0.9338 - val_loss: 5.1434 - val_accuracy: 0.2347 - lr: 1.0000e-04\n",
      "Epoch 44/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.1608 - accuracy: 0.9331\n",
      "Epoch 00044: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 56s 343ms/step - loss: 1.1608 - accuracy: 0.9331 - val_loss: 5.1395 - val_accuracy: 0.2351 - lr: 1.0000e-04\n",
      "Epoch 45/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.1168 - accuracy: 0.9415\n",
      "Epoch 00045: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 56s 344ms/step - loss: 1.1168 - accuracy: 0.9415 - val_loss: 5.1260 - val_accuracy: 0.2386 - lr: 1.0000e-04\n",
      "Epoch 46/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0880 - accuracy: 0.9411\n",
      "Epoch 00046: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 56s 343ms/step - loss: 1.0880 - accuracy: 0.9411 - val_loss: 5.0849 - val_accuracy: 0.2336 - lr: 1.0000e-04\n",
      "Epoch 47/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0433 - accuracy: 0.9494\n",
      "Epoch 00047: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 55s 338ms/step - loss: 1.0433 - accuracy: 0.9494 - val_loss: 5.1852 - val_accuracy: 0.2339 - lr: 1.0000e-04\n",
      "Epoch 48/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0283 - accuracy: 0.9490\n",
      "Epoch 00048: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 55s 339ms/step - loss: 1.0283 - accuracy: 0.9490 - val_loss: 5.0841 - val_accuracy: 0.2332 - lr: 1.0000e-04\n",
      "Epoch 49/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 1.0016 - accuracy: 0.9527\n",
      "Epoch 00049: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 57s 350ms/step - loss: 1.0016 - accuracy: 0.9527 - val_loss: 5.1091 - val_accuracy: 0.2297 - lr: 1.0000e-04\n",
      "Epoch 50/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9721 - accuracy: 0.9569\n",
      "Epoch 00050: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 56s 342ms/step - loss: 0.9721 - accuracy: 0.9569 - val_loss: 5.0917 - val_accuracy: 0.2351 - lr: 1.0000e-04\n",
      "Epoch 51/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9496 - accuracy: 0.9567\n",
      "Epoch 00051: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 55s 338ms/step - loss: 0.9496 - accuracy: 0.9567 - val_loss: 5.1198 - val_accuracy: 0.2309 - lr: 1.0000e-04\n",
      "Epoch 52/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9244 - accuracy: 0.9577\n",
      "Epoch 00052: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.9244 - accuracy: 0.9577 - val_loss: 5.0317 - val_accuracy: 0.2343 - lr: 1.0000e-04\n",
      "Epoch 53/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.9082 - accuracy: 0.9600\n",
      "Epoch 00053: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 56s 341ms/step - loss: 0.9082 - accuracy: 0.9600 - val_loss: 5.0929 - val_accuracy: 0.2359 - lr: 1.0000e-04\n",
      "Epoch 54/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8730 - accuracy: 0.9613\n",
      "Epoch 00054: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 56s 341ms/step - loss: 0.8730 - accuracy: 0.9613 - val_loss: 5.1105 - val_accuracy: 0.2370 - lr: 1.0000e-04\n",
      "Epoch 55/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8593 - accuracy: 0.9644\n",
      "Epoch 00055: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 55s 336ms/step - loss: 0.8593 - accuracy: 0.9644 - val_loss: 5.0504 - val_accuracy: 0.2359 - lr: 1.0000e-04\n",
      "Epoch 56/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8370 - accuracy: 0.9646\n",
      "Epoch 00056: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 55s 337ms/step - loss: 0.8370 - accuracy: 0.9646 - val_loss: 5.0336 - val_accuracy: 0.2351 - lr: 1.0000e-04\n",
      "Epoch 57/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8170 - accuracy: 0.9677\n",
      "Epoch 00057: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 56s 341ms/step - loss: 0.8170 - accuracy: 0.9677 - val_loss: 5.0303 - val_accuracy: 0.2339 - lr: 1.0000e-04\n",
      "Epoch 58/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.8028 - accuracy: 0.9638\n",
      "Epoch 00058: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 57s 352ms/step - loss: 0.8028 - accuracy: 0.9638 - val_loss: 5.0296 - val_accuracy: 0.2351 - lr: 1.0000e-04\n",
      "Epoch 59/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7859 - accuracy: 0.9635\n",
      "Epoch 00059: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 56s 344ms/step - loss: 0.7859 - accuracy: 0.9635 - val_loss: 5.0518 - val_accuracy: 0.2355 - lr: 1.0000e-04\n",
      "Epoch 60/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7578 - accuracy: 0.9721\n",
      "Epoch 00060: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 57s 350ms/step - loss: 0.7578 - accuracy: 0.9721 - val_loss: 5.0747 - val_accuracy: 0.2351 - lr: 1.0000e-04\n",
      "Epoch 61/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7552 - accuracy: 0.9648\n",
      "Epoch 00061: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 57s 347ms/step - loss: 0.7552 - accuracy: 0.9648 - val_loss: 5.0633 - val_accuracy: 0.2278 - lr: 1.0000e-04\n",
      "Epoch 62/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7372 - accuracy: 0.9696\n",
      "Epoch 00062: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 56s 345ms/step - loss: 0.7372 - accuracy: 0.9696 - val_loss: 5.0658 - val_accuracy: 0.2274 - lr: 1.0000e-04\n",
      "Epoch 63/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7114 - accuracy: 0.9727\n",
      "Epoch 00063: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 57s 350ms/step - loss: 0.7114 - accuracy: 0.9727 - val_loss: 5.0833 - val_accuracy: 0.2305 - lr: 1.0000e-04\n",
      "Epoch 64/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.7027 - accuracy: 0.9713\n",
      "Epoch 00064: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 56s 345ms/step - loss: 0.7027 - accuracy: 0.9713 - val_loss: 5.1189 - val_accuracy: 0.2235 - lr: 1.0000e-04\n",
      "Epoch 65/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6998 - accuracy: 0.9683\n",
      "Epoch 00065: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 57s 348ms/step - loss: 0.6998 - accuracy: 0.9683 - val_loss: 5.0645 - val_accuracy: 0.2305 - lr: 1.0000e-04\n",
      "Epoch 66/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6676 - accuracy: 0.9756\n",
      "Epoch 00066: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 58s 355ms/step - loss: 0.6676 - accuracy: 0.9756 - val_loss: 5.0966 - val_accuracy: 0.2312 - lr: 1.0000e-04\n",
      "Epoch 67/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6565 - accuracy: 0.9760\n",
      "Epoch 00067: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 58s 357ms/step - loss: 0.6565 - accuracy: 0.9760 - val_loss: 5.0546 - val_accuracy: 0.2251 - lr: 1.0000e-04\n",
      "Epoch 68/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6468 - accuracy: 0.9748\n",
      "Epoch 00068: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 60s 369ms/step - loss: 0.6468 - accuracy: 0.9748 - val_loss: 5.1162 - val_accuracy: 0.2255 - lr: 1.0000e-04\n",
      "Epoch 69/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6286 - accuracy: 0.9746\n",
      "Epoch 00069: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 56s 346ms/step - loss: 0.6286 - accuracy: 0.9746 - val_loss: 5.0629 - val_accuracy: 0.2274 - lr: 1.0000e-04\n",
      "Epoch 70/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6325 - accuracy: 0.9708\n",
      "Epoch 00070: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 56s 346ms/step - loss: 0.6325 - accuracy: 0.9708 - val_loss: 5.0943 - val_accuracy: 0.2239 - lr: 1.0000e-04\n",
      "Epoch 71/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.6213 - accuracy: 0.9702\n",
      "Epoch 00071: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 57s 348ms/step - loss: 0.6213 - accuracy: 0.9702 - val_loss: 5.1024 - val_accuracy: 0.2224 - lr: 1.0000e-04\n",
      "Epoch 72/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5965 - accuracy: 0.9781\n",
      "Epoch 00072: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 56s 347ms/step - loss: 0.5965 - accuracy: 0.9781 - val_loss: 5.1260 - val_accuracy: 0.2289 - lr: 1.0000e-04\n",
      "Epoch 73/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5844 - accuracy: 0.9781\n",
      "Epoch 00073: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 58s 355ms/step - loss: 0.5844 - accuracy: 0.9781 - val_loss: 5.1691 - val_accuracy: 0.2266 - lr: 1.0000e-04\n",
      "Epoch 74/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5884 - accuracy: 0.9738\n",
      "Epoch 00074: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 59s 365ms/step - loss: 0.5884 - accuracy: 0.9738 - val_loss: 5.1135 - val_accuracy: 0.2312 - lr: 1.0000e-04\n",
      "Epoch 75/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5676 - accuracy: 0.9758\n",
      "Epoch 00075: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 59s 363ms/step - loss: 0.5676 - accuracy: 0.9758 - val_loss: 5.0679 - val_accuracy: 0.2255 - lr: 1.0000e-04\n",
      "Epoch 76/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5677 - accuracy: 0.9706\n",
      "Epoch 00076: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 59s 361ms/step - loss: 0.5677 - accuracy: 0.9706 - val_loss: 5.0856 - val_accuracy: 0.2243 - lr: 1.0000e-04\n",
      "Epoch 77/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5531 - accuracy: 0.9763\n",
      "Epoch 00077: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 55s 339ms/step - loss: 0.5531 - accuracy: 0.9763 - val_loss: 5.1047 - val_accuracy: 0.2232 - lr: 1.0000e-04\n",
      "Epoch 78/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5450 - accuracy: 0.9746\n",
      "Epoch 00078: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 55s 338ms/step - loss: 0.5450 - accuracy: 0.9746 - val_loss: 5.0822 - val_accuracy: 0.2285 - lr: 1.0000e-04\n",
      "Epoch 79/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5325 - accuracy: 0.9779\n",
      "Epoch 00079: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 57s 349ms/step - loss: 0.5325 - accuracy: 0.9779 - val_loss: 5.1702 - val_accuracy: 0.2270 - lr: 1.0000e-04\n",
      "Epoch 80/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5291 - accuracy: 0.9771\n",
      "Epoch 00080: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 60s 370ms/step - loss: 0.5291 - accuracy: 0.9771 - val_loss: 5.1375 - val_accuracy: 0.2312 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5273 - accuracy: 0.9796\n",
      "Epoch 00081: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 57s 353ms/step - loss: 0.5273 - accuracy: 0.9796 - val_loss: 5.1162 - val_accuracy: 0.2305 - lr: 1.0000e-05\n",
      "Epoch 82/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5331 - accuracy: 0.9752\n",
      "Epoch 00082: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 56s 345ms/step - loss: 0.5331 - accuracy: 0.9752 - val_loss: 5.1146 - val_accuracy: 0.2316 - lr: 1.0000e-05\n",
      "Epoch 83/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5306 - accuracy: 0.9765\n",
      "Epoch 00083: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 57s 347ms/step - loss: 0.5306 - accuracy: 0.9765 - val_loss: 5.0830 - val_accuracy: 0.2312 - lr: 1.0000e-05\n",
      "Epoch 84/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5317 - accuracy: 0.9752\n",
      "Epoch 00084: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 56s 344ms/step - loss: 0.5317 - accuracy: 0.9752 - val_loss: 5.1152 - val_accuracy: 0.2274 - lr: 1.0000e-05\n",
      "Epoch 85/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5186 - accuracy: 0.9798\n",
      "Epoch 00085: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 56s 345ms/step - loss: 0.5186 - accuracy: 0.9798 - val_loss: 5.1717 - val_accuracy: 0.2305 - lr: 1.0000e-05\n",
      "Epoch 86/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5205 - accuracy: 0.9794\n",
      "Epoch 00086: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 60s 368ms/step - loss: 0.5205 - accuracy: 0.9794 - val_loss: 5.1449 - val_accuracy: 0.2328 - lr: 1.0000e-05\n",
      "Epoch 87/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5229 - accuracy: 0.9792\n",
      "Epoch 00087: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 56s 342ms/step - loss: 0.5229 - accuracy: 0.9792 - val_loss: 5.1729 - val_accuracy: 0.2266 - lr: 1.0000e-05\n",
      "Epoch 88/120\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.5069 - accuracy: 0.9831\n",
      "Epoch 00088: val_accuracy did not improve from 0.27241\n",
      "163/163 [==============================] - 56s 342ms/step - loss: 0.5069 - accuracy: 0.9831 - val_loss: 5.1365 - val_accuracy: 0.2251 - lr: 1.0000e-05\n",
      "Epoch 89/120\n",
      "154/163 [===========================>..] - ETA: 2s - loss: 0.5243 - accuracy: 0.9765"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-eb00b2561659>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m#     tf.keras.utils.plot_model(model, to_file='/media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/olsson/CNN20X10/Model1.png',show_shapes=True,show_layer_names=True,dpi=96)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mcsv_logger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCSVLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/LSTM_nina_20X100.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcsv_logger\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlrate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mbest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch_number'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "    file_path_train=path+'S'+str(i)+'_'+'tr'+'.'+'csv'\n",
    "    print(file_path_train)\n",
    "    df_Train=read_data_Train(file_path_train)\n",
    "    show_basic_dataframe_info(df_Train)\n",
    "    df_Train.head(5)\n",
    "    file_path_test=path+'S'+str(i)+'_'+'tt'+'.'+'csv'\n",
    "    print(file_path_test)\n",
    "    df_Test=read_data_Test(file_path_test)\n",
    "    show_basic_dataframe_info(df_Test)\n",
    "    df_Test.head(5)\n",
    "#     feature standardization\n",
    "    scaler = preprocessing.StandardScaler().fit(df_Train.iloc[:,0:N_FEATURES])\n",
    "    df_Train.iloc[:,0:N_FEATURES]=scaler.transform(df_Train.iloc[:,0:N_FEATURES])\n",
    "    df_Test.iloc[:,0:N_FEATURES]=scaler.transform(df_Test.iloc[:,0:N_FEATURES])\n",
    "    \n",
    "    LABEL = 'ActivityEncoded'\n",
    "    # Transform the labels from String to Integer via LabelEncoder\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    # Add a new column to the existing DataFrame with the encoded values\n",
    "    df_Train[LABEL] = le.fit_transform(df_Train['Class_label'].values.ravel())\n",
    "    # df_Valid[LABEL] = le.fit_transform(df_Valid['Class_label'].values.ravel())\n",
    "    df_Test[LABEL] = le.fit_transform(df_Test['Class_label'].values.ravel())\n",
    "    x_train, y_train = create_segments_and_labels(df_Train,TIME_PERIODS,STEP_DISTANCE,N_FEATURES,LABEL)\n",
    "    print('x_train shape: ', x_train.shape)\n",
    "    # print(x_train)\n",
    "    print(x_train.shape[0], 'training samples')\n",
    "    print('y_train shape: ', y_train.shape)\n",
    "    # Set input & output dimensions\n",
    "    num_time_periods, num_sensors = x_train.shape[1], x_train.shape[2]\n",
    "    print('num_time_periods',num_time_periods)\n",
    "    print('num_sensors',num_sensors)\n",
    "    num_classes = le.classes_.size\n",
    "    print('class_list',list(le.classes_))\n",
    "    # input_shape = (num_time_periods,num_sensors)\n",
    "    # print(input_shape)\n",
    "    input_shape = (num_time_periods,num_sensors)\n",
    "    #x_train = x_train.reshape(x_train.shape[0], input_shape)\n",
    "    print('x_train shape:', x_train[0].shape)\n",
    "    print('input_shape:', input_shape)\n",
    "    x_train = x_train.astype('float32')\n",
    "    # x_train = [torch.tensor(arr, dtype=torch.float32) for arr in x_train]\n",
    "    # y_train = y_train.astype('float32')\n",
    "    # print(y_train)\n",
    "    y_train_hot = np_utils.to_categorical(y_train, num_classes)\n",
    "    print(y_train_hot)\n",
    "    # y_train_hot= [torch.tensor(arr, dtype=torch.uint8) for arr in y_train_hot]\n",
    "    print('New y_train shape: ', y_train_hot.shape)\n",
    "    x_test, y_test = create_segments_and_labels(df_Test,TIME_PERIODS,STEP_DISTANCE,N_FEATURES,LABEL)\n",
    "    print('x_test shape: ', x_test.shape)\n",
    "    # print(x_train)\n",
    "    print(x_test.shape[0], 'testing samples')\n",
    "    print('y_test shape: ', y_test.shape)\n",
    "    # Set input_shape / reshape for Keras\n",
    "    #x_test = x_test.reshape(x_test.shape[0], input_shape)\n",
    "    x_test = x_test.astype('float32')\n",
    "    y_test = y_test.astype('float32')\n",
    "    y_test_hot = np_utils.to_categorical(y_test, num_classes)\n",
    "    # n_steps, n_length = 20, 25\n",
    "    # n_steps, n_length= 10, 50\n",
    "    # n_steps, n_length= 16, 32\n",
    "    n_length =  400\n",
    "    n_depth=12\n",
    "    n_channel=12\n",
    "    x_train = x_train.reshape(x_train.shape[0], n_length,n_depth)\n",
    "    print('x_train shape: ', x_train.shape)\n",
    "    # x_valid = x_valid.reshape(x_valid.shape[0], n_steps, n_length, n_depth)\n",
    "    # print('x_valid shape: ', x_valid.shape)\n",
    "    x_test = x_test.reshape(x_test.shape[0],  n_length,n_depth)\n",
    "    print('x_test shape: ', x_test.shape)\n",
    "    n_outputs = y_train_hot.shape[1]\n",
    "    print('n_outputs',n_outputs)\n",
    "    adam=optimizers.Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "#     sgd=optimizers.SGD(learning_rate=0.1, momentum=0.9, nesterov=False, name='SGD')\n",
    "    checkpoint_filepath = '/media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5'\n",
    "#     model.load_weights(checkpoint_filepath) \n",
    "    checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath,verbose=1, monitor='val_accuracy',save_weights_only=True,save_best_only=True)\n",
    "    early = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
    "    model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "#     tf.keras.utils.plot_model(model, to_file='/media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/olsson/CNN20X10/Model1.png',show_shapes=True,show_layer_names=True,dpi=96)\n",
    "    csv_logger = CSVLogger('/media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/LSTM_nina_20X100.csv', append=True, separator=';')\n",
    "    history = model.fit(x_train, y_train_hot, epochs=epochs, batch_size=batch_size, callbacks=[csv_logger,checkpoint_callback,lrate,early],validation_data=(x_test, y_test_hot), verbose=1)\n",
    "    best_index = history.history['val_accuracy'].index(max(history.history['val_accuracy']))\n",
    "    print('epoch_number',best_index+1)\n",
    "    print('train accuracy and validation accuracy', history.history['accuracy'][best_index], history.history['val_accuracy'][best_index])\n",
    "    model.load_weights(checkpoint_filepath) \n",
    "    _, testaccuracy = model.evaluate(x_test, y_test_hot, batch_size=batch_size, verbose=1)\n",
    "    print('test_accuracy',testaccuracy)\n",
    "    test_acc.append(testaccuracy)\n",
    "    print(test_acc)\n",
    "    test_mean=statistics.mean(test_acc)\n",
    "    print('test_mean for %d subjects:',i)\n",
    "    print(test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.mean(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
