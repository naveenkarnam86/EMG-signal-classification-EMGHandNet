{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "# get_ipython().magic(u'matplotlib auto')\n",
    "import tensorflow as tf\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()\n",
    "# import torch\n",
    "from tensorflow import keras\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -q -U tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow_addons as tfa\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Activation\n",
    "from tensorflow import reshape\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv1D,Conv2D, MaxPooling1D,AveragePooling1D\n",
    "from tensorflow.keras.layers import SeparableConv1D, Bidirectional\n",
    "from tensorflow.keras.layers import LocallyConnected2D,LocallyConnected1D\n",
    "from tensorflow.keras.layers import ZeroPadding2D,ZeroPadding1D, MaxPooling2D, Bidirectional\n",
    "from tensorflow.keras.regularizers import l2,l1\n",
    "from tensorflow.keras.layers import BatchNormalization,Add,concatenate\n",
    "from tensorflow.keras.callbacks import CSVLogger,LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "# import coremltools\n",
    "# from torch import nn, optim\n",
    "# import torch.nn.functional as F\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "#from IPython.display import display, HTML\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURES = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'Class_label']\n"
     ]
    }
   ],
   "source": [
    "column_names = ['C'+str(j) for j in range(1, N_FEATURES+1)]\n",
    "lst = ['Class_label']\n",
    "column_names = column_names+lst\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_Train(file_path_Train):\n",
    "    df_Train = pd.read_csv(file_path_Train,header=None,names=column_names)\n",
    "    # Last column has a \";\" character which must be removed ...\n",
    "    df_Train['Class_label'].replace(regex=True,inplace=True,to_replace=r';',value=r'')\n",
    "    # ... and then this column must be transformed to float explicitly\n",
    "    df_Train['Class_label'] = df_Train['Class_label'].apply(convert_to_float)\n",
    "    # This is very important otherwise the model will not fit and loss\n",
    "    # will show up as NAN\n",
    "    df_Train.dropna(axis=0, how='any', inplace=True)\n",
    "    return df_Train\n",
    "def convert_to_float(x):\n",
    "    try:\n",
    "        return np.float(x)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_basic_dataframe_info(dataframe):\n",
    "    # Shape and how many rows and columns\n",
    "    print('Number of columns in the dataframe: %i' % (dataframe.shape[1]))\n",
    "    print('Number of rows in the dataframe: %i\\n' % (dataframe.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_Test(file_path_Test):\n",
    "    df_Test = pd.read_csv(file_path_Test,header=None,names=column_names)\n",
    "    # Last column has a \";\" character which must be removed ...\n",
    "    df_Test['Class_label'].replace(regex=True,inplace=True,to_replace=r';',value=r'')\n",
    "    # ... and then this column must be transformed to float explicitly\n",
    "    df_Test['Class_label'] = df_Test['Class_label'].apply(convert_to_float)\n",
    "    # This is very important otherwise the model will not fit and loss\n",
    "    # will show up as NAN\n",
    "    df_Test.dropna(axis=0, how='any', inplace=True)\n",
    "    return df_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " pd.options.display.float_format = \"{:,.5f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 function to segment data into trial lengths (trial length =513 samples in this dataset)\n",
    "def create_segments_and_labels(df, time_steps,step,n_features, label_name):\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - time_steps, step):\n",
    "      for j in range(1, n_features+1):\n",
    "        L = ('C'+str(j)) \n",
    "        segments.append(df[str(L)].values[i: i + time_steps])\n",
    "      label = stats.mode(df[label_name][i: i + time_steps])[0][0]\n",
    "      labels.append(label)\n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, time_steps, n_features)\n",
    "    labels = np.asarray(labels)\n",
    "    return reshaped_segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "path='/media/naveen/nav/mat_codes/nina_DB4_codes/naveen_prep_nlw/Total_process_TT/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  for i in range(num_res_net_blocks_64):\n",
    "#     x = res_net_block_64(x, 64, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/naveen/nav/mat_codes/nina_DB4_codes/naveen_prep_nlw/Total_process_TT/nina_naveen_nlw_DB4_Train.csv\n"
     ]
    }
   ],
   "source": [
    "# file_path_train=path+'Train_data'+'.'+'csv'\n",
    "file_path_train=path+'nina_naveen_nlw_DB4_Train'+'.'+'csv'\n",
    "print(file_path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/naveen/nav/mat_codes/nina_DB4_codes/naveen_prep_nlw/Total_process_TT/nina_naveen_nlw_DB4_Test.csv\n"
     ]
    }
   ],
   "source": [
    "file_path_test=path+'nina_naveen_nlw_DB4_Test'+'.'+'csv'\n",
    "# file_path_test=path+'Test_data'+'.'+'csv'\n",
    "print(file_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in the dataframe: 13\n",
      "Number of rows in the dataframe: 20800000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12</th>\n",
       "      <th>Class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>64</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>111</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>118</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>126</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>127</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>127</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C1  C2  C3  C4  C5  C6  C7  C8  C9  C10  C11  C12  Class_label\n",
       "0  14   8  16  12  27  64  33  15   1    3   33  111      1.00000\n",
       "1  21  10  15  10  28  34  27  14   1    4   12  118      1.00000\n",
       "2  29   9  14   8  29   5  21  15   1    3   10  126      1.00000\n",
       "3  43   1  14   6  29   7  15  20   1    4   28  127      1.00000\n",
       "4  51  11  14   4  28  13   9  27   2    4   40  127      1.00000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train=read_data_Train(file_path_train)\n",
    "show_basic_dataframe_info(df_Train)\n",
    "df_Train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in the dataframe: 13\n",
      "Number of rows in the dataframe: 10400000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12</th>\n",
       "      <th>Class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>99</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>71</td>\n",
       "      <td>58</td>\n",
       "      <td>102</td>\n",
       "      <td>22</td>\n",
       "      <td>91</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>75</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>71</td>\n",
       "      <td>58</td>\n",
       "      <td>104</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>48</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>72</td>\n",
       "      <td>54</td>\n",
       "      <td>105</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>48</td>\n",
       "      <td>78</td>\n",
       "      <td>32</td>\n",
       "      <td>47</td>\n",
       "      <td>107</td>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>76</td>\n",
       "      <td>29</td>\n",
       "      <td>98</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    C1  C2  C3  C4  C5  C6  C7  C8  C9  C10  C11  C12  Class_label\n",
       "0  107  14  12   7  99  19   5  71  58  102   22   91      1.00000\n",
       "1  106  16  10   8  75  12  16  71  58  104   20   41      1.00000\n",
       "2  102  18   9   7  48  40  40  72  54  105   16   24      1.00000\n",
       "3   93  18   7   5  54  48  78  32  47  107    9   64      1.00000\n",
       "4   79  19   6   3  76  29  98   4  37  107    2   83      1.00000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test=read_data_Test(file_path_test)\n",
    "show_basic_dataframe_info(df_Test)\n",
    "df_Test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12</th>\n",
       "      <th>Class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>64</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>111</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>118</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>126</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>127</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>127</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C1  C2  C3  C4  C5  C6  C7  C8  C9  C10  C11  C12  Class_label\n",
       "0  14   8  16  12  27  64  33  15   1    3   33  111      1.00000\n",
       "1  21  10  15  10  28  34  27  14   1    4   12  118      1.00000\n",
       "2  29   9  14   8  29   5  21  15   1    3   10  126      1.00000\n",
       "3  43   1  14   6  29   7  15  20   1    4   28  127      1.00000\n",
       "4  51  11  14   4  28  13   9  27   2    4   40  127      1.00000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = \"{:,.5f}\".format\n",
    "df_Train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(df_Train.iloc[:,0:N_FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train.iloc[:,0:N_FEATURES]=scaler.transform(df_Train.iloc[:,0:N_FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12</th>\n",
       "      <th>Class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.37008</td>\n",
       "      <td>-1.47208</td>\n",
       "      <td>-1.06140</td>\n",
       "      <td>-0.92977</td>\n",
       "      <td>-0.53847</td>\n",
       "      <td>0.45083</td>\n",
       "      <td>-0.40544</td>\n",
       "      <td>-1.11646</td>\n",
       "      <td>-1.23680</td>\n",
       "      <td>-1.61419</td>\n",
       "      <td>-0.36486</td>\n",
       "      <td>1.78064</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.18840</td>\n",
       "      <td>-1.42226</td>\n",
       "      <td>-1.08680</td>\n",
       "      <td>-0.98586</td>\n",
       "      <td>-0.51239</td>\n",
       "      <td>-0.32841</td>\n",
       "      <td>-0.56317</td>\n",
       "      <td>-1.14266</td>\n",
       "      <td>-1.23680</td>\n",
       "      <td>-1.58923</td>\n",
       "      <td>-0.88006</td>\n",
       "      <td>1.97403</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.98077</td>\n",
       "      <td>-1.44717</td>\n",
       "      <td>-1.11220</td>\n",
       "      <td>-1.04195</td>\n",
       "      <td>-0.48631</td>\n",
       "      <td>-1.08167</td>\n",
       "      <td>-0.72090</td>\n",
       "      <td>-1.11646</td>\n",
       "      <td>-1.23680</td>\n",
       "      <td>-1.61419</td>\n",
       "      <td>-0.92913</td>\n",
       "      <td>2.19505</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.61741</td>\n",
       "      <td>-1.64644</td>\n",
       "      <td>-1.11220</td>\n",
       "      <td>-1.09804</td>\n",
       "      <td>-0.48631</td>\n",
       "      <td>-1.02972</td>\n",
       "      <td>-0.87862</td>\n",
       "      <td>-0.98544</td>\n",
       "      <td>-1.23680</td>\n",
       "      <td>-1.58923</td>\n",
       "      <td>-0.48753</td>\n",
       "      <td>2.22268</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.40977</td>\n",
       "      <td>-1.39736</td>\n",
       "      <td>-1.11220</td>\n",
       "      <td>-1.15413</td>\n",
       "      <td>-0.51239</td>\n",
       "      <td>-0.87387</td>\n",
       "      <td>-1.03635</td>\n",
       "      <td>-0.80201</td>\n",
       "      <td>-1.21095</td>\n",
       "      <td>-1.58923</td>\n",
       "      <td>-0.19313</td>\n",
       "      <td>2.22268</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C1       C2       C3       C4       C5       C6       C7       C8  \\\n",
       "0 -1.37008 -1.47208 -1.06140 -0.92977 -0.53847  0.45083 -0.40544 -1.11646   \n",
       "1 -1.18840 -1.42226 -1.08680 -0.98586 -0.51239 -0.32841 -0.56317 -1.14266   \n",
       "2 -0.98077 -1.44717 -1.11220 -1.04195 -0.48631 -1.08167 -0.72090 -1.11646   \n",
       "3 -0.61741 -1.64644 -1.11220 -1.09804 -0.48631 -1.02972 -0.87862 -0.98544   \n",
       "4 -0.40977 -1.39736 -1.11220 -1.15413 -0.51239 -0.87387 -1.03635 -0.80201   \n",
       "\n",
       "        C9      C10      C11     C12  Class_label  \n",
       "0 -1.23680 -1.61419 -0.36486 1.78064      1.00000  \n",
       "1 -1.23680 -1.58923 -0.88006 1.97403      1.00000  \n",
       "2 -1.23680 -1.61419 -0.92913 2.19505      1.00000  \n",
       "3 -1.23680 -1.58923 -0.48753 2.22268      1.00000  \n",
       "4 -1.21095 -1.58923 -0.19313 2.22268      1.00000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = \"{:,.5f}\".format\n",
    "df_Train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12</th>\n",
       "      <th>Class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>99</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>71</td>\n",
       "      <td>58</td>\n",
       "      <td>102</td>\n",
       "      <td>22</td>\n",
       "      <td>91</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>75</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>71</td>\n",
       "      <td>58</td>\n",
       "      <td>104</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>48</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>72</td>\n",
       "      <td>54</td>\n",
       "      <td>105</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>48</td>\n",
       "      <td>78</td>\n",
       "      <td>32</td>\n",
       "      <td>47</td>\n",
       "      <td>107</td>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>76</td>\n",
       "      <td>29</td>\n",
       "      <td>98</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    C1  C2  C3  C4  C5  C6  C7  C8  C9  C10  C11  C12  Class_label\n",
       "0  107  14  12   7  99  19   5  71  58  102   22   91      1.00000\n",
       "1  106  16  10   8  75  12  16  71  58  104   20   41      1.00000\n",
       "2  102  18   9   7  48  40  40  72  54  105   16   24      1.00000\n",
       "3   93  18   7   5  54  48  78  32  47  107    9   64      1.00000\n",
       "4   79  19   6   3  76  29  98   4  37  107    2   83      1.00000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = \"{:,.5f}\".format\n",
    "df_Test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Test.iloc[:,0:N_FEATURES]=scaler.transform(df_Test.iloc[:,0:N_FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12</th>\n",
       "      <th>Class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.04367</td>\n",
       "      <td>-1.32263</td>\n",
       "      <td>-1.16300</td>\n",
       "      <td>-1.07000</td>\n",
       "      <td>1.33949</td>\n",
       "      <td>-0.71802</td>\n",
       "      <td>-1.14150</td>\n",
       "      <td>0.35096</td>\n",
       "      <td>0.23657</td>\n",
       "      <td>0.85680</td>\n",
       "      <td>-0.63473</td>\n",
       "      <td>1.22808</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.01772</td>\n",
       "      <td>-1.27281</td>\n",
       "      <td>-1.21380</td>\n",
       "      <td>-1.04195</td>\n",
       "      <td>0.71350</td>\n",
       "      <td>-0.89984</td>\n",
       "      <td>-0.85233</td>\n",
       "      <td>0.35096</td>\n",
       "      <td>0.23657</td>\n",
       "      <td>0.90672</td>\n",
       "      <td>-0.68379</td>\n",
       "      <td>-0.15332</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.91390</td>\n",
       "      <td>-1.22300</td>\n",
       "      <td>-1.23920</td>\n",
       "      <td>-1.07000</td>\n",
       "      <td>0.00927</td>\n",
       "      <td>-0.17256</td>\n",
       "      <td>-0.22143</td>\n",
       "      <td>0.37717</td>\n",
       "      <td>0.13318</td>\n",
       "      <td>0.93168</td>\n",
       "      <td>-0.78193</td>\n",
       "      <td>-0.62299</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.68031</td>\n",
       "      <td>-1.22300</td>\n",
       "      <td>-1.29000</td>\n",
       "      <td>-1.12609</td>\n",
       "      <td>0.16576</td>\n",
       "      <td>0.03524</td>\n",
       "      <td>0.77750</td>\n",
       "      <td>-0.67099</td>\n",
       "      <td>-0.04776</td>\n",
       "      <td>0.98160</td>\n",
       "      <td>-0.95366</td>\n",
       "      <td>0.48212</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31695</td>\n",
       "      <td>-1.19809</td>\n",
       "      <td>-1.31540</td>\n",
       "      <td>-1.18218</td>\n",
       "      <td>0.73958</td>\n",
       "      <td>-0.45828</td>\n",
       "      <td>1.30325</td>\n",
       "      <td>-1.40470</td>\n",
       "      <td>-0.30625</td>\n",
       "      <td>0.98160</td>\n",
       "      <td>-1.12539</td>\n",
       "      <td>1.00705</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C1       C2       C3       C4      C5       C6       C7       C8  \\\n",
       "0 1.04367 -1.32263 -1.16300 -1.07000 1.33949 -0.71802 -1.14150  0.35096   \n",
       "1 1.01772 -1.27281 -1.21380 -1.04195 0.71350 -0.89984 -0.85233  0.35096   \n",
       "2 0.91390 -1.22300 -1.23920 -1.07000 0.00927 -0.17256 -0.22143  0.37717   \n",
       "3 0.68031 -1.22300 -1.29000 -1.12609 0.16576  0.03524  0.77750 -0.67099   \n",
       "4 0.31695 -1.19809 -1.31540 -1.18218 0.73958 -0.45828  1.30325 -1.40470   \n",
       "\n",
       "        C9     C10      C11      C12  Class_label  \n",
       "0  0.23657 0.85680 -0.63473  1.22808      1.00000  \n",
       "1  0.23657 0.90672 -0.68379 -0.15332      1.00000  \n",
       "2  0.13318 0.93168 -0.78193 -0.62299      1.00000  \n",
       "3 -0.04776 0.98160 -0.95366  0.48212      1.00000  \n",
       "4 -0.30625 0.98160 -1.12539  1.00705      1.00000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = \"{:,.5f}\".format\n",
    "df_Test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = 'ActivityEncoded'\n",
    "# Transform the labels from String to Integer via LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "# Add a new column to the existing DataFrame with the encoded values\n",
    "df_Train[LABEL] = le.fit_transform(df_Train['Class_label'].values.ravel())\n",
    "# df_Valid[LABEL] = le.fit_transform(df_Valid['Class_label'].values.ravel())\n",
    "df_Test[LABEL] = le.fit_transform(df_Test['Class_label'].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of steps within one time segment\n",
    "TIME_PERIODS = 400\n",
    "# The steps to take from one segment to the next; if this value is equal to\n",
    "# TIME_PERIODS, then there is no overlap between the segments\n",
    "STEP_DISTANCE = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (51999, 400, 12)\n",
      "51999 training samples\n",
      "y_train shape:  (51999,)\n",
      "num_time_periods 400\n",
      "num_sensors 12\n",
      "class_list [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0]\n",
      "x_train shape: (400, 12)\n",
      "input_shape: (400, 12)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "New y_train shape:  (51999, 52)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = create_segments_and_labels(df_Train,TIME_PERIODS,STEP_DISTANCE,N_FEATURES,LABEL)\n",
    "print('x_train shape: ', x_train.shape)\n",
    "# print(x_train)\n",
    "print(x_train.shape[0], 'training samples')\n",
    "print('y_train shape: ', y_train.shape)\n",
    "# Set input & output dimensions\n",
    "num_time_periods, num_sensors = x_train.shape[1], x_train.shape[2]\n",
    "print('num_time_periods',num_time_periods)\n",
    "print('num_sensors',num_sensors)\n",
    "num_classes = le.classes_.size\n",
    "print('class_list',list(le.classes_))\n",
    "# input_shape = (num_time_periods,num_sensors)\n",
    "# print(input_shape)\n",
    "input_shape = (num_time_periods,num_sensors)\n",
    "#x_train = x_train.reshape(x_train.shape[0], input_shape)\n",
    "print('x_train shape:', x_train[0].shape)\n",
    "print('input_shape:', input_shape)\n",
    "x_train = x_train.astype('float32')\n",
    "# x_train = [torch.tensor(arr, dtype=torch.float32) for arr in x_train]\n",
    "# y_train = y_train.astype('float32')\n",
    "# print(y_train)\n",
    "y_train_hot = np_utils.to_categorical(y_train, num_classes)\n",
    "print(y_train_hot)\n",
    "# y_train_hot= [torch.tensor(arr, dtype=torch.uint8) for arr in y_train_hot]\n",
    "print('New y_train shape: ', y_train_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test shape:  (25999, 400, 12)\n",
      "25999 testing samples\n",
      "y_test shape:  (25999,)\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = create_segments_and_labels(df_Test,TIME_PERIODS,STEP_DISTANCE,N_FEATURES,LABEL)\n",
    "print('x_test shape: ', x_test.shape)\n",
    "# print(x_train)\n",
    "print(x_test.shape[0], 'testing samples')\n",
    "print('y_test shape: ', y_test.shape)\n",
    "# Set input_shape / reshape for Keras\n",
    "#x_test = x_test.reshape(x_test.shape[0], input_shape)\n",
    "x_test = x_test.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "y_test_hot = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (51999, 400, 12)\n",
      "x_test shape:  (25999, 400, 12)\n",
      "n_outputs 52\n"
     ]
    }
   ],
   "source": [
    "# n_steps, n_length = 20, 25\n",
    "# n_steps, n_length= 10, 50\n",
    "# n_steps, n_length= 16, 32\n",
    "n_length =  400\n",
    "n_depth=12\n",
    "n_channel=12\n",
    "x_train = x_train.reshape(x_train.shape[0], n_length,n_depth)\n",
    "print('x_train shape: ', x_train.shape)\n",
    "# x_valid = x_valid.reshape(x_valid.shape[0], n_steps, n_length, n_depth)\n",
    "# print('x_valid shape: ', x_valid.shape)\n",
    "x_test = x_test.reshape(x_test.shape[0],  n_length,n_depth)\n",
    "print('x_test shape: ', x_test.shape)\n",
    "n_outputs = y_train_hot.shape[1]\n",
    "print('n_outputs',n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_data,n_channel):\n",
    "    inputs=input_data\n",
    "    print(inputs.shape)\n",
    "    l_y=[]\n",
    "    for i in range(0,n_channel):\n",
    "        ip=inputs[:,:,i]\n",
    "        print('ip_shape',ip.shape)\n",
    "#         ip1=tf.convert_to_tensor(ip, dtype=tf.float32)\n",
    "        ip=tf.reshape(ip,(tf.shape(ip)[0],400,1))\n",
    "        print('ip_shape',ip.shape)\n",
    "        x = Conv1D(64, kernel_size=3,kernel_initializer=\"he_normal\",kernel_regularizer=l1(1e-04), \\\n",
    "               padding='same',input_shape=ip.shape)(ip)\n",
    "        print('conv1_o',x.shape)\n",
    "        x = BatchNormalization(epsilon=1e-06, momentum=0.9, weights=None)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x= Conv1D(filters=64, kernel_size=3,padding=\"same\", kernel_regularizer=l2(5e-04),kernel_initializer=\"he_normal\",strides=1)(x)\n",
    "        x= BatchNormalization(epsilon=1e-06, momentum=0.9, weights=None)(x)\n",
    "        x= Activation('relu')(x)\n",
    "        x= LocallyConnected1D(64, kernel_size=1, kernel_regularizer=l2(5e-04),kernel_initializer=\"he_normal\",strides=1,padding='valid')(x)\n",
    "        x= BatchNormalization(epsilon=1e-06, momentum=0.9, weights=None)(x)\n",
    "        x= Activation('relu')(x)\n",
    "        x= LocallyConnected1D(64, kernel_size=1, kernel_regularizer=l2(5e-04),kernel_initializer=\"he_normal\",strides=1,padding='valid')(x)\n",
    "        x= BatchNormalization(epsilon=1e-06, momentum=0.9, weights=None)(x)\n",
    "        x= Activation('relu')(x)\n",
    "        y= Dropout(0.5)(x)\n",
    "        l_y.append(y)\n",
    "    y_stack=tf.stack(l_y, axis=2)   \n",
    "    return y_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model():\n",
    "    inputs = Input(shape=(n_length,n_depth),name=\"main\")\n",
    "    p=conv_block(inputs,12)\n",
    "    print(p.shape)\n",
    "    print(type(p))\n",
    "#     print(y.shape)\n",
    "    y=Flatten()(p)\n",
    "    print(y.shape)\n",
    "    y= Dense(512, kernel_initializer=\"he_normal\")(y)\n",
    "    y= BatchNormalization(epsilon=1e-06, momentum=0.9, weights=None)(y)\n",
    "    y= Activation('relu')(y)\n",
    "    y= Dropout(0.5)(y)\n",
    "    y= Dense(512, kernel_initializer=\"he_normal\")(y)\n",
    "    y= BatchNormalization(epsilon=1e-06, momentum=0.9, weights=None)(y)\n",
    "    y= Activation('relu')(y)\n",
    "    y= Dropout(0.5)(y)\n",
    "    y= Dense(128, kernel_initializer=\"he_normal\")(y)\n",
    "    y= BatchNormalization(epsilon=1e-06, momentum=0.9, weights=None)(y)\n",
    "    y= Activation('relu')(y)\n",
    "    outputs=Dense(n_outputs, activation='softmax')(y)\n",
    "    print(outputs.shape)\n",
    "#     wei_mscnn_model = Model(inputs,sub_inputs], outputs)\n",
    "    print('inputs_shape',inputs.shape)\n",
    "    final_model = Model(inputs,outputs,name=\"wei_mscnn_model\")\n",
    "    return final_model        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 400, 12)\n",
      "ip_shape (None, 400)\n",
      "ip_shape (None, 400, 1)\n",
      "conv1_o (None, 400, 64)\n",
      "ip_shape (None, 400)\n",
      "ip_shape (None, 400, 1)\n",
      "conv1_o (None, 400, 64)\n",
      "ip_shape (None, 400)\n",
      "ip_shape (None, 400, 1)\n",
      "conv1_o (None, 400, 64)\n",
      "ip_shape (None, 400)\n",
      "ip_shape (None, 400, 1)\n",
      "conv1_o (None, 400, 64)\n",
      "ip_shape (None, 400)\n",
      "ip_shape (None, 400, 1)\n",
      "conv1_o (None, 400, 64)\n",
      "ip_shape (None, 400)\n",
      "ip_shape (None, 400, 1)\n",
      "conv1_o (None, 400, 64)\n",
      "ip_shape (None, 400)\n",
      "ip_shape (None, 400, 1)\n",
      "conv1_o (None, 400, 64)\n",
      "ip_shape (None, 400)\n",
      "ip_shape (None, 400, 1)\n",
      "conv1_o (None, 400, 64)\n",
      "ip_shape (None, 400)\n",
      "ip_shape (None, 400, 1)\n",
      "conv1_o (None, 400, 64)\n",
      "ip_shape (None, 400)\n",
      "ip_shape (None, 400, 1)\n",
      "conv1_o (None, 400, 64)\n",
      "ip_shape (None, 400)\n",
      "ip_shape (None, 400, 1)\n",
      "conv1_o (None, 400, 64)\n",
      "ip_shape (None, 400)\n",
      "ip_shape (None, 400, 1)\n",
      "conv1_o (None, 400, 64)\n",
      "(None, 400, 12, 64)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(None, 307200)\n",
      "(None, 52)\n",
      "inputs_shape (None, 400, 12)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = generate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose, epochs, batch_size = 0, 100, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "   initial_lrate = 1e-3\n",
    "   drop = 0.1\n",
    "   epochs_drop = 30.0\n",
    "   lrate = initial_lrate * tf.math.pow(drop,  \n",
    "           tf.math.floor((1+epoch)/epochs_drop))\n",
    "   return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrate = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
    "test_acc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"wei_mscnn_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main (InputLayer)               [(None, 400, 12)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_8 (Te [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_10 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_12 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_14 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_16 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_18 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_20 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_22 (T [(None, 400)]        0           main[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_1 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_2 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_3 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_4 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_5 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_10[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_6 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_12[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_7 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_14[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_8 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_16[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_9 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_18[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_10 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_20[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_11 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_22[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [()]                 0           tf_op_layer_Shape_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_5 (Te [()]                 0           tf_op_layer_Shape_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_7 (Te [()]                 0           tf_op_layer_Shape_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_9 (Te [()]                 0           tf_op_layer_Shape_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_11 (T [()]                 0           tf_op_layer_Shape_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_13 (T [()]                 0           tf_op_layer_Shape_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_15 (T [()]                 0           tf_op_layer_Shape_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_17 (T [()]                 0           tf_op_layer_Shape_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_19 (T [()]                 0           tf_op_layer_Shape_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_21 (T [()]                 0           tf_op_layer_Shape_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_23 (T [()]                 0           tf_op_layer_Shape_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape/shape (Tens [(3,)]               0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1/shape (Te [(3,)]               0           tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2/shape (Te [(3,)]               0           tf_op_layer_strided_slice_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3/shape (Te [(3,)]               0           tf_op_layer_strided_slice_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4/shape (Te [(3,)]               0           tf_op_layer_strided_slice_9[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5/shape (Te [(3,)]               0           tf_op_layer_strided_slice_11[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6/shape (Te [(3,)]               0           tf_op_layer_strided_slice_13[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7/shape (Te [(3,)]               0           tf_op_layer_strided_slice_15[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8/shape (Te [(3,)]               0           tf_op_layer_strided_slice_17[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9/shape (Te [(3,)]               0           tf_op_layer_strided_slice_19[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_10/shape (T [(3,)]               0           tf_op_layer_strided_slice_21[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_11/shape (T [(3,)]               0           tf_op_layer_strided_slice_23[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 400, 1)]     0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 tf_op_layer_Reshape/shape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_2[0][0]\n",
      "                                                                 tf_op_layer_Reshape_1/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_4[0][0]\n",
      "                                                                 tf_op_layer_Reshape_2/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_6[0][0]\n",
      "                                                                 tf_op_layer_Reshape_3/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_8[0][0]\n",
      "                                                                 tf_op_layer_Reshape_4/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_10[0][0\n",
      "                                                                 tf_op_layer_Reshape_5/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_12[0][0\n",
      "                                                                 tf_op_layer_Reshape_6/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_14[0][0\n",
      "                                                                 tf_op_layer_Reshape_7/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_16[0][0\n",
      "                                                                 tf_op_layer_Reshape_8/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9 (TensorFl [(None, 400, 1)]     0           tf_op_layer_strided_slice_18[0][0\n",
      "                                                                 tf_op_layer_Reshape_9/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_10 (TensorF [(None, 400, 1)]     0           tf_op_layer_strided_slice_20[0][0\n",
      "                                                                 tf_op_layer_Reshape_10/shape[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_11 (TensorF [(None, 400, 1)]     0           tf_op_layer_strided_slice_22[0][0\n",
      "                                                                 tf_op_layer_Reshape_11/shape[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 400, 64)      256         tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 400, 64)      256         tf_op_layer_Reshape_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 400, 64)      256         tf_op_layer_Reshape_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 400, 64)      256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 400, 64)      256         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 400, 64)      256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 400, 64)      256         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 400, 64)      256         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 400, 64)      256         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 400, 64)      256         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 400, 64)      256         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 400, 64)      256         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 400, 64)      256         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 400, 64)      256         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 400, 64)      256         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 400, 64)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 400, 64)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 400, 64)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 400, 64)      0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 400, 64)      0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 400, 64)      0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 400, 64)      0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 400, 64)      0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 400, 64)      0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 400, 64)      0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 400, 64)      0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 400, 64)      0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 400, 64)      12352       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 400, 64)      12352       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 400, 64)      12352       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 400, 64)      12352       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 400, 64)      12352       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 400, 64)      12352       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 400, 64)      12352       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 400, 64)      12352       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 400, 64)      12352       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 400, 64)      12352       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 400, 64)      12352       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 400, 64)      12352       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 400, 64)      256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 400, 64)      256         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 400, 64)      256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 400, 64)      256         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 400, 64)      256         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 400, 64)      256         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 400, 64)      256         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 400, 64)      256         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 400, 64)      256         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 400, 64)      256         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 400, 64)      256         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 400, 64)      256         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 400, 64)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 400, 64)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 400, 64)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 400, 64)      0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 400, 64)      0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 400, 64)      0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 400, 64)      0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 400, 64)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 400, 64)      0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 400, 64)      0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 400, 64)      0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 400, 64)      0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d (LocallyCon (None, 400, 64)      1664000     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_2 (LocallyC (None, 400, 64)      1664000     activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_4 (LocallyC (None, 400, 64)      1664000     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_6 (LocallyC (None, 400, 64)      1664000     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_8 (LocallyC (None, 400, 64)      1664000     activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_10 (Locally (None, 400, 64)      1664000     activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_12 (Locally (None, 400, 64)      1664000     activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_14 (Locally (None, 400, 64)      1664000     activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_16 (Locally (None, 400, 64)      1664000     activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_18 (Locally (None, 400, 64)      1664000     activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_20 (Locally (None, 400, 64)      1664000     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_22 (Locally (None, 400, 64)      1664000     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 400, 64)      256         locally_connected1d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 400, 64)      256         locally_connected1d_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 400, 64)      256         locally_connected1d_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 400, 64)      256         locally_connected1d_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 400, 64)      256         locally_connected1d_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 400, 64)      256         locally_connected1d_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 400, 64)      256         locally_connected1d_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 400, 64)      256         locally_connected1d_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 400, 64)      256         locally_connected1d_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 400, 64)      256         locally_connected1d_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 400, 64)      256         locally_connected1d_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 400, 64)      256         locally_connected1d_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 400, 64)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 400, 64)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 400, 64)      0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 400, 64)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 400, 64)      0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 400, 64)      0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 400, 64)      0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 400, 64)      0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 400, 64)      0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 400, 64)      0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 400, 64)      0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 400, 64)      0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_1 (LocallyC (None, 400, 64)      1664000     activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_3 (LocallyC (None, 400, 64)      1664000     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_5 (LocallyC (None, 400, 64)      1664000     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_7 (LocallyC (None, 400, 64)      1664000     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_9 (LocallyC (None, 400, 64)      1664000     activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_11 (Locally (None, 400, 64)      1664000     activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_13 (Locally (None, 400, 64)      1664000     activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_15 (Locally (None, 400, 64)      1664000     activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_17 (Locally (None, 400, 64)      1664000     activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_19 (Locally (None, 400, 64)      1664000     activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_21 (Locally (None, 400, 64)      1664000     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_23 (Locally (None, 400, 64)      1664000     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 400, 64)      256         locally_connected1d_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 400, 64)      256         locally_connected1d_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 400, 64)      256         locally_connected1d_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 400, 64)      256         locally_connected1d_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 400, 64)      256         locally_connected1d_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 400, 64)      256         locally_connected1d_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 400, 64)      256         locally_connected1d_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 400, 64)      256         locally_connected1d_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 400, 64)      256         locally_connected1d_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 400, 64)      256         locally_connected1d_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 400, 64)      256         locally_connected1d_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 400, 64)      256         locally_connected1d_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 400, 64)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 400, 64)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 400, 64)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 400, 64)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 400, 64)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 400, 64)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 400, 64)      0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 400, 64)      0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 400, 64)      0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 400, 64)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 400, 64)      0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 400, 64)      0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 400, 64)      0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 400, 64)      0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 400, 64)      0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 400, 64)      0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 400, 64)      0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 400, 64)      0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 400, 64)      0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 400, 64)      0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 400, 64)      0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 400, 64)      0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 400, 64)      0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 400, 64)      0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_stack (TensorFlowOp [(None, 400, 12, 64) 0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "                                                                 dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 307200)       0           tf_op_layer_stack[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          157286912   flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 512)          0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 512)          0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          262656      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 512)          0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 512)          0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          65664       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 128)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 128)          0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 52)           6708        activation_50[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 197,726,132\n",
      "Trainable params: 197,717,684\n",
      "Non-trainable params: 8,448\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "adam=optimizers.Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "# sgd=tfa.optimizers.SGDW(weight_decay=0.0001,learning_rate=0.1, momentum=0.9, nesterov=False, name='SGDW')\n",
    "sgd=tf.optimizers.SGD(learning_rate=1e-3, momentum=0.9, nesterov=False, name='SGD')\n",
    "checkpoint_filepath = '/media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5'\n",
    "# model.load_weights(checkpoint_filepath) \n",
    "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath,verbose=1, monitor='val_accuracy',save_weights_only=True,save_best_only=True)\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
    "model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "#     tf.keras.utils.plot_model(model, to_file='/media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/olsson/CNN20X10/Model1.png',show_shapes=True,show_layer_names=True,dpi=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 3.5750 - accuracy: 0.1196\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.14224, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 619s 381ms/step - loss: 3.5750 - accuracy: 0.1196 - val_loss: 3.4566 - val_accuracy: 0.1422 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 3.5279 - accuracy: 0.1331\n",
      "Epoch 00002: val_accuracy improved from 0.14224 to 0.16712, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 554s 341ms/step - loss: 3.5279 - accuracy: 0.1331 - val_loss: 3.3585 - val_accuracy: 0.1671 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 3.4655 - accuracy: 0.1455\n",
      "Epoch 00003: val_accuracy improved from 0.16712 to 0.17181, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 553s 340ms/step - loss: 3.4655 - accuracy: 0.1455 - val_loss: 3.3225 - val_accuracy: 0.1718 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 3.4038 - accuracy: 0.1545\n",
      "Epoch 00004: val_accuracy improved from 0.17181 to 0.18678, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 548s 337ms/step - loss: 3.4038 - accuracy: 0.1545 - val_loss: 3.2333 - val_accuracy: 0.1868 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 3.3581 - accuracy: 0.1643\n",
      "Epoch 00005: val_accuracy improved from 0.18678 to 0.19055, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 526s 323ms/step - loss: 3.3581 - accuracy: 0.1643 - val_loss: 3.1928 - val_accuracy: 0.1905 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 3.3082 - accuracy: 0.1730\n",
      "Epoch 00006: val_accuracy improved from 0.19055 to 0.20858, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 539s 331ms/step - loss: 3.3082 - accuracy: 0.1730 - val_loss: 3.1297 - val_accuracy: 0.2086 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 3.2590 - accuracy: 0.1779\n",
      "Epoch 00007: val_accuracy improved from 0.20858 to 0.21635, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 543s 334ms/step - loss: 3.2590 - accuracy: 0.1779 - val_loss: 3.0843 - val_accuracy: 0.2164 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 3.2157 - accuracy: 0.1849\n",
      "Epoch 00008: val_accuracy improved from 0.21635 to 0.23120, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 543s 334ms/step - loss: 3.2157 - accuracy: 0.1849 - val_loss: 3.0142 - val_accuracy: 0.2312 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 3.1796 - accuracy: 0.1905\n",
      "Epoch 00009: val_accuracy did not improve from 0.23120\n",
      "1625/1625 [==============================] - 537s 330ms/step - loss: 3.1796 - accuracy: 0.1905 - val_loss: 2.9940 - val_accuracy: 0.2297 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 3.1375 - accuracy: 0.1991\n",
      "Epoch 00010: val_accuracy improved from 0.23120 to 0.24132, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 543s 334ms/step - loss: 3.1375 - accuracy: 0.1991 - val_loss: 2.9403 - val_accuracy: 0.2413 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 3.1106 - accuracy: 0.2029\n",
      "Epoch 00011: val_accuracy improved from 0.24132 to 0.24339, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 543s 334ms/step - loss: 3.1106 - accuracy: 0.2029 - val_loss: 2.9253 - val_accuracy: 0.2434 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 3.0799 - accuracy: 0.2089\n",
      "Epoch 00012: val_accuracy improved from 0.24339 to 0.25201, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 544s 335ms/step - loss: 3.0799 - accuracy: 0.2089 - val_loss: 2.8954 - val_accuracy: 0.2520 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 3.0542 - accuracy: 0.2125\n",
      "Epoch 00013: val_accuracy improved from 0.25201 to 0.26363, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 543s 334ms/step - loss: 3.0542 - accuracy: 0.2125 - val_loss: 2.8525 - val_accuracy: 0.2636 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 3.0271 - accuracy: 0.2201\n",
      "Epoch 00014: val_accuracy did not improve from 0.26363\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 3.0271 - accuracy: 0.2201 - val_loss: 2.8611 - val_accuracy: 0.2547 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 3.0098 - accuracy: 0.2214\n",
      "Epoch 00015: val_accuracy improved from 0.26363 to 0.27293, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 544s 335ms/step - loss: 3.0098 - accuracy: 0.2214 - val_loss: 2.8099 - val_accuracy: 0.2729 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.9873 - accuracy: 0.2283\n",
      "Epoch 00016: val_accuracy did not improve from 0.27293\n",
      "1625/1625 [==============================] - 537s 330ms/step - loss: 2.9873 - accuracy: 0.2283 - val_loss: 2.7945 - val_accuracy: 0.2729 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.9731 - accuracy: 0.2278\n",
      "Epoch 00017: val_accuracy did not improve from 0.27293\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.9731 - accuracy: 0.2278 - val_loss: 2.7959 - val_accuracy: 0.2729 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.9487 - accuracy: 0.2353\n",
      "Epoch 00018: val_accuracy improved from 0.27293 to 0.28170, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 544s 335ms/step - loss: 2.9487 - accuracy: 0.2353 - val_loss: 2.7589 - val_accuracy: 0.2817 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.9247 - accuracy: 0.2394\n",
      "Epoch 00019: val_accuracy improved from 0.28170 to 0.28855, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 543s 334ms/step - loss: 2.9247 - accuracy: 0.2394 - val_loss: 2.7507 - val_accuracy: 0.2885 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.9146 - accuracy: 0.2421\n",
      "Epoch 00020: val_accuracy did not improve from 0.28855\n",
      "1625/1625 [==============================] - 537s 331ms/step - loss: 2.9146 - accuracy: 0.2421 - val_loss: 2.7346 - val_accuracy: 0.2847 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.9022 - accuracy: 0.2434\n",
      "Epoch 00021: val_accuracy improved from 0.28855 to 0.29451, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 542s 334ms/step - loss: 2.9022 - accuracy: 0.2434 - val_loss: 2.7167 - val_accuracy: 0.2945 - lr: 0.0010\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1625/1625 [==============================] - ETA: 0s - loss: 2.8855 - accuracy: 0.2471\n",
      "Epoch 00022: val_accuracy improved from 0.29451 to 0.29690, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 543s 334ms/step - loss: 2.8855 - accuracy: 0.2471 - val_loss: 2.7115 - val_accuracy: 0.2969 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.8709 - accuracy: 0.2504\n",
      "Epoch 00023: val_accuracy did not improve from 0.29690\n",
      "1625/1625 [==============================] - 537s 330ms/step - loss: 2.8709 - accuracy: 0.2504 - val_loss: 2.7098 - val_accuracy: 0.2924 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.8634 - accuracy: 0.2532\n",
      "Epoch 00024: val_accuracy improved from 0.29690 to 0.29851, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 542s 334ms/step - loss: 2.8634 - accuracy: 0.2532 - val_loss: 2.6765 - val_accuracy: 0.2985 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.8456 - accuracy: 0.2547\n",
      "Epoch 00025: val_accuracy did not improve from 0.29851\n",
      "1625/1625 [==============================] - 537s 330ms/step - loss: 2.8456 - accuracy: 0.2547 - val_loss: 2.6737 - val_accuracy: 0.2976 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.8327 - accuracy: 0.2586\n",
      "Epoch 00026: val_accuracy improved from 0.29851 to 0.30582, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 542s 334ms/step - loss: 2.8327 - accuracy: 0.2586 - val_loss: 2.6703 - val_accuracy: 0.3058 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.8235 - accuracy: 0.2598\n",
      "Epoch 00027: val_accuracy did not improve from 0.30582\n",
      "1625/1625 [==============================] - 537s 331ms/step - loss: 2.8235 - accuracy: 0.2598 - val_loss: 2.6643 - val_accuracy: 0.3016 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.8077 - accuracy: 0.2633\n",
      "Epoch 00028: val_accuracy did not improve from 0.30582\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.8077 - accuracy: 0.2633 - val_loss: 2.6521 - val_accuracy: 0.3046 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.8062 - accuracy: 0.2648\n",
      "Epoch 00029: val_accuracy improved from 0.30582 to 0.30801, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 543s 334ms/step - loss: 2.8062 - accuracy: 0.2648 - val_loss: 2.6397 - val_accuracy: 0.3080 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.7033 - accuracy: 0.2843\n",
      "Epoch 00030: val_accuracy improved from 0.30801 to 0.31870, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 542s 334ms/step - loss: 2.7033 - accuracy: 0.2843 - val_loss: 2.5758 - val_accuracy: 0.3187 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.6578 - accuracy: 0.2917\n",
      "Epoch 00031: val_accuracy improved from 0.31870 to 0.32286, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 544s 335ms/step - loss: 2.6578 - accuracy: 0.2917 - val_loss: 2.5421 - val_accuracy: 0.3229 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.6393 - accuracy: 0.2910\n",
      "Epoch 00032: val_accuracy improved from 0.32286 to 0.32594, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 543s 334ms/step - loss: 2.6393 - accuracy: 0.2910 - val_loss: 2.5226 - val_accuracy: 0.3259 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.6126 - accuracy: 0.2977\n",
      "Epoch 00033: val_accuracy improved from 0.32594 to 0.32651, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 544s 335ms/step - loss: 2.6126 - accuracy: 0.2977 - val_loss: 2.5113 - val_accuracy: 0.3265 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.6017 - accuracy: 0.2986\n",
      "Epoch 00034: val_accuracy improved from 0.32651 to 0.32832, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 543s 334ms/step - loss: 2.6017 - accuracy: 0.2986 - val_loss: 2.5023 - val_accuracy: 0.3283 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.5916 - accuracy: 0.2984\n",
      "Epoch 00035: val_accuracy did not improve from 0.32832\n",
      "1625/1625 [==============================] - 538s 331ms/step - loss: 2.5916 - accuracy: 0.2984 - val_loss: 2.4992 - val_accuracy: 0.3276 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.5809 - accuracy: 0.2990\n",
      "Epoch 00036: val_accuracy did not improve from 0.32832\n",
      "1625/1625 [==============================] - 537s 330ms/step - loss: 2.5809 - accuracy: 0.2990 - val_loss: 2.4901 - val_accuracy: 0.3282 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.5690 - accuracy: 0.3022\n",
      "Epoch 00037: val_accuracy improved from 0.32832 to 0.33005, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 543s 334ms/step - loss: 2.5690 - accuracy: 0.3022 - val_loss: 2.4830 - val_accuracy: 0.3301 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.5591 - accuracy: 0.3036\n",
      "Epoch 00038: val_accuracy improved from 0.33005 to 0.33024, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 542s 334ms/step - loss: 2.5591 - accuracy: 0.3036 - val_loss: 2.4787 - val_accuracy: 0.3302 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.5519 - accuracy: 0.3053\n",
      "Epoch 00039: val_accuracy improved from 0.33024 to 0.33074, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 543s 334ms/step - loss: 2.5519 - accuracy: 0.3053 - val_loss: 2.4688 - val_accuracy: 0.3307 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.5437 - accuracy: 0.3071\n",
      "Epoch 00040: val_accuracy improved from 0.33074 to 0.33274, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 543s 334ms/step - loss: 2.5437 - accuracy: 0.3071 - val_loss: 2.4617 - val_accuracy: 0.3327 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.5352 - accuracy: 0.3091\n",
      "Epoch 00041: val_accuracy did not improve from 0.33274\n",
      "1625/1625 [==============================] - 537s 330ms/step - loss: 2.5352 - accuracy: 0.3091 - val_loss: 2.4666 - val_accuracy: 0.3299 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.5324 - accuracy: 0.3072\n",
      "Epoch 00042: val_accuracy did not improve from 0.33274\n",
      "1625/1625 [==============================] - 538s 331ms/step - loss: 2.5324 - accuracy: 0.3072 - val_loss: 2.4595 - val_accuracy: 0.3314 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.5212 - accuracy: 0.3107\n",
      "Epoch 00043: val_accuracy improved from 0.33274 to 0.33278, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 541s 333ms/step - loss: 2.5212 - accuracy: 0.3107 - val_loss: 2.4615 - val_accuracy: 0.3328 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.5203 - accuracy: 0.3092\n",
      "Epoch 00044: val_accuracy did not improve from 0.33278\n",
      "1625/1625 [==============================] - 535s 329ms/step - loss: 2.5203 - accuracy: 0.3092 - val_loss: 2.4620 - val_accuracy: 0.3304 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.5073 - accuracy: 0.3132\n",
      "Epoch 00045: val_accuracy improved from 0.33278 to 0.33294, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 542s 334ms/step - loss: 2.5073 - accuracy: 0.3132 - val_loss: 2.4510 - val_accuracy: 0.3329 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4982 - accuracy: 0.3139\n",
      "Epoch 00046: val_accuracy improved from 0.33294 to 0.33351, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 543s 334ms/step - loss: 2.4982 - accuracy: 0.3139 - val_loss: 2.4480 - val_accuracy: 0.3335 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4945 - accuracy: 0.3157\n",
      "Epoch 00047: val_accuracy improved from 0.33351 to 0.33474, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 542s 333ms/step - loss: 2.4945 - accuracy: 0.3157 - val_loss: 2.4414 - val_accuracy: 0.3347 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4988 - accuracy: 0.3145\n",
      "Epoch 00048: val_accuracy did not improve from 0.33474\n",
      "1625/1625 [==============================] - 537s 330ms/step - loss: 2.4988 - accuracy: 0.3145 - val_loss: 2.4438 - val_accuracy: 0.3332 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4924 - accuracy: 0.3165\n",
      "Epoch 00049: val_accuracy improved from 0.33474 to 0.33559, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 543s 334ms/step - loss: 2.4924 - accuracy: 0.3165 - val_loss: 2.4371 - val_accuracy: 0.3356 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4817 - accuracy: 0.3169\n",
      "Epoch 00050: val_accuracy did not improve from 0.33559\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.4817 - accuracy: 0.3169 - val_loss: 2.4380 - val_accuracy: 0.3354 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4795 - accuracy: 0.3174\n",
      "Epoch 00051: val_accuracy improved from 0.33559 to 0.33755, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 542s 334ms/step - loss: 2.4795 - accuracy: 0.3174 - val_loss: 2.4311 - val_accuracy: 0.3376 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4717 - accuracy: 0.3179\n",
      "Epoch 00052: val_accuracy did not improve from 0.33755\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.4717 - accuracy: 0.3179 - val_loss: 2.4399 - val_accuracy: 0.3347 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4708 - accuracy: 0.3191\n",
      "Epoch 00053: val_accuracy improved from 0.33755 to 0.33763, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 542s 334ms/step - loss: 2.4708 - accuracy: 0.3191 - val_loss: 2.4315 - val_accuracy: 0.3376 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4647 - accuracy: 0.3222\n",
      "Epoch 00054: val_accuracy did not improve from 0.33763\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.4647 - accuracy: 0.3222 - val_loss: 2.4279 - val_accuracy: 0.3349 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4612 - accuracy: 0.3221\n",
      "Epoch 00055: val_accuracy did not improve from 0.33763\n",
      "1625/1625 [==============================] - 535s 329ms/step - loss: 2.4612 - accuracy: 0.3221 - val_loss: 2.4396 - val_accuracy: 0.3355 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4533 - accuracy: 0.3219\n",
      "Epoch 00056: val_accuracy improved from 0.33763 to 0.33836, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 542s 333ms/step - loss: 2.4533 - accuracy: 0.3219 - val_loss: 2.4256 - val_accuracy: 0.3384 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4522 - accuracy: 0.3234\n",
      "Epoch 00057: val_accuracy did not improve from 0.33836\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.4522 - accuracy: 0.3234 - val_loss: 2.4305 - val_accuracy: 0.3355 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4547 - accuracy: 0.3224\n",
      "Epoch 00058: val_accuracy did not improve from 0.33836\n",
      "1625/1625 [==============================] - 537s 330ms/step - loss: 2.4547 - accuracy: 0.3224 - val_loss: 2.4243 - val_accuracy: 0.3383 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4427 - accuracy: 0.3265\n",
      "Epoch 00059: val_accuracy did not improve from 0.33836\n",
      "1625/1625 [==============================] - 535s 329ms/step - loss: 2.4427 - accuracy: 0.3265 - val_loss: 2.4285 - val_accuracy: 0.3364 - lr: 1.0000e-04\n",
      "Epoch 60/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4271 - accuracy: 0.3301\n",
      "Epoch 00060: val_accuracy did not improve from 0.33836\n",
      "1625/1625 [==============================] - 535s 329ms/step - loss: 2.4271 - accuracy: 0.3301 - val_loss: 2.4248 - val_accuracy: 0.3372 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4239 - accuracy: 0.3293\n",
      "Epoch 00061: val_accuracy did not improve from 0.33836\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.4239 - accuracy: 0.3293 - val_loss: 2.4238 - val_accuracy: 0.3364 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4260 - accuracy: 0.3300\n",
      "Epoch 00062: val_accuracy did not improve from 0.33836\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.4260 - accuracy: 0.3300 - val_loss: 2.4360 - val_accuracy: 0.3342 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4191 - accuracy: 0.3322\n",
      "Epoch 00063: val_accuracy did not improve from 0.33836\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.4191 - accuracy: 0.3322 - val_loss: 2.4270 - val_accuracy: 0.3369 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4211 - accuracy: 0.3305\n",
      "Epoch 00064: val_accuracy improved from 0.33836 to 0.33863, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 543s 334ms/step - loss: 2.4211 - accuracy: 0.3305 - val_loss: 2.4200 - val_accuracy: 0.3386 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4162 - accuracy: 0.3315\n",
      "Epoch 00065: val_accuracy did not improve from 0.33863\n",
      "1625/1625 [==============================] - 537s 330ms/step - loss: 2.4162 - accuracy: 0.3315 - val_loss: 2.4165 - val_accuracy: 0.3375 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4270 - accuracy: 0.3283\n",
      "Epoch 00066: val_accuracy did not improve from 0.33863\n",
      "1625/1625 [==============================] - 537s 330ms/step - loss: 2.4270 - accuracy: 0.3283 - val_loss: 2.4283 - val_accuracy: 0.3369 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4092 - accuracy: 0.3347\n",
      "Epoch 00067: val_accuracy did not improve from 0.33863\n",
      "1625/1625 [==============================] - 537s 331ms/step - loss: 2.4092 - accuracy: 0.3347 - val_loss: 2.4255 - val_accuracy: 0.3360 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4171 - accuracy: 0.3311\n",
      "Epoch 00068: val_accuracy did not improve from 0.33863\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.4171 - accuracy: 0.3311 - val_loss: 2.4189 - val_accuracy: 0.3374 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4144 - accuracy: 0.3313\n",
      "Epoch 00069: val_accuracy did not improve from 0.33863\n",
      "1625/1625 [==============================] - 537s 330ms/step - loss: 2.4144 - accuracy: 0.3313 - val_loss: 2.4190 - val_accuracy: 0.3375 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4172 - accuracy: 0.3337\n",
      "Epoch 00070: val_accuracy did not improve from 0.33863\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.4172 - accuracy: 0.3337 - val_loss: 2.4211 - val_accuracy: 0.3364 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4098 - accuracy: 0.3322\n",
      "Epoch 00071: val_accuracy did not improve from 0.33863\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.4098 - accuracy: 0.3322 - val_loss: 2.4172 - val_accuracy: 0.3364 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4080 - accuracy: 0.3343\n",
      "Epoch 00072: val_accuracy did not improve from 0.33863\n",
      "1625/1625 [==============================] - 537s 330ms/step - loss: 2.4080 - accuracy: 0.3343 - val_loss: 2.4221 - val_accuracy: 0.3367 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4044 - accuracy: 0.3363\n",
      "Epoch 00073: val_accuracy did not improve from 0.33863\n",
      "1625/1625 [==============================] - 538s 331ms/step - loss: 2.4044 - accuracy: 0.3363 - val_loss: 2.4162 - val_accuracy: 0.3383 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4167 - accuracy: 0.3305\n",
      "Epoch 00074: val_accuracy did not improve from 0.33863\n",
      "1625/1625 [==============================] - 537s 330ms/step - loss: 2.4167 - accuracy: 0.3305 - val_loss: 2.4171 - val_accuracy: 0.3377 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4024 - accuracy: 0.3354\n",
      "Epoch 00075: val_accuracy improved from 0.33863 to 0.33990, saving model to /media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/checkpoint.hdf5\n",
      "1625/1625 [==============================] - 543s 334ms/step - loss: 2.4024 - accuracy: 0.3354 - val_loss: 2.4145 - val_accuracy: 0.3399 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4111 - accuracy: 0.3335\n",
      "Epoch 00076: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.4111 - accuracy: 0.3335 - val_loss: 2.4231 - val_accuracy: 0.3344 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4030 - accuracy: 0.3348\n",
      "Epoch 00077: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 537s 330ms/step - loss: 2.4030 - accuracy: 0.3348 - val_loss: 2.4165 - val_accuracy: 0.3363 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4006 - accuracy: 0.3336\n",
      "Epoch 00078: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.4006 - accuracy: 0.3336 - val_loss: 2.4207 - val_accuracy: 0.3369 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4058 - accuracy: 0.3337\n",
      "Epoch 00079: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 537s 331ms/step - loss: 2.4058 - accuracy: 0.3337 - val_loss: 2.4232 - val_accuracy: 0.3373 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4117 - accuracy: 0.3329\n",
      "Epoch 00080: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.4117 - accuracy: 0.3329 - val_loss: 2.4178 - val_accuracy: 0.3379 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4052 - accuracy: 0.3333\n",
      "Epoch 00081: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.4052 - accuracy: 0.3333 - val_loss: 2.4178 - val_accuracy: 0.3352 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4017 - accuracy: 0.3342\n",
      "Epoch 00082: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.4017 - accuracy: 0.3342 - val_loss: 2.4149 - val_accuracy: 0.3391 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4074 - accuracy: 0.3309\n",
      "Epoch 00083: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 537s 330ms/step - loss: 2.4074 - accuracy: 0.3309 - val_loss: 2.4182 - val_accuracy: 0.3386 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.3996 - accuracy: 0.3347\n",
      "Epoch 00084: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 537s 330ms/step - loss: 2.3996 - accuracy: 0.3347 - val_loss: 2.4190 - val_accuracy: 0.3375 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4019 - accuracy: 0.3326\n",
      "Epoch 00085: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.4019 - accuracy: 0.3326 - val_loss: 2.4231 - val_accuracy: 0.3339 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4046 - accuracy: 0.3344\n",
      "Epoch 00086: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 538s 331ms/step - loss: 2.4046 - accuracy: 0.3344 - val_loss: 2.4128 - val_accuracy: 0.3381 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.3963 - accuracy: 0.3334\n",
      "Epoch 00087: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.3963 - accuracy: 0.3334 - val_loss: 2.4148 - val_accuracy: 0.3379 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4014 - accuracy: 0.3330\n",
      "Epoch 00088: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.4014 - accuracy: 0.3330 - val_loss: 2.4142 - val_accuracy: 0.3386 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4014 - accuracy: 0.3348\n",
      "Epoch 00089: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.4014 - accuracy: 0.3348 - val_loss: 2.4193 - val_accuracy: 0.3373 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.3868 - accuracy: 0.3365\n",
      "Epoch 00090: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.3868 - accuracy: 0.3365 - val_loss: 2.4142 - val_accuracy: 0.3394 - lr: 1.0000e-06\n",
      "Epoch 91/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.3997 - accuracy: 0.3354\n",
      "Epoch 00091: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.3997 - accuracy: 0.3354 - val_loss: 2.4217 - val_accuracy: 0.3380 - lr: 1.0000e-06\n",
      "Epoch 92/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.3986 - accuracy: 0.3364\n",
      "Epoch 00092: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.3986 - accuracy: 0.3364 - val_loss: 2.4161 - val_accuracy: 0.3391 - lr: 1.0000e-06\n",
      "Epoch 93/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.3947 - accuracy: 0.3322\n",
      "Epoch 00093: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.3947 - accuracy: 0.3322 - val_loss: 2.4151 - val_accuracy: 0.3396 - lr: 1.0000e-06\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1625/1625 [==============================] - ETA: 0s - loss: 2.3961 - accuracy: 0.3340\n",
      "Epoch 00094: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 535s 330ms/step - loss: 2.3961 - accuracy: 0.3340 - val_loss: 2.4158 - val_accuracy: 0.3380 - lr: 1.0000e-06\n",
      "Epoch 95/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4040 - accuracy: 0.3335\n",
      "Epoch 00095: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 535s 330ms/step - loss: 2.4040 - accuracy: 0.3335 - val_loss: 2.4218 - val_accuracy: 0.3372 - lr: 1.0000e-06\n",
      "Epoch 96/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.3951 - accuracy: 0.3330\n",
      "Epoch 00096: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.3951 - accuracy: 0.3330 - val_loss: 2.4158 - val_accuracy: 0.3377 - lr: 1.0000e-06\n",
      "Epoch 97/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.3957 - accuracy: 0.3349\n",
      "Epoch 00097: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.3957 - accuracy: 0.3349 - val_loss: 2.4167 - val_accuracy: 0.3379 - lr: 1.0000e-06\n",
      "Epoch 98/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.3946 - accuracy: 0.3379\n",
      "Epoch 00098: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 536s 330ms/step - loss: 2.3946 - accuracy: 0.3379 - val_loss: 2.4138 - val_accuracy: 0.3369 - lr: 1.0000e-06\n",
      "Epoch 99/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.3958 - accuracy: 0.3334\n",
      "Epoch 00099: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 537s 330ms/step - loss: 2.3958 - accuracy: 0.3334 - val_loss: 2.4209 - val_accuracy: 0.3372 - lr: 1.0000e-06\n",
      "Epoch 100/100\n",
      "1625/1625 [==============================] - ETA: 0s - loss: 2.4040 - accuracy: 0.3321\n",
      "Epoch 00100: val_accuracy did not improve from 0.33990\n",
      "1625/1625 [==============================] - 537s 330ms/step - loss: 2.4040 - accuracy: 0.3321 - val_loss: 2.4189 - val_accuracy: 0.3363 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "csv_logger = CSVLogger('/media/naveen/nav/mat_codes/nina_DB1_codes/nina_prep_python/wei_DB4_20X10/CNN_nina_20X10.csv', append=True, separator=';')\n",
    "history = model.fit(x_train, y_train_hot, epochs=epochs, batch_size=batch_size, callbacks=[csv_logger,checkpoint_callback,lrate,early],validation_data=(x_test, y_test_hot), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_number 75\n",
      "train accuracy and validation accuracy 0.3354487717151642 0.33989769220352173\n"
     ]
    }
   ],
   "source": [
    "best_index = history.history['val_accuracy'].index(max(history.history['val_accuracy']))\n",
    "print('epoch_number',best_index+1)\n",
    "print('train accuracy and validation accuracy', history.history['accuracy'][best_index], history.history['val_accuracy'][best_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "813/813 [==============================] - 58s 71ms/step - loss: 2.4145 - accuracy: 0.3399\n",
      "test_accuracy 0.33989769220352173\n",
      "[0.33989769220352173]\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(checkpoint_filepath) \n",
    "_, testaccuracy = model.evaluate(x_test, y_test_hot, batch_size=batch_size, verbose=1)\n",
    "print('test_accuracy',testaccuracy)\n",
    "test_acc.append(testaccuracy)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33989769220352173"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics.mean(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
